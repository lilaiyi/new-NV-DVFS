
Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit

Fatbin ptx code:
================
arch = sm_80
code version = [7,2]
producer = <unknown>
host = linux
compile_size = 64bit
compressed








.version 7.2
.target sm_80
.address_size 64


.global .align 4 .u32 _ZZN78_INTERNAL_56_tmpxft_000029d3_00000000_13_reduction_compute_86_cpp1_ii_096bbd7118cooperative_groups4__v17details17_binary_partitionINS1_15coalesced_groupEEES4_RKT_bE8fullMask = -1;












.extern .shared .align 8 .b8 __smem_d[];
.extern .shared .align 4 .b8 __smem[];

.visible .entry _Z13reduce2_floatPfS_j(
.param .u64 _Z13reduce2_floatPfS_j_param_0,
.param .u64 _Z13reduce2_floatPfS_j_param_1,
.param .u32 _Z13reduce2_floatPfS_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<16>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z13reduce2_floatPfS_j_param_0];
ld.param.u64 %rd2, [_Z13reduce2_floatPfS_j_param_1];
ld.param.u32 %r10, [_Z13reduce2_floatPfS_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f32 %f8, 0f00000000;
@%p1 bra LBB0_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

LBB0_2:
shl.b32 %r11, %r3, 2;
mov.u32 %r12, __smem;
add.s32 %r6, %r12, %r11;
st.shared.f32 [%r6], %f8;
barrier.sync 0;
shr.u32 %r15, %r1, 1;
setp.eq.s32 %p2, %r15, 0;
@%p2 bra LBB0_6;

LBB0_3:
setp.ge.u32 %p3, %r3, %r15;
@%p3 bra LBB0_5;

shl.b32 %r13, %r15, 2;
add.s32 %r14, %r6, %r13;
ld.shared.f32 %f4, [%r6];
ld.shared.f32 %f5, [%r14];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r6], %f6;

LBB0_5:
barrier.sync 0;
shr.u32 %r15, %r15, 1;
setp.ne.s32 %p4, %r15, 0;
@%p4 bra LBB0_3;

LBB0_6:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB0_8;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

LBB0_8:
ret;

}

.visible .entry _Z11reduce2_intPiS_j(
.param .u64 _Z11reduce2_intPiS_j_param_0,
.param .u64 _Z11reduce2_intPiS_j_param_1,
.param .u32 _Z11reduce2_intPiS_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z11reduce2_intPiS_j_param_0];
ld.param.u64 %rd2, [_Z11reduce2_intPiS_j_param_1];
ld.param.u32 %r12, [_Z11reduce2_intPiS_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r12;
mov.u32 %r21, 0;
@%p1 bra LBB1_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r21, [%rd5];

LBB1_2:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.u32 [%r7], %r21;
barrier.sync 0;
shr.u32 %r22, %r1, 1;
setp.eq.s32 %p2, %r22, 0;
@%p2 bra LBB1_6;

LBB1_3:
setp.ge.u32 %p3, %r3, %r22;
@%p3 bra LBB1_5;

shl.b32 %r15, %r22, 2;
add.s32 %r16, %r7, %r15;
ld.shared.u32 %r17, [%r7];
ld.shared.u32 %r18, [%r16];
add.s32 %r19, %r17, %r18;
st.shared.u32 [%r7], %r19;

LBB1_5:
barrier.sync 0;
shr.u32 %r22, %r22, 1;
setp.ne.s32 %p4, %r22, 0;
@%p4 bra LBB1_3;

LBB1_6:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB1_8;

ld.shared.u32 %r20, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r20;

LBB1_8:
ret;

}

.visible .entry _Z14reduce2_doublePdS_j(
.param .u64 _Z14reduce2_doublePdS_j_param_0,
.param .u64 _Z14reduce2_doublePdS_j_param_1,
.param .u32 _Z14reduce2_doublePdS_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<15>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z14reduce2_doublePdS_j_param_0];
ld.param.u64 %rd2, [_Z14reduce2_doublePdS_j_param_1];
ld.param.u32 %r9, [_Z14reduce2_doublePdS_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra LBB2_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

LBB2_2:
shl.b32 %r10, %r3, 3;
mov.u32 %r11, __smem_d;
add.s32 %r5, %r11, %r10;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
shr.u32 %r14, %r1, 1;
setp.eq.s32 %p2, %r14, 0;
@%p2 bra LBB2_6;

LBB2_3:
setp.ge.u32 %p3, %r3, %r14;
@%p3 bra LBB2_5;

shl.b32 %r12, %r14, 3;
add.s32 %r13, %r5, %r12;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r13];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

LBB2_5:
barrier.sync 0;
shr.u32 %r14, %r14, 1;
setp.ne.s32 %p4, %r14, 0;
@%p4 bra LBB2_3;

LBB2_6:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB2_8;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

LBB2_8:
ret;

}

.visible .entry _Z7reduce0IiEvPT_S1_j(
.param .u64 _Z7reduce0IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce0IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r22, 0;
@%p1 bra LBB3_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r22, [%rd5];

LBB3_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r7, %r13, %r12;
st.shared.u32 [%r7], %r22;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB3_7;

mov.u32 %r23, 1;

LBB3_4:
shl.b32 %r9, %r23, 1;
rem.u32 %r15, %r3, %r9;
setp.ne.s32 %p3, %r15, 0;
@%p3 bra LBB3_6;

shl.b32 %r16, %r23, 2;
add.s32 %r17, %r7, %r16;
ld.shared.u32 %r18, [%r7];
ld.shared.u32 %r19, [%r17];
add.s32 %r20, %r18, %r19;
st.shared.u32 [%r7], %r20;

LBB3_6:
barrier.sync 0;
setp.lt.u32 %p4, %r9, %r1;
mov.u32 %r23, %r9;
@%p4 bra LBB3_4;

LBB3_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB3_9;

ld.shared.u32 %r21, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r21;

LBB3_9:
ret;

}

.visible .entry _Z7reduce1IiEvPT_S1_j(
.param .u64 _Z7reduce1IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IiEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<28>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IiEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce1IiEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.u32 %r26, 0;
@%p1 bra LBB4_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r26, [%rd5];

LBB4_2:
shl.b32 %r12, %r3, 2;
mov.u32 %r13, __smem;
add.s32 %r14, %r13, %r12;
st.shared.u32 [%r14], %r26;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB4_7;

mov.u32 %r27, 1;

LBB4_4:
shl.b32 %r8, %r27, 1;
mul.lo.s32 %r9, %r8, %r3;
setp.ge.u32 %p3, %r9, %r1;
@%p3 bra LBB4_6;

add.s32 %r16, %r9, %r27;
shl.b32 %r17, %r16, 2;
add.s32 %r19, %r13, %r17;
shl.b32 %r20, %r9, 2;
add.s32 %r21, %r13, %r20;
ld.shared.u32 %r22, [%r21];
ld.shared.u32 %r23, [%r19];
add.s32 %r24, %r22, %r23;
st.shared.u32 [%r21], %r24;

LBB4_6:
barrier.sync 0;
setp.lt.u32 %p4, %r8, %r1;
mov.u32 %r27, %r8;
@%p4 bra LBB4_4;

LBB4_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB4_9;

ld.shared.u32 %r25, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r25;

LBB4_9:
ret;

}

.visible .entry _Z7reduce3IiEvPT_S1_j(
.param .u64 _Z7reduce3IiEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IiEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IiEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<33>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IiEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IiEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce3IiEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r20, %r2, %r3;
setp.ge.u32 %p1, %r4, %r18;
mov.u32 %r31, 0;
@%p1 bra LBB5_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r31, [%rd5];

LBB5_2:
add.s32 %r7, %r4, %r1;
setp.ge.u32 %p2, %r7, %r18;
@%p2 bra LBB5_4;

mul.wide.u32 %rd6, %r7, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.u32 %r21, [%rd7];
add.s32 %r31, %r21, %r31;

LBB5_4:
shl.b32 %r22, %r3, 2;
mov.u32 %r23, __smem;
add.s32 %r10, %r23, %r22;
st.shared.u32 [%r10], %r31;
barrier.sync 0;
shr.u32 %r29, %r1, 1;
setp.eq.s32 %p3, %r29, 0;
@%p3 bra LBB5_8;

LBB5_5:
setp.ge.u32 %p4, %r3, %r29;
@%p4 bra LBB5_7;

shl.b32 %r24, %r29, 2;
add.s32 %r25, %r10, %r24;
ld.shared.u32 %r26, [%r25];
add.s32 %r31, %r26, %r31;
st.shared.u32 [%r10], %r31;

LBB5_7:
barrier.sync 0;
shr.u32 %r29, %r29, 1;
setp.ne.s32 %p5, %r29, 0;
@%p5 bra LBB5_5;

LBB5_8:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra LBB5_10;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r31;

LBB5_10:
ret;

}

.visible .entry _Z7reduce4IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<88>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r15, [_Z7reduce4IiLj512EEvPT_S1_j_param_2];
mov.u32 %r17, %ntid.x;
shl.b32 %r18, %r17, 1;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r21, %r18, %r19, %r20;
setp.ge.u32 %p1, %r21, %r15;
mov.u32 %r85, 0;
@%p1 bra LBB6_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r19, %r20;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r85, [%rd5];

LBB6_2:
add.s32 %r32, %r21, 512;
setp.ge.u32 %p2, %r32, %r15;
@%p2 bra LBB6_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r19, %r20;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+2048];
add.s32 %r85, %r38, %r85;

LBB6_4:
shl.b32 %r40, %r20, 2;
mov.u32 %r41, __smem;
add.s32 %r42, %r41, %r40;
st.shared.u32 [%r42], %r85;
barrier.sync 0;
setp.lt.u32 %p3, %r17, 66;
@%p3 bra LBB6_9;

mov.u32 %r83, %r17;

LBB6_6:
shr.u32 %r8, %r83, 1;
setp.ge.u32 %p4, %r20, %r8;
@%p4 bra LBB6_8;

shl.b32 %r49, %r8, 2;
add.s32 %r50, %r42, %r49;
ld.shared.u32 %r51, [%r50];
add.s32 %r85, %r51, %r85;
st.shared.u32 [%r42], %r85;

LBB6_8:
barrier.sync 0;
setp.gt.u32 %p5, %r83, 131;
mov.u32 %r83, %r8;
@%p5 bra LBB6_6;

LBB6_9:
mov.u32 %r52, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r52, %r53, %r54;
mad.lo.s32 %r12, %r55, %r17, %r20;
setp.gt.u32 %p6, %r12, 31;
@%p6 bra LBB6_11;

mov.u32 %r62, 2;
ld.shared.u32 %r63, [%r42+128];
add.s32 %r64, %r63, %r85;
mov.u32 %r65, 31;
mov.u32 %r66, 16;
mov.u32 %r67, -1;
shfl.sync.down.b32 %r68|%p7, %r64, %r66, %r65, %r67;
add.s32 %r69, %r68, %r64;
mov.u32 %r70, 8;
shfl.sync.down.b32 %r71|%p8, %r69, %r70, %r65, %r67;
add.s32 %r72, %r71, %r69;
mov.u32 %r73, 4;
shfl.sync.down.b32 %r74|%p9, %r72, %r73, %r65, %r67;
add.s32 %r75, %r74, %r72;
shfl.sync.down.b32 %r76|%p10, %r75, %r62, %r65, %r67;
add.s32 %r77, %r76, %r75;
mov.u32 %r78, 1;
shfl.sync.down.b32 %r79|%p11, %r77, %r78, %r65, %r67;
add.s32 %r85, %r79, %r77;

LBB6_11:
setp.ne.s32 %p12, %r12, 0;
@%p12 bra LBB6_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r19, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r85;

LBB6_13:
ret;

}

.visible .entry _Z7reduce4IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<88>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r15, [_Z7reduce4IiLj256EEvPT_S1_j_param_2];
mov.u32 %r17, %ntid.x;
shl.b32 %r18, %r17, 1;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r21, %r18, %r19, %r20;
setp.ge.u32 %p1, %r21, %r15;
mov.u32 %r85, 0;
@%p1 bra LBB7_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r19, %r20;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r85, [%rd5];

LBB7_2:
add.s32 %r32, %r21, 256;
setp.ge.u32 %p2, %r32, %r15;
@%p2 bra LBB7_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r19, %r20;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+1024];
add.s32 %r85, %r38, %r85;

LBB7_4:
shl.b32 %r40, %r20, 2;
mov.u32 %r41, __smem;
add.s32 %r42, %r41, %r40;
st.shared.u32 [%r42], %r85;
barrier.sync 0;
setp.lt.u32 %p3, %r17, 66;
@%p3 bra LBB7_9;

mov.u32 %r83, %r17;

LBB7_6:
shr.u32 %r8, %r83, 1;
setp.ge.u32 %p4, %r20, %r8;
@%p4 bra LBB7_8;

shl.b32 %r49, %r8, 2;
add.s32 %r50, %r42, %r49;
ld.shared.u32 %r51, [%r50];
add.s32 %r85, %r51, %r85;
st.shared.u32 [%r42], %r85;

LBB7_8:
barrier.sync 0;
setp.gt.u32 %p5, %r83, 131;
mov.u32 %r83, %r8;
@%p5 bra LBB7_6;

LBB7_9:
mov.u32 %r52, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r52, %r53, %r54;
mad.lo.s32 %r12, %r55, %r17, %r20;
setp.gt.u32 %p6, %r12, 31;
@%p6 bra LBB7_11;

mov.u32 %r62, 2;
ld.shared.u32 %r63, [%r42+128];
add.s32 %r64, %r63, %r85;
mov.u32 %r65, 31;
mov.u32 %r66, 16;
mov.u32 %r67, -1;
shfl.sync.down.b32 %r68|%p7, %r64, %r66, %r65, %r67;
add.s32 %r69, %r68, %r64;
mov.u32 %r70, 8;
shfl.sync.down.b32 %r71|%p8, %r69, %r70, %r65, %r67;
add.s32 %r72, %r71, %r69;
mov.u32 %r73, 4;
shfl.sync.down.b32 %r74|%p9, %r72, %r73, %r65, %r67;
add.s32 %r75, %r74, %r72;
shfl.sync.down.b32 %r76|%p10, %r75, %r62, %r65, %r67;
add.s32 %r77, %r76, %r75;
mov.u32 %r78, 1;
shfl.sync.down.b32 %r79|%p11, %r77, %r78, %r65, %r67;
add.s32 %r85, %r79, %r77;

LBB7_11:
setp.ne.s32 %p12, %r12, 0;
@%p12 bra LBB7_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r19, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r85;

LBB7_13:
ret;

}

.visible .entry _Z7reduce4IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<88>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r15, [_Z7reduce4IiLj128EEvPT_S1_j_param_2];
mov.u32 %r17, %ntid.x;
shl.b32 %r18, %r17, 1;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r21, %r18, %r19, %r20;
setp.ge.u32 %p1, %r21, %r15;
mov.u32 %r85, 0;
@%p1 bra LBB8_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r19, %r20;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r85, [%rd5];

LBB8_2:
add.s32 %r32, %r21, 128;
setp.ge.u32 %p2, %r32, %r15;
@%p2 bra LBB8_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r19, %r20;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+512];
add.s32 %r85, %r38, %r85;

LBB8_4:
shl.b32 %r40, %r20, 2;
mov.u32 %r41, __smem;
add.s32 %r42, %r41, %r40;
st.shared.u32 [%r42], %r85;
barrier.sync 0;
setp.lt.u32 %p3, %r17, 66;
@%p3 bra LBB8_9;

mov.u32 %r83, %r17;

LBB8_6:
shr.u32 %r8, %r83, 1;
setp.ge.u32 %p4, %r20, %r8;
@%p4 bra LBB8_8;

shl.b32 %r49, %r8, 2;
add.s32 %r50, %r42, %r49;
ld.shared.u32 %r51, [%r50];
add.s32 %r85, %r51, %r85;
st.shared.u32 [%r42], %r85;

LBB8_8:
barrier.sync 0;
setp.gt.u32 %p5, %r83, 131;
mov.u32 %r83, %r8;
@%p5 bra LBB8_6;

LBB8_9:
mov.u32 %r52, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r52, %r53, %r54;
mad.lo.s32 %r12, %r55, %r17, %r20;
setp.gt.u32 %p6, %r12, 31;
@%p6 bra LBB8_11;

mov.u32 %r62, 2;
ld.shared.u32 %r63, [%r42+128];
add.s32 %r64, %r63, %r85;
mov.u32 %r65, 31;
mov.u32 %r66, 16;
mov.u32 %r67, -1;
shfl.sync.down.b32 %r68|%p7, %r64, %r66, %r65, %r67;
add.s32 %r69, %r68, %r64;
mov.u32 %r70, 8;
shfl.sync.down.b32 %r71|%p8, %r69, %r70, %r65, %r67;
add.s32 %r72, %r71, %r69;
mov.u32 %r73, 4;
shfl.sync.down.b32 %r74|%p9, %r72, %r73, %r65, %r67;
add.s32 %r75, %r74, %r72;
shfl.sync.down.b32 %r76|%p10, %r75, %r62, %r65, %r67;
add.s32 %r77, %r76, %r75;
mov.u32 %r78, 1;
shfl.sync.down.b32 %r79|%p11, %r77, %r78, %r65, %r67;
add.s32 %r85, %r79, %r77;

LBB8_11:
setp.ne.s32 %p12, %r12, 0;
@%p12 bra LBB8_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r19, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r85;

LBB8_13:
ret;

}

.visible .entry _Z7reduce4IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<88>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r15, [_Z7reduce4IiLj64EEvPT_S1_j_param_2];
mov.u32 %r17, %ntid.x;
shl.b32 %r18, %r17, 1;
mov.u32 %r19, %ctaid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r21, %r18, %r19, %r20;
setp.ge.u32 %p1, %r21, %r15;
mov.u32 %r85, 0;
@%p1 bra LBB9_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r19, %r20;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r85, [%rd5];

LBB9_2:
add.s32 %r32, %r21, 64;
setp.ge.u32 %p2, %r32, %r15;
@%p2 bra LBB9_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r19, %r20;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+256];
add.s32 %r85, %r38, %r85;

LBB9_4:
shl.b32 %r40, %r20, 2;
mov.u32 %r41, __smem;
add.s32 %r42, %r41, %r40;
st.shared.u32 [%r42], %r85;
barrier.sync 0;
setp.lt.u32 %p3, %r17, 66;
@%p3 bra LBB9_9;

mov.u32 %r83, %r17;

LBB9_6:
shr.u32 %r8, %r83, 1;
setp.ge.u32 %p4, %r20, %r8;
@%p4 bra LBB9_8;

shl.b32 %r49, %r8, 2;
add.s32 %r50, %r42, %r49;
ld.shared.u32 %r51, [%r50];
add.s32 %r85, %r51, %r85;
st.shared.u32 [%r42], %r85;

LBB9_8:
barrier.sync 0;
setp.gt.u32 %p5, %r83, 131;
mov.u32 %r83, %r8;
@%p5 bra LBB9_6;

LBB9_9:
mov.u32 %r52, %ntid.y;
mov.u32 %r53, %tid.z;
mov.u32 %r54, %tid.y;
mad.lo.s32 %r55, %r52, %r53, %r54;
mad.lo.s32 %r12, %r55, %r17, %r20;
setp.gt.u32 %p6, %r12, 31;
@%p6 bra LBB9_11;

mov.u32 %r62, 2;
ld.shared.u32 %r63, [%r42+128];
add.s32 %r64, %r63, %r85;
mov.u32 %r65, 31;
mov.u32 %r66, 16;
mov.u32 %r67, -1;
shfl.sync.down.b32 %r68|%p7, %r64, %r66, %r65, %r67;
add.s32 %r69, %r68, %r64;
mov.u32 %r70, 8;
shfl.sync.down.b32 %r71|%p8, %r69, %r70, %r65, %r67;
add.s32 %r72, %r71, %r69;
mov.u32 %r73, 4;
shfl.sync.down.b32 %r74|%p9, %r72, %r73, %r65, %r67;
add.s32 %r75, %r74, %r72;
shfl.sync.down.b32 %r76|%p10, %r75, %r62, %r65, %r67;
add.s32 %r77, %r76, %r75;
mov.u32 %r78, 1;
shfl.sync.down.b32 %r79|%p11, %r77, %r78, %r65, %r67;
add.s32 %r85, %r79, %r77;

LBB9_11:
setp.ne.s32 %p12, %r12, 0;
@%p12 bra LBB9_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r19, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r85;

LBB9_13:
ret;

}

.visible .entry _Z7reduce4IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj32EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB10_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB10_2:
add.s32 %r32, %r21, 32;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB10_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+128];
add.s32 %r76, %r38, %r76;

LBB10_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB10_9;

mov.u32 %r74, %r18;

LBB10_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB10_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB10_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB10_6;

LBB10_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB10_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB10_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB10_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB10_13:
ret;

}

.visible .entry _Z7reduce4IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj16EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB11_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB11_2:
add.s32 %r32, %r21, 16;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB11_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+64];
add.s32 %r76, %r38, %r76;

LBB11_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB11_9;

mov.u32 %r74, %r18;

LBB11_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB11_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB11_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB11_6;

LBB11_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB11_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB11_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB11_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB11_13:
ret;

}

.visible .entry _Z7reduce4IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj8EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB12_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB12_2:
add.s32 %r32, %r21, 8;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB12_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+32];
add.s32 %r76, %r38, %r76;

LBB12_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB12_9;

mov.u32 %r74, %r18;

LBB12_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB12_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB12_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB12_6;

LBB12_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB12_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB12_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB12_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB12_13:
ret;

}

.visible .entry _Z7reduce4IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj4EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB13_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB13_2:
add.s32 %r32, %r21, 4;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB13_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+16];
add.s32 %r76, %r38, %r76;

LBB13_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB13_9;

mov.u32 %r74, %r18;

LBB13_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB13_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB13_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB13_6;

LBB13_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB13_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB13_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB13_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB13_13:
ret;

}

.visible .entry _Z7reduce4IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj2EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB14_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB14_2:
add.s32 %r32, %r21, 2;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB14_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+8];
add.s32 %r76, %r38, %r76;

LBB14_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB14_9;

mov.u32 %r74, %r18;

LBB14_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB14_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB14_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB14_6;

LBB14_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB14_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB14_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB14_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB14_13:
ret;

}

.visible .entry _Z7reduce4IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<79>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce4IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce4IiLj1EEvPT_S1_j_param_2];
mov.u32 %r18, %ntid.x;
shl.b32 %r19, %r18, 1;
mov.u32 %r20, %ctaid.x;
mov.u32 %r1, %tid.x;
mad.lo.s32 %r21, %r19, %r20, %r1;
setp.ge.u32 %p1, %r21, %r16;
mov.u32 %r76, 0;
@%p1 bra LBB15_2;

cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r22, %ntid.x;
shl.b32 %r23, %r22, 1;
mad.lo.s32 %r26, %r23, %r20, %r1;
mul.wide.u32 %rd4, %r26, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r76, [%rd5];

LBB15_2:
add.s32 %r32, %r21, 1;
setp.ge.u32 %p2, %r32, %r16;
@%p2 bra LBB15_4;

cvta.to.global.u64 %rd6, %rd1;
mov.u32 %r33, %ntid.x;
shl.b32 %r34, %r33, 1;
mad.lo.s32 %r37, %r34, %r20, %r1;
mul.wide.u32 %rd7, %r37, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r38, [%rd8+4];
add.s32 %r76, %r38, %r76;

LBB15_4:
shl.b32 %r39, %r1, 2;
mov.u32 %r40, __smem;
add.s32 %r41, %r40, %r39;
st.shared.u32 [%r41], %r76;
barrier.sync 0;
setp.lt.u32 %p3, %r18, 66;
@%p3 bra LBB15_9;

mov.u32 %r74, %r18;

LBB15_6:
shr.u32 %r9, %r74, 1;
setp.ge.u32 %p4, %r1, %r9;
@%p4 bra LBB15_8;

shl.b32 %r47, %r9, 2;
add.s32 %r48, %r41, %r47;
ld.shared.u32 %r49, [%r48];
add.s32 %r76, %r49, %r76;
st.shared.u32 [%r41], %r76;

LBB15_8:
barrier.sync 0;
setp.gt.u32 %p5, %r74, 131;
mov.u32 %r74, %r9;
@%p5 bra LBB15_6;

LBB15_9:
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mad.lo.s32 %r13, %r53, %r18, %r1;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB15_11;

mov.u32 %r55, 2;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.down.b32 %r59|%p7, %r76, %r57, %r56, %r58;
add.s32 %r60, %r59, %r76;
mov.u32 %r61, 8;
shfl.sync.down.b32 %r62|%p8, %r60, %r61, %r56, %r58;
add.s32 %r63, %r62, %r60;
mov.u32 %r64, 4;
shfl.sync.down.b32 %r65|%p9, %r63, %r64, %r56, %r58;
add.s32 %r66, %r65, %r63;
shfl.sync.down.b32 %r67|%p10, %r66, %r55, %r56, %r58;
add.s32 %r68, %r67, %r66;
mov.u32 %r69, 1;
shfl.sync.down.b32 %r70|%p11, %r68, %r69, %r56, %r58;
add.s32 %r76, %r70, %r68;

LBB15_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB15_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r20, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r76;

LBB15_13:
ret;

}

.visible .entry _Z7reduce5IiLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<74>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce5IiLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj512EEvPT_S1_j_param_1];
ld.param.u32 %r15, [_Z7reduce5IiLj512EEvPT_S1_j_param_2];
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 10;
mov.u32 %r19, %tid.x;
add.s32 %r20, %r18, %r19;
setp.ge.u32 %p1, %r20, %r15;
mov.u32 %r69, 0;
@%p1 bra LBB16_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r20, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r69, [%rd5];

LBB16_2:
add.s32 %r29, %r20, 512;
setp.ge.u32 %p2, %r29, %r15;
@%p2 bra LBB16_4;

cvta.to.global.u64 %rd6, %rd1;
mul.wide.u32 %rd7, %r20, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r34, [%rd8+2048];
add.s32 %r69, %r34, %r69;

LBB16_4:
shl.b32 %r36, %r19, 2;
mov.u32 %r37, __smem;
add.s32 %r5, %r37, %r36;
st.shared.u32 [%r5], %r69;
barrier.sync 0;
setp.gt.u32 %p3, %r19, 255;
@%p3 bra LBB16_6;

ld.shared.u32 %r38, [%r5+1024];
add.s32 %r69, %r38, %r69;
st.shared.u32 [%r5], %r69;

LBB16_6:
barrier.sync 0;
setp.gt.u32 %p4, %r19, 127;
@%p4 bra LBB16_8;

ld.shared.u32 %r40, [%r5+512];
add.s32 %r69, %r40, %r69;
st.shared.u32 [%r5], %r69;

LBB16_8:
barrier.sync 0;
setp.gt.u32 %p5, %r19, 63;
@%p5 bra LBB16_10;

ld.shared.u32 %r42, [%r5+256];
add.s32 %r69, %r42, %r69;
st.shared.u32 [%r5], %r69;

LBB16_10:
barrier.sync 0;
mov.u32 %r43, %ntid.y;
mov.u32 %r44, %tid.z;
mov.u32 %r45, %tid.y;
mad.lo.s32 %r46, %r43, %r44, %r45;
mov.u32 %r47, %ntid.x;
mad.lo.s32 %r12, %r46, %r47, %r19;
setp.gt.u32 %p6, %r12, 31;
@%p6 bra LBB16_12;

ld.shared.u32 %r49, [%r5+128];
add.s32 %r50, %r49, %r69;
mov.u32 %r51, 2;
mov.u32 %r52, 31;
mov.u32 %r53, 16;
mov.u32 %r54, -1;
shfl.sync.down.b32 %r55|%p7, %r50, %r53, %r52, %r54;
add.s32 %r56, %r55, %r50;
mov.u32 %r57, 8;
shfl.sync.down.b32 %r58|%p8, %r56, %r57, %r52, %r54;
add.s32 %r59, %r58, %r56;
mov.u32 %r60, 4;
shfl.sync.down.b32 %r61|%p9, %r59, %r60, %r52, %r54;
add.s32 %r62, %r61, %r59;
shfl.sync.down.b32 %r63|%p10, %r62, %r51, %r52, %r54;
add.s32 %r64, %r63, %r62;
mov.u32 %r65, 1;
shfl.sync.down.b32 %r66|%p11, %r64, %r65, %r52, %r54;
add.s32 %r69, %r66, %r64;

LBB16_12:
setp.ne.s32 %p12, %r12, 0;
@%p12 bra LBB16_14;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r69;

LBB16_14:
ret;

}

.visible .entry _Z7reduce5IiLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<69>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce5IiLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj256EEvPT_S1_j_param_1];
ld.param.u32 %r13, [_Z7reduce5IiLj256EEvPT_S1_j_param_2];
mov.u32 %r15, %ctaid.x;
shl.b32 %r16, %r15, 9;
mov.u32 %r17, %tid.x;
add.s32 %r18, %r16, %r17;
setp.ge.u32 %p1, %r18, %r13;
mov.u32 %r65, 0;
@%p1 bra LBB17_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r18, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r65, [%rd5];

LBB17_2:
add.s32 %r27, %r18, 256;
setp.ge.u32 %p2, %r27, %r13;
@%p2 bra LBB17_4;

cvta.to.global.u64 %rd6, %rd1;
mul.wide.u32 %rd7, %r18, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.u32 %r32, [%rd8+1024];
add.s32 %r65, %r32, %r65;

LBB17_4:
shl.b32 %r34, %r17, 2;
mov.u32 %r35, __smem;
add.s32 %r5, %r35, %r34;
st.shared.u32 [%r5], %r65;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r17, 127;
@%p3 bra LBB17_6;

ld.shared.u32 %r36, [%r5+512];
add.s32 %r65, %r36, %r65;
st.shared.u32 [%r5], %r65;

LBB17_6:
barrier.sync 0;
setp.gt.u32 %p4, %r17, 63;
@%p4 bra LBB17_8;

ld.shared.u32 %r38, [%r5+256];
add.s32 %r65, %r38, %r65;
st.shared.u32 [%r5], %r65;

LBB17_8:
barrier.sync 0;
mov.u32 %r39, %ntid.y;
mov.u32 %r40, %tid.z;
mov.u32 %r41, %tid.y;
mad.lo.s32 %r42, %r39, %r40, %r41;
mov.u32 %r43, %ntid.x;
mad.lo.s32 %r10, %r42, %r43, %r17;
setp.gt.u32 %p5, %r10, 31;
@%p5 bra LBB17_10;

ld.shared.u32 %r45, [%r5+128];
add.s32 %r46, %r45, %r65;
mov.u32 %r47, 2;
mov.u32 %r48, 31;
mov.u32 %r49, 16;
mov.u32 %r50, -1;
shfl.sync.down.b32 %r51|%p6, %r46, %r49, %r48, %r50;
add.s32 %r52, %r51, %r46;
mov.u32 %r53, 8;
shfl.sync.down.b32 %r54|%p7, %r52, %r53, %r48, %r50;
add.s32 %r55, %r54, %r52;
mov.u32 %r56, 4;
shfl.sync.down.b32 %r57|%p8, %r55, %r56, %r48, %r50;
add.s32 %r58, %r57, %r55;
shfl.sync.down.b32 %r59|%p9, %r58, %r47, %r48, %r50;
add.s32 %r60, %r59, %r58;
mov.u32 %r61, 1;
shfl.sync.down.b32 %r62|%p10, %r60, %r61, %r48, %r50;
add.s32 %r65, %r62, %r60;

LBB17_10:
setp.ne.s32 %p11, %r10, 0;
@%p11 bra LBB17_12;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r15, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r65;

LBB17_12:
ret;

}

.visible .entry _Z7reduce5IiLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<56>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj128EEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce5IiLj128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r13, %ctaid.x;
shl.b32 %r14, %r13, 8;
mov.u32 %r15, %tid.x;
add.s32 %r16, %r14, %r15;
setp.ge.u32 %p1, %r16, %r11;
mul.wide.u32 %rd5, %r16, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r53, 0;
@%p1 bra LBB18_2;

ld.global.u32 %r53, [%rd1];

LBB18_2:
add.s32 %r21, %r16, 128;
setp.ge.u32 %p2, %r21, %r11;
@%p2 bra LBB18_4;

ld.global.u32 %r22, [%rd1+512];
add.s32 %r53, %r22, %r53;

LBB18_4:
shl.b32 %r24, %r15, 2;
mov.u32 %r25, __smem;
add.s32 %r5, %r25, %r24;
st.shared.u32 [%r5], %r53;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r15, 63;
@%p3 bra LBB18_6;

ld.shared.u32 %r26, [%r5+256];
add.s32 %r53, %r26, %r53;
st.shared.u32 [%r5], %r53;

LBB18_6:
barrier.sync 0;
mov.u32 %r27, %ntid.y;
mov.u32 %r28, %tid.z;
mov.u32 %r29, %tid.y;
mad.lo.s32 %r30, %r27, %r28, %r29;
mov.u32 %r31, %ntid.x;
mad.lo.s32 %r8, %r30, %r31, %r15;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB18_8;

ld.shared.u32 %r33, [%r5+128];
add.s32 %r34, %r33, %r53;
mov.u32 %r35, 2;
mov.u32 %r36, 31;
mov.u32 %r37, 16;
mov.u32 %r38, -1;
shfl.sync.down.b32 %r39|%p5, %r34, %r37, %r36, %r38;
add.s32 %r40, %r39, %r34;
mov.u32 %r41, 8;
shfl.sync.down.b32 %r42|%p6, %r40, %r41, %r36, %r38;
add.s32 %r43, %r42, %r40;
mov.u32 %r44, 4;
shfl.sync.down.b32 %r45|%p7, %r43, %r44, %r36, %r38;
add.s32 %r46, %r45, %r43;
shfl.sync.down.b32 %r47|%p8, %r46, %r35, %r36, %r38;
add.s32 %r48, %r47, %r46;
mov.u32 %r49, 1;
shfl.sync.down.b32 %r50|%p9, %r48, %r49, %r36, %r38;
add.s32 %r53, %r50, %r48;

LBB18_8:
setp.ne.s32 %p10, %r8, 0;
@%p10 bra LBB18_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r13, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r53;

LBB18_10:
ret;

}

.visible .entry _Z7reduce5IiLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<47>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj64EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 7;
mov.u32 %r14, %tid.x;
add.s32 %r1, %r13, %r14;
setp.ge.u32 %p1, %r1, %r10;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r45, 0;
@%p1 bra LBB19_2;

ld.global.u32 %r45, [%rd1];

LBB19_2:
add.s32 %r15, %r1, 64;
setp.ge.u32 %p2, %r15, %r10;
@%p2 bra LBB19_4;

ld.global.u32 %r16, [%rd1+256];
add.s32 %r45, %r16, %r45;

LBB19_4:
shl.b32 %r18, %r14, 2;
mov.u32 %r19, __smem;
add.s32 %r6, %r19, %r18;
st.shared.u32 [%r6], %r45;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r7, %r23, %r24, %r14;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB19_6;

ld.shared.u32 %r25, [%r6+128];
add.s32 %r26, %r25, %r45;
mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r26, %r29, %r28, %r30;
add.s32 %r32, %r31, %r26;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r45, %r42, %r40;

LBB19_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB19_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r45;

LBB19_8:
ret;

}

.visible .entry _Z7reduce5IiLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj32EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj32EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 6;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB20_2;

ld.global.u32 %r42, [%rd1];

LBB20_2:
add.s32 %r14, %r2, 32;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB20_4;

ld.global.u32 %r15, [%rd1+128];
add.s32 %r42, %r15, %r42;

LBB20_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB20_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB20_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB20_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB20_8:
ret;

}

.visible .entry _Z7reduce5IiLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj16EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj16EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 5;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB21_2;

ld.global.u32 %r42, [%rd1];

LBB21_2:
add.s32 %r14, %r2, 16;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB21_4;

ld.global.u32 %r15, [%rd1+64];
add.s32 %r42, %r15, %r42;

LBB21_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB21_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB21_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB21_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB21_8:
ret;

}

.visible .entry _Z7reduce5IiLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj8EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj8EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 4;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB22_2;

ld.global.u32 %r42, [%rd1];

LBB22_2:
add.s32 %r14, %r2, 8;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB22_4;

ld.global.u32 %r15, [%rd1+32];
add.s32 %r42, %r15, %r42;

LBB22_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB22_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB22_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB22_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB22_8:
ret;

}

.visible .entry _Z7reduce5IiLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj4EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj4EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 3;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB23_2;

ld.global.u32 %r42, [%rd1];

LBB23_2:
add.s32 %r14, %r2, 4;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB23_4;

ld.global.u32 %r15, [%rd1+16];
add.s32 %r42, %r15, %r42;

LBB23_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB23_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB23_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB23_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB23_8:
ret;

}

.visible .entry _Z7reduce5IiLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj2EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj2EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 2;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB24_2;

ld.global.u32 %r42, [%rd1];

LBB24_2:
add.s32 %r14, %r2, 2;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB24_4;

ld.global.u32 %r15, [%rd1+8];
add.s32 %r42, %r15, %r42;

LBB24_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB24_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB24_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB24_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB24_8:
ret;

}

.visible .entry _Z7reduce5IiLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IiLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IiLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IiLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IiLj1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce5IiLj1EEvPT_S1_j_param_2];
mov.u32 %r12, %ctaid.x;
shl.b32 %r13, %r12, 1;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r13, %r1;
setp.ge.u32 %p1, %r2, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.u32 %r42, 0;
@%p1 bra LBB25_2;

ld.global.u32 %r42, [%rd1];

LBB25_2:
add.s32 %r14, %r2, 1;
setp.ge.u32 %p2, %r14, %r10;
@%p2 bra LBB25_4;

ld.global.u32 %r15, [%rd1+4];
add.s32 %r42, %r15, %r42;

LBB25_4:
shl.b32 %r16, %r1, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.u32 [%r18], %r42;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r7, %r22, %r23, %r1;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB25_6;

mov.u32 %r24, 2;
mov.u32 %r25, 31;
mov.u32 %r26, 16;
mov.u32 %r27, -1;
shfl.sync.down.b32 %r28|%p4, %r42, %r26, %r25, %r27;
add.s32 %r29, %r28, %r42;
mov.u32 %r30, 8;
shfl.sync.down.b32 %r31|%p5, %r29, %r30, %r25, %r27;
add.s32 %r32, %r31, %r29;
mov.u32 %r33, 4;
shfl.sync.down.b32 %r34|%p6, %r32, %r33, %r25, %r27;
add.s32 %r35, %r34, %r32;
shfl.sync.down.b32 %r36|%p7, %r35, %r24, %r25, %r27;
add.s32 %r37, %r36, %r35;
mov.u32 %r38, 1;
shfl.sync.down.b32 %r39|%p8, %r37, %r38, %r25, %r27;
add.s32 %r42, %r39, %r37;

LBB25_6:
setp.ne.s32 %p9, %r7, 0;
@%p9 bra LBB25_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r12, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r42;

LBB25_8:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .b32 %r<75>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r20, [_Z7reduce6IiLj512ELb1EEvPT_S1_j_param_2];
mov.u32 %r22, %tid.x;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 10;
add.s32 %r67, %r24, %r22;
setp.ge.u32 %p1, %r67, %r20;
mov.u32 %r68, 0;
@%p1 bra LBB26_5;

mov.u32 %r68, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB26_2:
mul.wide.u32 %rd4, %r67, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r30, [%rd5];
add.s32 %r68, %r30, %r68;
add.s32 %r5, %r67, 512;
setp.ge.u32 %p2, %r5, %r20;
@%p2 bra LBB26_4;

mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r31, [%rd8];
add.s32 %r68, %r31, %r68;

LBB26_4:
mov.u32 %r32, %nctaid.x;
shl.b32 %r33, %r32, 10;
add.s32 %r67, %r67, %r33;
setp.lt.u32 %p3, %r67, %r20;
@%p3 bra LBB26_2;

LBB26_5:
shl.b32 %r35, %r22, 2;
mov.u32 %r36, __smem;
add.s32 %r10, %r36, %r35;
st.shared.u32 [%r10], %r68;
barrier.sync 0;
setp.gt.u32 %p4, %r22, 255;
@%p4 bra LBB26_7;

ld.shared.u32 %r37, [%r10+1024];
add.s32 %r68, %r37, %r68;
st.shared.u32 [%r10], %r68;

LBB26_7:
barrier.sync 0;
setp.gt.u32 %p5, %r22, 127;
@%p5 bra LBB26_9;

ld.shared.u32 %r39, [%r10+512];
add.s32 %r68, %r39, %r68;
st.shared.u32 [%r10], %r68;

LBB26_9:
barrier.sync 0;
setp.gt.u32 %p6, %r22, 63;
@%p6 bra LBB26_11;

ld.shared.u32 %r41, [%r10+256];
add.s32 %r68, %r41, %r68;
st.shared.u32 [%r10], %r68;

LBB26_11:
barrier.sync 0;
mov.u32 %r42, %ntid.y;
mov.u32 %r43, %tid.z;
mov.u32 %r44, %tid.y;
mad.lo.s32 %r45, %r42, %r43, %r44;
mov.u32 %r46, %ntid.x;
mad.lo.s32 %r17, %r45, %r46, %r22;
setp.gt.u32 %p7, %r17, 31;
@%p7 bra LBB26_13;

ld.shared.u32 %r48, [%r10+128];
add.s32 %r49, %r48, %r68;
mov.u32 %r50, 2;
mov.u32 %r51, 31;
mov.u32 %r52, 16;
mov.u32 %r53, -1;
shfl.sync.down.b32 %r54|%p8, %r49, %r52, %r51, %r53;
add.s32 %r55, %r54, %r49;
mov.u32 %r56, 8;
shfl.sync.down.b32 %r57|%p9, %r55, %r56, %r51, %r53;
add.s32 %r58, %r57, %r55;
mov.u32 %r59, 4;
shfl.sync.down.b32 %r60|%p10, %r58, %r59, %r51, %r53;
add.s32 %r61, %r60, %r58;
shfl.sync.down.b32 %r62|%p11, %r61, %r50, %r51, %r53;
add.s32 %r63, %r62, %r61;
mov.u32 %r64, 1;
shfl.sync.down.b32 %r65|%p12, %r63, %r64, %r51, %r53;
add.s32 %r68, %r65, %r63;

LBB26_13:
setp.ne.s32 %p13, %r17, 0;
@%p13 bra LBB26_15;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r23, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r68;

LBB26_15:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<70>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r18, [_Z7reduce6IiLj256ELb1EEvPT_S1_j_param_2];
mov.u32 %r20, %tid.x;
mov.u32 %r21, %ctaid.x;
shl.b32 %r22, %r21, 9;
add.s32 %r63, %r22, %r20;
setp.ge.u32 %p1, %r63, %r18;
mov.u32 %r64, 0;
@%p1 bra LBB27_5;

mov.u32 %r64, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB27_2:
mul.wide.u32 %rd4, %r63, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r28, [%rd5];
add.s32 %r64, %r28, %r64;
add.s32 %r5, %r63, 256;
setp.ge.u32 %p2, %r5, %r18;
@%p2 bra LBB27_4;

mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r29, [%rd8];
add.s32 %r64, %r29, %r64;

LBB27_4:
mov.u32 %r30, %nctaid.x;
shl.b32 %r31, %r30, 9;
add.s32 %r63, %r63, %r31;
setp.lt.u32 %p3, %r63, %r18;
@%p3 bra LBB27_2;

LBB27_5:
shl.b32 %r33, %r20, 2;
mov.u32 %r34, __smem;
add.s32 %r10, %r34, %r33;
st.shared.u32 [%r10], %r64;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r20, 127;
@%p4 bra LBB27_7;

ld.shared.u32 %r35, [%r10+512];
add.s32 %r64, %r35, %r64;
st.shared.u32 [%r10], %r64;

LBB27_7:
barrier.sync 0;
setp.gt.u32 %p5, %r20, 63;
@%p5 bra LBB27_9;

ld.shared.u32 %r37, [%r10+256];
add.s32 %r64, %r37, %r64;
st.shared.u32 [%r10], %r64;

LBB27_9:
barrier.sync 0;
mov.u32 %r38, %ntid.y;
mov.u32 %r39, %tid.z;
mov.u32 %r40, %tid.y;
mad.lo.s32 %r41, %r38, %r39, %r40;
mov.u32 %r42, %ntid.x;
mad.lo.s32 %r15, %r41, %r42, %r20;
setp.gt.u32 %p6, %r15, 31;
@%p6 bra LBB27_11;

ld.shared.u32 %r44, [%r10+128];
add.s32 %r45, %r44, %r64;
mov.u32 %r46, 2;
mov.u32 %r47, 31;
mov.u32 %r48, 16;
mov.u32 %r49, -1;
shfl.sync.down.b32 %r50|%p7, %r45, %r48, %r47, %r49;
add.s32 %r51, %r50, %r45;
mov.u32 %r52, 8;
shfl.sync.down.b32 %r53|%p8, %r51, %r52, %r47, %r49;
add.s32 %r54, %r53, %r51;
mov.u32 %r55, 4;
shfl.sync.down.b32 %r56|%p9, %r54, %r55, %r47, %r49;
add.s32 %r57, %r56, %r54;
shfl.sync.down.b32 %r58|%p10, %r57, %r46, %r47, %r49;
add.s32 %r59, %r58, %r57;
mov.u32 %r60, 1;
shfl.sync.down.b32 %r61|%p11, %r59, %r60, %r47, %r49;
add.s32 %r64, %r61, %r59;

LBB27_11:
setp.ne.s32 %p12, %r15, 0;
@%p12 bra LBB27_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r21, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r64;

LBB27_13:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<65>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj128ELb1EEvPT_S1_j_param_2];
mov.u32 %r18, %tid.x;
mov.u32 %r19, %ctaid.x;
shl.b32 %r20, %r19, 8;
add.s32 %r59, %r20, %r18;
setp.ge.u32 %p1, %r59, %r16;
mov.u32 %r60, 0;
@%p1 bra LBB28_5;

mov.u32 %r60, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB28_2:
mul.wide.u32 %rd4, %r59, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r26, [%rd5];
add.s32 %r60, %r26, %r60;
add.s32 %r5, %r59, 128;
setp.ge.u32 %p2, %r5, %r16;
@%p2 bra LBB28_4;

mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r27, [%rd8];
add.s32 %r60, %r27, %r60;

LBB28_4:
mov.u32 %r28, %nctaid.x;
shl.b32 %r29, %r28, 8;
add.s32 %r59, %r59, %r29;
setp.lt.u32 %p3, %r59, %r16;
@%p3 bra LBB28_2;

LBB28_5:
shl.b32 %r31, %r18, 2;
mov.u32 %r32, __smem;
add.s32 %r10, %r32, %r31;
st.shared.u32 [%r10], %r60;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r18, 63;
@%p4 bra LBB28_7;

ld.shared.u32 %r33, [%r10+256];
add.s32 %r60, %r33, %r60;
st.shared.u32 [%r10], %r60;

LBB28_7:
barrier.sync 0;
mov.u32 %r34, %ntid.y;
mov.u32 %r35, %tid.z;
mov.u32 %r36, %tid.y;
mad.lo.s32 %r37, %r34, %r35, %r36;
mov.u32 %r38, %ntid.x;
mad.lo.s32 %r13, %r37, %r38, %r18;
setp.gt.u32 %p5, %r13, 31;
@%p5 bra LBB28_9;

ld.shared.u32 %r40, [%r10+128];
add.s32 %r41, %r40, %r60;
mov.u32 %r42, 2;
mov.u32 %r43, 31;
mov.u32 %r44, 16;
mov.u32 %r45, -1;
shfl.sync.down.b32 %r46|%p6, %r41, %r44, %r43, %r45;
add.s32 %r47, %r46, %r41;
mov.u32 %r48, 8;
shfl.sync.down.b32 %r49|%p7, %r47, %r48, %r43, %r45;
add.s32 %r50, %r49, %r47;
mov.u32 %r51, 4;
shfl.sync.down.b32 %r52|%p8, %r50, %r51, %r43, %r45;
add.s32 %r53, %r52, %r50;
shfl.sync.down.b32 %r54|%p9, %r53, %r42, %r43, %r45;
add.s32 %r55, %r54, %r53;
mov.u32 %r56, 1;
shfl.sync.down.b32 %r57|%p10, %r55, %r56, %r43, %r45;
add.s32 %r60, %r57, %r55;

LBB28_9:
setp.ne.s32 %p11, %r13, 0;
@%p11 bra LBB28_11;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r19, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r60;

LBB28_11:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<60>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj64ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 7;
add.s32 %r55, %r18, %r16;
setp.ge.u32 %p1, %r55, %r14;
mov.u32 %r56, 0;
@%p1 bra LBB29_5;

mov.u32 %r56, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB29_2:
mul.wide.u32 %rd4, %r55, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r24, [%rd5];
add.s32 %r56, %r24, %r56;
add.s32 %r5, %r55, 64;
setp.ge.u32 %p2, %r5, %r14;
@%p2 bra LBB29_4;

mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r25, [%rd8];
add.s32 %r56, %r25, %r56;

LBB29_4:
mov.u32 %r26, %nctaid.x;
shl.b32 %r27, %r26, 7;
add.s32 %r55, %r55, %r27;
setp.lt.u32 %p3, %r55, %r14;
@%p3 bra LBB29_2;

LBB29_5:
shl.b32 %r29, %r16, 2;
mov.u32 %r30, __smem;
add.s32 %r10, %r30, %r29;
st.shared.u32 [%r10], %r56;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB29_7;

ld.shared.u32 %r36, [%r10+128];
add.s32 %r37, %r36, %r56;
mov.u32 %r38, 2;
mov.u32 %r39, 31;
mov.u32 %r40, 16;
mov.u32 %r41, -1;
shfl.sync.down.b32 %r42|%p5, %r37, %r40, %r39, %r41;
add.s32 %r43, %r42, %r37;
mov.u32 %r44, 8;
shfl.sync.down.b32 %r45|%p6, %r43, %r44, %r39, %r41;
add.s32 %r46, %r45, %r43;
mov.u32 %r47, 4;
shfl.sync.down.b32 %r48|%p7, %r46, %r47, %r39, %r41;
add.s32 %r49, %r48, %r46;
shfl.sync.down.b32 %r50|%p8, %r49, %r38, %r39, %r41;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 1;
shfl.sync.down.b32 %r53|%p9, %r51, %r52, %r39, %r41;
add.s32 %r56, %r53, %r51;

LBB29_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB29_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r56;

LBB29_9:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj32ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 6;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB30_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 6;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB30_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 32;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB30_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB30_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB30_2;

LBB30_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB30_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB30_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB30_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB30_9:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj16ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 5;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB31_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 5;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB31_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 16;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB31_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB31_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB31_2;

LBB31_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB31_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB31_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB31_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB31_9:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj8ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 4;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB32_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 4;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB32_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 8;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB32_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB32_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB32_2;

LBB32_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB32_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB32_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB32_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB32_9:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj4ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 3;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB33_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 3;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB33_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 4;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB33_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB33_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB33_2;

LBB33_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB33_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB33_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB33_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB33_9:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj2ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 2;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB34_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 2;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB34_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 2;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB34_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB34_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB34_2;

LBB34_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB34_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB34_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB34_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB34_9:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<58>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj1ELb1EEvPT_S1_j_param_2];
mov.u32 %r16, %tid.x;
mov.u32 %r17, %ctaid.x;
shl.b32 %r18, %r17, 1;
add.s32 %r53, %r18, %r16;
setp.ge.u32 %p1, %r53, %r14;
mov.u32 %r54, 0;
@%p1 bra LBB35_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 1;
mov.u32 %r54, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB35_2:
mul.wide.u32 %rd4, %r53, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r54, %r25, %r54;
add.s32 %r6, %r53, 1;
setp.ge.u32 %p2, %r6, %r14;
@%p2 bra LBB35_4;

mul.wide.u32 %rd7, %r6, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.u32 %r26, [%rd8];
add.s32 %r54, %r26, %r54;

LBB35_4:
add.s32 %r53, %r53, %r2;
setp.lt.u32 %p3, %r53, %r14;
@%p3 bra LBB35_2;

LBB35_5:
shl.b32 %r28, %r16, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r54;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r31, %ntid.y;
mov.u32 %r32, %tid.z;
mov.u32 %r33, %tid.y;
mad.lo.s32 %r34, %r31, %r32, %r33;
mov.u32 %r35, %ntid.x;
mad.lo.s32 %r11, %r34, %r35, %r16;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB35_7;

mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r40|%p5, %r54, %r38, %r37, %r39;
add.s32 %r41, %r40, %r54;
mov.u32 %r42, 8;
shfl.sync.down.b32 %r43|%p6, %r41, %r42, %r37, %r39;
add.s32 %r44, %r43, %r41;
mov.u32 %r45, 4;
shfl.sync.down.b32 %r46|%p7, %r44, %r45, %r37, %r39;
add.s32 %r47, %r46, %r44;
shfl.sync.down.b32 %r48|%p8, %r47, %r36, %r37, %r39;
add.s32 %r49, %r48, %r47;
mov.u32 %r50, 1;
shfl.sync.down.b32 %r51|%p9, %r49, %r50, %r37, %r39;
add.s32 %r54, %r51, %r49;

LBB35_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB35_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r17, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.u32 [%rd11], %r54;

LBB35_9:
ret;

}

.visible .entry _Z7reduce6IiLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .b32 %r<86>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r18, %tid.x;
mov.u32 %r19, %ctaid.x;
shl.b32 %r20, %r19, 9;
add.s32 %r79, %r20, %r18;
setp.ge.u32 %p1, %r79, %r16;
mov.u32 %r81, 0;
@%p1 bra LBB36_3;

mov.u32 %r81, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB36_2:
mul.wide.u32 %rd4, %r79, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r26, [%rd5];
add.s32 %r81, %r26, %r81;
mov.u32 %r27, %nctaid.x;
shl.b32 %r28, %r27, 9;
add.s32 %r79, %r79, %r28;
setp.lt.u32 %p2, %r79, %r16;
@%p2 bra LBB36_2;

LBB36_3:
shl.b32 %r30, %r18, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r81;
barrier.sync 0;
setp.gt.u32 %p3, %r18, 255;
@%p3 bra LBB36_5;

ld.shared.u32 %r37, [%r32+1024];
add.s32 %r81, %r37, %r81;
st.shared.u32 [%r32], %r81;

LBB36_5:
barrier.sync 0;
setp.gt.u32 %p4, %r18, 127;
@%p4 bra LBB36_7;

ld.shared.u32 %r43, [%r32+512];
add.s32 %r81, %r43, %r81;
st.shared.u32 [%r32], %r81;

LBB36_7:
barrier.sync 0;
setp.gt.u32 %p5, %r18, 63;
@%p5 bra LBB36_9;

ld.shared.u32 %r49, [%r32+256];
add.s32 %r81, %r49, %r81;
st.shared.u32 [%r32], %r81;

LBB36_9:
barrier.sync 0;
mov.u32 %r50, %ntid.y;
mov.u32 %r51, %tid.z;
mov.u32 %r52, %tid.y;
mad.lo.s32 %r53, %r50, %r51, %r52;
mov.u32 %r54, %ntid.x;
mad.lo.s32 %r13, %r53, %r54, %r18;
setp.gt.u32 %p6, %r13, 31;
@%p6 bra LBB36_11;

mov.u32 %r60, 2;
ld.shared.u32 %r61, [%r32+128];
add.s32 %r62, %r61, %r81;
mov.u32 %r63, 31;
mov.u32 %r64, 16;
mov.u32 %r65, -1;
shfl.sync.down.b32 %r66|%p7, %r62, %r64, %r63, %r65;
add.s32 %r67, %r66, %r62;
mov.u32 %r68, 8;
shfl.sync.down.b32 %r69|%p8, %r67, %r68, %r63, %r65;
add.s32 %r70, %r69, %r67;
mov.u32 %r71, 4;
shfl.sync.down.b32 %r72|%p9, %r70, %r71, %r63, %r65;
add.s32 %r73, %r72, %r70;
shfl.sync.down.b32 %r74|%p10, %r73, %r60, %r63, %r65;
add.s32 %r75, %r74, %r73;
mov.u32 %r76, 1;
shfl.sync.down.b32 %r77|%p11, %r75, %r76, %r63, %r65;
add.s32 %r81, %r77, %r75;

LBB36_11:
setp.ne.s32 %p12, %r13, 0;
@%p12 bra LBB36_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r19, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r81;

LBB36_13:
ret;

}

.visible .entry _Z7reduce6IiLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .b32 %r<65>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r16, [_Z7reduce6IiLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r18, %tid.x;
mov.u32 %r19, %ctaid.x;
shl.b32 %r20, %r19, 8;
add.s32 %r59, %r20, %r18;
setp.ge.u32 %p1, %r59, %r16;
mov.u32 %r61, 0;
@%p1 bra LBB37_3;

mov.u32 %r26, %nctaid.x;
shl.b32 %r2, %r26, 8;
mov.u32 %r61, 0;
cvta.to.global.u64 %rd3, %rd1;

LBB37_2:
mul.wide.u32 %rd4, %r59, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.u32 %r27, [%rd5];
add.s32 %r61, %r27, %r61;
add.s32 %r59, %r59, %r2;
setp.lt.u32 %p2, %r59, %r16;
@%p2 bra LBB37_2;

LBB37_3:
shl.b32 %r29, %r18, 2;
mov.u32 %r30, __smem;
add.s32 %r8, %r30, %r29;
st.shared.u32 [%r8], %r61;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r18, 127;
@%p3 bra LBB37_5;

ld.shared.u32 %r31, [%r8+512];
add.s32 %r61, %r31, %r61;
st.shared.u32 [%r8], %r61;

LBB37_5:
barrier.sync 0;
setp.gt.u32 %p4, %r18, 63;
@%p4 bra LBB37_7;

ld.shared.u32 %r33, [%r8+256];
add.s32 %r61, %r33, %r61;
st.shared.u32 [%r8], %r61;

LBB37_7:
barrier.sync 0;
mov.u32 %r34, %ntid.y;
mov.u32 %r35, %tid.z;
mov.u32 %r36, %tid.y;
mad.lo.s32 %r37, %r34, %r35, %r36;
mov.u32 %r38, %ntid.x;
mad.lo.s32 %r13, %r37, %r38, %r18;
setp.gt.u32 %p5, %r13, 31;
@%p5 bra LBB37_9;

ld.shared.u32 %r40, [%r8+128];
add.s32 %r41, %r40, %r61;
mov.u32 %r42, 2;
mov.u32 %r43, 31;
mov.u32 %r44, 16;
mov.u32 %r45, -1;
shfl.sync.down.b32 %r46|%p6, %r41, %r44, %r43, %r45;
add.s32 %r47, %r46, %r41;
mov.u32 %r48, 8;
shfl.sync.down.b32 %r49|%p7, %r47, %r48, %r43, %r45;
add.s32 %r50, %r49, %r47;
mov.u32 %r51, 4;
shfl.sync.down.b32 %r52|%p8, %r50, %r51, %r43, %r45;
add.s32 %r53, %r52, %r50;
shfl.sync.down.b32 %r54|%p9, %r53, %r42, %r43, %r45;
add.s32 %r55, %r54, %r53;
mov.u32 %r56, 1;
shfl.sync.down.b32 %r57|%p10, %r55, %r56, %r43, %r45;
add.s32 %r61, %r57, %r55;

LBB37_9:
setp.ne.s32 %p11, %r13, 0;
@%p11 bra LBB37_11;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r19, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r61;

LBB37_11:
ret;

}

.visible .entry _Z7reduce6IiLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .b32 %r<60>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r14, [_Z7reduce6IiLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r16, %ctaid.x;
shl.b32 %r17, %r16, 7;
mov.u32 %r18, %tid.x;
add.s32 %r55, %r17, %r18;
setp.ge.u32 %p1, %r55, %r14;
mov.u32 %r57, 0;
@%p1 bra LBB38_3;

mov.u32 %r24, %nctaid.x;
shl.b32 %r2, %r24, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r57, 0;

LBB38_2:
mul.wide.u32 %rd4, %r55, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r25, [%rd5];
add.s32 %r57, %r25, %r57;
add.s32 %r55, %r55, %r2;
setp.lt.u32 %p2, %r55, %r14;
@%p2 bra LBB38_2;

LBB38_3:
shl.b32 %r27, %r18, 2;
mov.u32 %r28, __smem;
add.s32 %r8, %r28, %r27;
st.shared.u32 [%r8], %r57;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r18, 63;
@%p3 bra LBB38_5;

ld.shared.u32 %r29, [%r8+256];
add.s32 %r57, %r29, %r57;
st.shared.u32 [%r8], %r57;

LBB38_5:
barrier.sync 0;
mov.u32 %r30, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r30, %r31, %r32;
mov.u32 %r34, %ntid.x;
mad.lo.s32 %r11, %r33, %r34, %r18;
setp.gt.u32 %p4, %r11, 31;
@%p4 bra LBB38_7;

ld.shared.u32 %r36, [%r8+128];
add.s32 %r37, %r36, %r57;
mov.u32 %r38, 2;
mov.u32 %r39, 31;
mov.u32 %r40, 16;
mov.u32 %r41, -1;
shfl.sync.down.b32 %r42|%p5, %r37, %r40, %r39, %r41;
add.s32 %r43, %r42, %r37;
mov.u32 %r44, 8;
shfl.sync.down.b32 %r45|%p6, %r43, %r44, %r39, %r41;
add.s32 %r46, %r45, %r43;
mov.u32 %r47, 4;
shfl.sync.down.b32 %r48|%p7, %r46, %r47, %r39, %r41;
add.s32 %r49, %r48, %r46;
shfl.sync.down.b32 %r50|%p8, %r49, %r38, %r39, %r41;
add.s32 %r51, %r50, %r49;
mov.u32 %r52, 1;
shfl.sync.down.b32 %r53|%p9, %r51, %r52, %r39, %r41;
add.s32 %r57, %r53, %r51;

LBB38_7:
setp.ne.s32 %p10, %r11, 0;
@%p10 bra LBB38_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r16, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r57;

LBB38_9:
ret;

}

.visible .entry _Z7reduce6IiLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<51>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 6;
mov.u32 %r16, %tid.x;
add.s32 %r47, %r15, %r16;
setp.ge.u32 %p1, %r47, %r12;
mov.u32 %r49, 0;
@%p1 bra LBB39_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r2, %r18, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r49, 0;

LBB39_2:
mul.wide.u32 %rd4, %r47, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r19, [%rd5];
add.s32 %r49, %r19, %r49;
add.s32 %r47, %r47, %r2;
setp.lt.u32 %p2, %r47, %r12;
@%p2 bra LBB39_2;

LBB39_3:
shl.b32 %r21, %r16, 2;
mov.u32 %r22, __smem;
add.s32 %r8, %r22, %r21;
st.shared.u32 [%r8], %r49;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r23, %ntid.y;
mov.u32 %r24, %tid.z;
mov.u32 %r25, %tid.y;
mad.lo.s32 %r26, %r23, %r24, %r25;
mov.u32 %r27, %ntid.x;
mad.lo.s32 %r9, %r26, %r27, %r16;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB39_5;

ld.shared.u32 %r28, [%r8+128];
add.s32 %r29, %r28, %r49;
mov.u32 %r30, 2;
mov.u32 %r31, 31;
mov.u32 %r32, 16;
mov.u32 %r33, -1;
shfl.sync.down.b32 %r34|%p4, %r29, %r32, %r31, %r33;
add.s32 %r35, %r34, %r29;
mov.u32 %r36, 8;
shfl.sync.down.b32 %r37|%p5, %r35, %r36, %r31, %r33;
add.s32 %r38, %r37, %r35;
mov.u32 %r39, 4;
shfl.sync.down.b32 %r40|%p6, %r38, %r39, %r31, %r33;
add.s32 %r41, %r40, %r38;
shfl.sync.down.b32 %r42|%p7, %r41, %r30, %r31, %r33;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 1;
shfl.sync.down.b32 %r45|%p8, %r43, %r44, %r31, %r33;
add.s32 %r49, %r45, %r43;

LBB39_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB39_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r49;

LBB39_7:
ret;

}

.visible .entry _Z7reduce6IiLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<48>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 5;
mov.u32 %r1, %tid.x;
add.s32 %r44, %r15, %r1;
setp.ge.u32 %p1, %r44, %r12;
mov.u32 %r46, 0;
@%p1 bra LBB40_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r3, %r17, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r46, 0;

LBB40_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r46, %r18, %r46;
add.s32 %r44, %r44, %r3;
setp.lt.u32 %p2, %r44, %r12;
@%p2 bra LBB40_2;

LBB40_3:
shl.b32 %r19, %r1, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r9, %r25, %r26, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB40_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r46, %r29, %r28, %r30;
add.s32 %r32, %r31, %r46;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r46, %r42, %r40;

LBB40_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB40_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

LBB40_7:
ret;

}

.visible .entry _Z7reduce6IiLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<48>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 4;
mov.u32 %r1, %tid.x;
add.s32 %r44, %r15, %r1;
setp.ge.u32 %p1, %r44, %r12;
mov.u32 %r46, 0;
@%p1 bra LBB41_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r3, %r17, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r46, 0;

LBB41_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r46, %r18, %r46;
add.s32 %r44, %r44, %r3;
setp.lt.u32 %p2, %r44, %r12;
@%p2 bra LBB41_2;

LBB41_3:
shl.b32 %r19, %r1, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r9, %r25, %r26, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB41_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r46, %r29, %r28, %r30;
add.s32 %r32, %r31, %r46;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r46, %r42, %r40;

LBB41_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB41_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

LBB41_7:
ret;

}

.visible .entry _Z7reduce6IiLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<48>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 3;
mov.u32 %r1, %tid.x;
add.s32 %r44, %r15, %r1;
setp.ge.u32 %p1, %r44, %r12;
mov.u32 %r46, 0;
@%p1 bra LBB42_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r3, %r17, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r46, 0;

LBB42_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r46, %r18, %r46;
add.s32 %r44, %r44, %r3;
setp.lt.u32 %p2, %r44, %r12;
@%p2 bra LBB42_2;

LBB42_3:
shl.b32 %r19, %r1, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r9, %r25, %r26, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB42_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r46, %r29, %r28, %r30;
add.s32 %r32, %r31, %r46;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r46, %r42, %r40;

LBB42_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB42_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

LBB42_7:
ret;

}

.visible .entry _Z7reduce6IiLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<48>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 2;
mov.u32 %r1, %tid.x;
add.s32 %r44, %r15, %r1;
setp.ge.u32 %p1, %r44, %r12;
mov.u32 %r46, 0;
@%p1 bra LBB43_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r3, %r17, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r46, 0;

LBB43_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r46, %r18, %r46;
add.s32 %r44, %r44, %r3;
setp.lt.u32 %p2, %r44, %r12;
@%p2 bra LBB43_2;

LBB43_3:
shl.b32 %r19, %r1, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r9, %r25, %r26, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB43_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r46, %r29, %r28, %r30;
add.s32 %r32, %r31, %r46;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r46, %r42, %r40;

LBB43_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB43_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

LBB43_7:
ret;

}

.visible .entry _Z7reduce6IiLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<48>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
shl.b32 %r15, %r14, 1;
mov.u32 %r1, %tid.x;
add.s32 %r44, %r15, %r1;
setp.ge.u32 %p1, %r44, %r12;
mov.u32 %r46, 0;
@%p1 bra LBB44_3;

mov.u32 %r17, %nctaid.x;
shl.b32 %r3, %r17, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r46, 0;

LBB44_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r18, [%rd5];
add.s32 %r46, %r18, %r46;
add.s32 %r44, %r44, %r3;
setp.lt.u32 %p2, %r44, %r12;
@%p2 bra LBB44_2;

LBB44_3:
shl.b32 %r19, %r1, 2;
mov.u32 %r20, __smem;
add.s32 %r21, %r20, %r19;
st.shared.u32 [%r21], %r46;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r9, %r25, %r26, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB44_5;

mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p4, %r46, %r29, %r28, %r30;
add.s32 %r32, %r31, %r46;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p5, %r32, %r33, %r28, %r30;
add.s32 %r35, %r34, %r32;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p6, %r35, %r36, %r28, %r30;
add.s32 %r38, %r37, %r35;
shfl.sync.down.b32 %r39|%p7, %r38, %r27, %r28, %r30;
add.s32 %r40, %r39, %r38;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r28, %r30;
add.s32 %r46, %r42, %r40;

LBB44_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB44_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r46;

LBB44_7:
ret;

}

.visible .entry _Z7reduce6IiLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r12, [_Z7reduce6IiLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r14, %ctaid.x;
mov.u32 %r1, %tid.x;
add.s32 %r42, %r14, %r1;
setp.ge.u32 %p1, %r42, %r12;
mov.u32 %r44, 0;
@%p1 bra LBB45_3;

mov.u32 %r3, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r44, 0;

LBB45_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r16, [%rd5];
add.s32 %r44, %r16, %r44;
add.s32 %r42, %r42, %r3;
setp.lt.u32 %p2, %r42, %r12;
@%p2 bra LBB45_2;

LBB45_3:
shl.b32 %r17, %r1, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.u32 [%r19], %r44;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r9, %r23, %r24, %r1;
setp.gt.u32 %p3, %r9, 31;
@%p3 bra LBB45_5;

mov.u32 %r25, 2;
mov.u32 %r26, 31;
mov.u32 %r27, 16;
mov.u32 %r28, -1;
shfl.sync.down.b32 %r29|%p4, %r44, %r27, %r26, %r28;
add.s32 %r30, %r29, %r44;
mov.u32 %r31, 8;
shfl.sync.down.b32 %r32|%p5, %r30, %r31, %r26, %r28;
add.s32 %r33, %r32, %r30;
mov.u32 %r34, 4;
shfl.sync.down.b32 %r35|%p6, %r33, %r34, %r26, %r28;
add.s32 %r36, %r35, %r33;
shfl.sync.down.b32 %r37|%p7, %r36, %r25, %r26, %r28;
add.s32 %r38, %r37, %r36;
mov.u32 %r39, 1;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r26, %r28;
add.s32 %r44, %r40, %r38;

LBB45_5:
setp.ne.s32 %p9, %r9, 0;
@%p9 bra LBB45_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r14, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r44;

LBB45_7:
ret;

}

.visible .entry _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB46_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 11;
mov.u32 %r41, 0;

LBB46_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 1024;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB46_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB46_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB46_2;

LBB46_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB46_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB46_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 1024;
mov.u32 %r44, 1;
@%p6 bra LBB46_9;

mov.u32 %r34, 1024;
div.u32 %r44, %r34, %r14;

LBB46_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB46_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB46_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB46_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB46_13:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB47_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 10;
mov.u32 %r41, 0;

LBB47_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 512;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB47_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB47_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB47_2;

LBB47_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB47_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB47_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 512;
mov.u32 %r44, 1;
@%p6 bra LBB47_9;

mov.u32 %r34, 512;
div.u32 %r44, %r34, %r14;

LBB47_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB47_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB47_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB47_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB47_13:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB48_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 9;
mov.u32 %r41, 0;

LBB48_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 256;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB48_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB48_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB48_2;

LBB48_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB48_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB48_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 256;
mov.u32 %r44, 1;
@%p6 bra LBB48_9;

mov.u32 %r34, 256;
div.u32 %r44, %r34, %r14;

LBB48_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB48_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB48_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB48_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB48_13:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB49_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 8;
mov.u32 %r41, 0;

LBB49_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 128;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB49_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB49_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB49_2;

LBB49_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB49_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB49_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 128;
mov.u32 %r44, 1;
@%p6 bra LBB49_9;

mov.u32 %r34, 128;
div.u32 %r44, %r34, %r14;

LBB49_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB49_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB49_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB49_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB49_13:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB50_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 7;
mov.u32 %r41, 0;

LBB50_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 64;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB50_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB50_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB50_2;

LBB50_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB50_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB50_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 64;
mov.u32 %r44, 1;
@%p6 bra LBB50_9;

mov.u32 %r34, 64;
div.u32 %r44, %r34, %r14;

LBB50_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB50_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB50_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB50_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB50_13:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB51_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 6;
mov.u32 %r41, 0;

LBB51_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 32;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB51_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB51_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB51_2;

LBB51_5:
mov.u32 %r27, -1;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB51_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB51_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 32;
mov.u32 %r44, 1;
@%p6 bra LBB51_9;

mov.u32 %r34, 32;
div.u32 %r44, %r34, %r14;

LBB51_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB51_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB51_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB51_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB51_13:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB52_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 5;
mov.u32 %r41, 0;

LBB52_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 16;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB52_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB52_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB52_2;

LBB52_5:
mov.u32 %r27, 65535;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB52_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB52_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 16;
mov.u32 %r44, 1;
@%p6 bra LBB52_9;

mov.u32 %r34, 16;
div.u32 %r44, %r34, %r14;

LBB52_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB52_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB52_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB52_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB52_13:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB53_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 4;
mov.u32 %r41, 0;

LBB53_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 8;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB53_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB53_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB53_2;

LBB53_5:
mov.u32 %r27, 255;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB53_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB53_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 8;
mov.u32 %r44, 1;
@%p6 bra LBB53_9;

mov.u32 %r34, 8;
div.u32 %r44, %r34, %r14;

LBB53_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB53_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB53_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB53_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB53_13:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB54_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 3;
mov.u32 %r41, 0;

LBB54_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 4;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB54_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB54_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB54_2;

LBB54_5:
mov.u32 %r27, 15;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB54_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB54_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 4;
mov.u32 %r44, 1;
@%p6 bra LBB54_9;

mov.u32 %r34, 4;
div.u32 %r44, %r34, %r14;

LBB54_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB54_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB54_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB54_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB54_13:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<10>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r20, [_Z7reduce7IiLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r22, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r40, %r22, %r2;
setp.ge.u32 %p2, %r40, %r20;
mov.u32 %r41, 0;
@%p2 bra LBB55_5;

mov.u32 %r24, %nctaid.x;
shl.b32 %r4, %r24, 2;
mov.u32 %r41, 0;

LBB55_2:
mul.wide.u32 %rd4, %r40, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r25, [%rd5];
add.s32 %r41, %r25, %r41;
add.s32 %r8, %r40, 2;
setp.ge.u32 %p3, %r8, %r20;
@%p3 bra LBB55_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r26, [%rd7];
add.s32 %r41, %r26, %r41;

LBB55_4:
add.s32 %r40, %r40, %r4;
setp.lt.u32 %p4, %r40, %r20;
@%p4 bra LBB55_2;

LBB55_5:
mov.u32 %r27, 3;
redux.sync.add.s32 %r45, %r41, %r27;
mov.u32 %r14, WARP_SZ;
rem.u32 %r28, %r2, %r14;
setp.ne.s32 %p5, %r28, 0;
@%p5 bra LBB55_7;

div.u32 %r29, %r2, %r14;
shl.b32 %r30, %r29, 2;
mov.u32 %r31, __smem;
add.s32 %r32, %r31, %r30;
st.shared.u32 [%r32], %r45;

LBB55_7:
bar.sync 0;
setp.gt.u32 %p6, %r14, 2;
mov.u32 %r44, 1;
@%p6 bra LBB55_9;

mov.u32 %r34, 2;
div.u32 %r44, %r34, %r14;

LBB55_9:
setp.ge.u32 %p7, %r2, %r44;
setp.lt.u32 %p8, %r2, %r44;
vote.sync.ballot.b32 %r17, %p8, %r27;
@%p7 bra LBB55_11;

shl.b32 %r36, %r2, 2;
mov.u32 %r37, __smem;
add.s32 %r38, %r37, %r36;
ld.shared.u32 %r39, [%r38];
redux.sync.add.s32 %r45, %r39, %r17;

LBB55_11:
setp.ne.s32 %p9, %r2, 0;
@%p9 bra LBB55_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r45;

LBB55_13:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r18, [_Z7reduce7IiLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r20, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r33, %r20, %r2;
setp.ge.u32 %p2, %r33, %r18;
mov.u32 %r34, 0;
@%p2 bra LBB56_5;

mov.u32 %r22, %nctaid.x;
shl.b32 %r4, %r22, 1;
mov.u32 %r34, 0;

LBB56_2:
mul.wide.u32 %rd4, %r33, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r23, [%rd5];
add.s32 %r34, %r23, %r34;
add.s32 %r8, %r33, 1;
setp.ge.u32 %p3, %r8, %r18;
@%p3 bra LBB56_4;

mul.wide.u32 %rd6, %r8, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.u32 %r24, [%rd7];
add.s32 %r34, %r24, %r34;

LBB56_4:
add.s32 %r33, %r33, %r4;
setp.lt.u32 %p4, %r33, %r18;
@%p4 bra LBB56_2;

LBB56_5:
mov.u32 %r25, 1;
redux.sync.add.s32 %r37, %r34, %r25;
mov.u32 %r14, WARP_SZ;
rem.u32 %r26, %r2, %r14;
setp.ne.s32 %p5, %r26, 0;
@%p5 bra LBB56_7;

div.u32 %r27, %r2, %r14;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.u32 [%r30], %r37;

LBB56_7:
bar.sync 0;
setp.ne.s32 %p6, %r2, 0;
setp.eq.s32 %p7, %r2, 0;
vote.sync.ballot.b32 %r15, %p7, %r25;
@%p6 bra LBB56_9;

ld.shared.u32 %r32, [__smem];
redux.sync.add.s32 %r37, %r32, %r15;

LBB56_9:
@%p6 bra LBB56_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.u32 [%rd10], %r37;

LBB56_11:
ret;

}

.visible .entry _Z7reduce7IiLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB57_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 9;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB57_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB57_2;

LBB57_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB57_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB57_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 512;
mov.u32 %r39, 1;
@%p5 bra LBB57_7;

mov.u32 %r30, 512;
div.u32 %r39, %r30, %r11;

LBB57_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB57_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB57_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB57_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB57_11:
ret;

}

.visible .entry _Z7reduce7IiLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB58_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 8;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB58_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB58_2;

LBB58_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB58_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB58_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 256;
mov.u32 %r39, 1;
@%p5 bra LBB58_7;

mov.u32 %r30, 256;
div.u32 %r39, %r30, %r11;

LBB58_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB58_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB58_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB58_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB58_11:
ret;

}

.visible .entry _Z7reduce7IiLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB59_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB59_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB59_2;

LBB59_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB59_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB59_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 128;
mov.u32 %r39, 1;
@%p5 bra LBB59_7;

mov.u32 %r30, 128;
div.u32 %r39, %r30, %r11;

LBB59_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB59_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB59_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB59_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB59_11:
ret;

}

.visible .entry _Z7reduce7IiLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB60_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB60_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB60_2;

LBB60_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB60_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB60_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 64;
mov.u32 %r39, 1;
@%p5 bra LBB60_7;

mov.u32 %r30, 64;
div.u32 %r39, %r30, %r11;

LBB60_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB60_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB60_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB60_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB60_11:
ret;

}

.visible .entry _Z7reduce7IiLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB61_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB61_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB61_2;

LBB61_3:
mov.u32 %r23, -1;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB61_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB61_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 32;
mov.u32 %r39, 1;
@%p5 bra LBB61_7;

mov.u32 %r30, 32;
div.u32 %r39, %r30, %r11;

LBB61_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB61_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB61_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB61_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB61_11:
ret;

}

.visible .entry _Z7reduce7IiLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB62_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB62_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB62_2;

LBB62_3:
mov.u32 %r23, 65535;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB62_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB62_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 16;
mov.u32 %r39, 1;
@%p5 bra LBB62_7;

mov.u32 %r30, 16;
div.u32 %r39, %r30, %r11;

LBB62_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB62_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB62_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB62_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB62_11:
ret;

}

.visible .entry _Z7reduce7IiLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB63_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB63_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB63_2;

LBB63_3:
mov.u32 %r23, 255;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB63_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB63_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 8;
mov.u32 %r39, 1;
@%p5 bra LBB63_7;

mov.u32 %r30, 8;
div.u32 %r39, %r30, %r11;

LBB63_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB63_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB63_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB63_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB63_11:
ret;

}

.visible .entry _Z7reduce7IiLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB64_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB64_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB64_2;

LBB64_3:
mov.u32 %r23, 15;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB64_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB64_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 4;
mov.u32 %r39, 1;
@%p5 bra LBB64_7;

mov.u32 %r30, 4;
div.u32 %r39, %r30, %r11;

LBB64_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB64_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB64_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB64_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB64_11:
ret;

}

.visible .entry _Z7reduce7IiLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<9>;
.reg .b32 %r<41>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IiLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r19, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r19, %r2;
setp.ge.u32 %p2, %r36, %r17;
mov.u32 %r38, 0;
@%p2 bra LBB65_3;

mov.u32 %r21, %nctaid.x;
shl.b32 %r4, %r21, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r38, 0;

LBB65_2:
mul.wide.u32 %rd4, %r36, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r22, [%rd5];
add.s32 %r38, %r22, %r38;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r17;
@%p3 bra LBB65_2;

LBB65_3:
mov.u32 %r23, 3;
redux.sync.add.s32 %r40, %r38, %r23;
mov.u32 %r11, WARP_SZ;
rem.u32 %r24, %r2, %r11;
setp.ne.s32 %p4, %r24, 0;
@%p4 bra LBB65_5;

div.u32 %r25, %r2, %r11;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.u32 [%r28], %r40;

LBB65_5:
bar.sync 0;
setp.gt.u32 %p5, %r11, 2;
mov.u32 %r39, 1;
@%p5 bra LBB65_7;

mov.u32 %r30, 2;
div.u32 %r39, %r30, %r11;

LBB65_7:
setp.ge.u32 %p6, %r2, %r39;
setp.lt.u32 %p7, %r2, %r39;
vote.sync.ballot.b32 %r14, %p7, %r23;
@%p6 bra LBB65_9;

shl.b32 %r32, %r2, 2;
mov.u32 %r33, __smem;
add.s32 %r34, %r33, %r32;
ld.shared.u32 %r35, [%r34];
redux.sync.add.s32 %r40, %r35, %r14;

LBB65_9:
setp.ne.s32 %p8, %r2, 0;
@%p8 bra LBB65_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r40;

LBB65_11:
ret;

}

.visible .entry _Z7reduce7IiLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IiLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r27, %r1, %r2;
setp.ge.u32 %p2, %r27, %r15;
mov.u32 %r29, 0;
@%p2 bra LBB66_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r29, 0;

LBB66_2:
mul.wide.u32 %rd4, %r27, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.u32 %r18, [%rd5];
add.s32 %r29, %r18, %r29;
add.s32 %r27, %r27, %r4;
setp.lt.u32 %p3, %r27, %r15;
@%p3 bra LBB66_2;

LBB66_3:
mov.u32 %r19, 1;
redux.sync.add.s32 %r30, %r29, %r19;
mov.u32 %r11, WARP_SZ;
rem.u32 %r20, %r2, %r11;
setp.ne.s32 %p4, %r20, 0;
@%p4 bra LBB66_5;

div.u32 %r21, %r2, %r11;
shl.b32 %r22, %r21, 2;
mov.u32 %r23, __smem;
add.s32 %r24, %r23, %r22;
st.shared.u32 [%r24], %r30;

LBB66_5:
bar.sync 0;
setp.ne.s32 %p5, %r2, 0;
setp.eq.s32 %p6, %r2, 0;
vote.sync.ballot.b32 %r12, %p6, %r19;
@%p5 bra LBB66_7;

ld.shared.u32 %r26, [__smem];
redux.sync.add.s32 %r30, %r26, %r12;

LBB66_7:
@%p5 bra LBB66_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r30;

LBB66_9:
ret;

}

.visible .entry _Z9cg_reduceIiEvPT_S1_j(
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIiEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIiEvPT_S1_j_param_2
)
{
.reg .pred %p<8>;
.reg .b32 %r<100>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIiEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIiEvPT_S1_j_param_1];
ld.param.u32 %r19, [_Z9cg_reduceIiEvPT_S1_j_param_2];
mov.u32 %r21, %tid.x;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r27, %r25, %r26, %r21;
mul.lo.s32 %r28, %r26, %r22;
mov.u32 %r29, %ntid.z;
mul.lo.s32 %r95, %r28, %r29;
mov.u32 %r30, %ctaid.x;
mad.lo.s32 %r92, %r95, %r30, %r27;
setp.ge.u32 %p1, %r92, %r19;
mov.u32 %r97, 0;
@%p1 bra LBB67_3;

mov.u32 %r44, %nctaid.x;
mul.lo.s32 %r3, %r95, %r44;
cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r97, 0;

LBB67_2:
mul.wide.u32 %rd4, %r92, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r45, [%rd5];
add.s32 %r97, %r45, %r97;
add.s32 %r92, %r92, %r3;
setp.lt.u32 %p2, %r92, %r19;
@%p2 bra LBB67_2;

LBB67_3:
shl.b32 %r52, %r27, 2;
mov.u32 %r53, __smem;
add.s32 %r54, %r53, %r52;
st.shared.u32 [%r54], %r97;
setp.lt.u32 %p3, %r95, 64;
@%p3 bra LBB67_7;

LBB67_4:
barrier.sync 0;
shr.u32 %r13, %r95, 1;
setp.ge.u32 %p4, %r27, %r13;
@%p4 bra LBB67_6;

shl.b32 %r72, %r13, 2;
add.s32 %r73, %r54, %r72;
ld.shared.u32 %r74, [%r73];
add.s32 %r97, %r74, %r97;
st.shared.u32 [%r54], %r97;

LBB67_6:
setp.gt.u32 %p5, %r95, 127;
mov.u32 %r95, %r13;
@%p5 bra LBB67_4;

LBB67_7:
barrier.sync 0;
shl.b32 %r82, %r27, 11;
setp.gt.u32 %p6, %r82, 65535;
@%p6 bra LBB67_9;

mov.u32 %r83, -1;
redux.sync.add.s32 %r97, %r97, %r83;

LBB67_9:
setp.ne.s32 %p7, %r27, 0;
@%p7 bra LBB67_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r30, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.u32 [%rd8], %r97;

LBB67_11:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<21>;
.reg .b32 %r<197>;
.reg .b64 %rd<22>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch[256];

ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r47, [_Z20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_j_param_2];
mov.u32 %r48, %tid.x;
mov.u32 %r49, %ntid.y;
mov.u32 %r50, %tid.z;
mov.u32 %r51, %tid.y;
mad.lo.s32 %r52, %r49, %r50, %r51;
mov.u32 %r53, %ntid.x;
mad.lo.s32 %r54, %r52, %r53, %r48;
setp.gt.u32 %p1, %r54, 31;
@%p1 bra LBB68_2;

shl.b32 %r62, %r54, 2;
mov.u32 %r63, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r64, %r63, %r62;
mov.u32 %r65, 0;
st.shared.u32 [%r64], %r65;

LBB68_2:
barrier.sync 0;
mov.u32 %r1, %nctaid.x;
add.s32 %r66, %r47, -1;
and.b32 %r67, %r66, %r47;
setp.eq.s32 %p2, %r67, 0;
@%p2 bra LBB68_6;

mov.u32 %r69, %ctaid.x;
shl.b32 %r70, %r69, 10;
add.s32 %r179, %r70, %r48;
setp.ge.u32 %p3, %r179, %r47;
mov.u32 %r184, 0;
@%p3 bra LBB68_11;

cvta.to.global.u64 %rd1, %rd3;
shl.b32 %r3, %r1, 10;
mov.u32 %r184, 0;

LBB68_5:
mul.wide.u32 %rd5, %r179, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r73, [%rd6];
add.s32 %r184, %r73, %r184;
add.s32 %r179, %r179, %r3;
setp.lt.u32 %p4, %r179, %r47;
@%p4 bra LBB68_5;
bra.uni LBB68_11;

LBB68_6:
mov.u32 %r75, %ctaid.x;
shl.b32 %r76, %r75, 11;
add.s32 %r181, %r76, %r48;
setp.ge.u32 %p5, %r181, %r47;
mov.u32 %r184, 0;
@%p5 bra LBB68_11;

cvta.to.global.u64 %rd2, %rd3;
shl.b32 %r9, %r1, 11;
mov.u32 %r184, 0;
cvt.u64.u32 %rd11, %r47;

LBB68_8:
cvt.u64.u32 %rd7, %r181;
mul.wide.u32 %rd8, %r181, 4;
add.s64 %rd9, %rd2, %rd8;
ld.global.u32 %r83, [%rd9];
add.s32 %r184, %r83, %r184;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd11;
@%p6 bra LBB68_10;

add.s32 %r85, %r181, %r53;
mul.wide.u32 %rd13, %r85, 4;
add.s64 %rd14, %rd2, %rd13;
ld.global.u32 %r86, [%rd14];
add.s32 %r184, %r86, %r184;

LBB68_10:
add.s32 %r181, %r181, %r9;
setp.lt.u32 %p7, %r181, %r47;
@%p7 bra LBB68_8;

LBB68_11:
shr.u32 %r17, %r54, 9;
shr.u32 %r95, %r54, 3;
and.b32 %r96, %r95, 536870908;
mov.u32 %r97, _ZZ20multi_warp_cg_reduceIiLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r18, %r97, %r96;
mov.u32 %r98, -1;
redux.sync.add.s32 %r99, %r184, %r98;
mov.u32 %r87, 0;
st.shared.u32 [%r18+128], %r99;
and.b32 %r19, %r54, 31;
setp.ne.s32 %p8, %r19, 0;
bar.warp.sync -1;
mov.u32 %r185, %r87;
@%p8 bra LBB68_13;

mul.wide.u32 %rd16, %r17, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r97;
cvta.shared.u64 %rd17, %tmp; }
add.s64 %rd18, %rd17, %rd16;
add.s64 %rd15, %rd18, 8;
mov.u32 %r101, 1;

	atom.add.release.gpu.u32 %r185,[%rd15],%r101;


LBB68_13:
mov.u32 %r103, 31;
shfl.sync.idx.b32 %r22|%p9, %r185, %r87, %r103, %r98;
add.s32 %r106, %r22, 1;
and.b32 %r107, %r106, 2147483647;
setp.eq.s32 %p10, %r107, 16;
shl.b32 %r108, %r17, 2;
add.s32 %r23, %r97, %r108;
@%p10 bra LBB68_15;
bra.uni LBB68_14;

LBB68_15:
and.b32 %r119, %r54, 16;
setp.ne.s32 %p12, %r119, 0;
@%p12 bra LBB68_17;

and.b32 %r128, %r54, 15;
and.b32 %r129, %r54, -512;
shr.u32 %r130, %r129, 5;
or.b32 %r131, %r130, %r128;
shl.b32 %r132, %r131, 2;
add.s32 %r134, %r97, %r132;

	mov.u32 %r120, %laneid;

	and.b32 %r135, %r120, -16;
mov.u32 %r136, 65535;
shl.b32 %r137, %r136, %r135;
ld.shared.u32 %r138, [%r134+128];
redux.sync.add.s32 %r139, %r138, %r137;
st.shared.u32 [%r134+128], %r139;

LBB68_17:
bar.warp.sync -1;
@%p8 bra LBB68_19;

ld.volatile.shared.u32 %r140, [%r23+8];
not.b32 %r141, %r140;
and.b32 %r142, %r141, -2147483648;
st.volatile.shared.u32 [%r23+8], %r142;
bra.uni LBB68_19;

LBB68_14:
ld.volatile.shared.u32 %r110, [%r23+8];
xor.b32 %r111, %r110, %r22;
setp.gt.s32 %p11, %r111, -1;
@%p11 bra LBB68_14;

LBB68_19:
ld.shared.u32 %r24, [%r18+128];
bar.warp.sync -1;
and.b32 %r150, %r54, 511;
setp.ne.s32 %p14, %r150, 0;
@%p14 bra LBB68_21;

mov.u32 %r152, __smem;
add.s32 %r153, %r152, %r108;
st.shared.u32 [%r153], %r24;

LBB68_21:
barrier.sync 0;
setp.ne.s32 %p15, %r48, 0;
@%p15 bra LBB68_30;

mul.lo.s32 %r158, %r53, %r49;
mov.u32 %r159, %ntid.z;
mad.lo.s32 %r160, %r158, %r159, 511;
shr.u32 %r25, %r160, 9;
setp.eq.s32 %p16, %r25, 0;
mov.u32 %r196, 0;
@%p16 bra LBB68_29;

add.s32 %r164, %r25, -1;
and.b32 %r195, %r25, 3;
setp.lt.u32 %p17, %r164, 3;
mov.u32 %r191, 0;
mov.u32 %r196, %r191;
@%p17 bra LBB68_26;

sub.s32 %r189, %r25, %r195;
mov.u32 %r191, 0;
mov.u32 %r186, __smem;
mov.u32 %r196, %r191;

LBB68_25:
ld.shared.u32 %r168, [%r186];
add.s32 %r169, %r168, %r196;
ld.shared.u32 %r170, [%r186+4];
add.s32 %r171, %r170, %r169;
ld.shared.u32 %r172, [%r186+8];
add.s32 %r173, %r172, %r171;
ld.shared.u32 %r174, [%r186+12];
add.s32 %r196, %r174, %r173;
add.s32 %r191, %r191, 4;
add.s32 %r186, %r186, 16;
add.s32 %r189, %r189, -4;
setp.ne.s32 %p18, %r189, 0;
@%p18 bra LBB68_25;

LBB68_26:
setp.eq.s32 %p19, %r195, 0;
@%p19 bra LBB68_29;

shl.b32 %r175, %r191, 2;
mov.u32 %r176, __smem;
add.s32 %r193, %r176, %r175;

LBB68_28:
.pragma "nounroll";
ld.shared.u32 %r177, [%r193];
add.s32 %r196, %r177, %r196;
add.s32 %r193, %r193, 4;
add.s32 %r195, %r195, -1;
setp.ne.s32 %p20, %r195, 0;
@%p20 bra LBB68_28;

LBB68_29:
mov.u32 %r178, %ctaid.x;
cvta.to.global.u64 %rd19, %rd4;
mul.wide.u32 %rd20, %r178, 4;
add.s64 %rd21, %rd19, %rd20;
st.global.u32 [%rd21], %r196;

LBB68_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<233>;
.reg .b64 %rd<22>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch[128];

ld.param.u64 %rd2, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r44, [_Z20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_j_param_2];
mov.u32 %r45, %tid.x;
mov.u32 %r46, %ntid.y;
mov.u32 %r47, %tid.z;
mov.u32 %r48, %tid.y;
mad.lo.s32 %r49, %r46, %r47, %r48;
mov.u32 %r50, %ntid.x;
mad.lo.s32 %r51, %r49, %r50, %r45;
setp.gt.u32 %p1, %r51, 15;
@%p1 bra LBB69_2;

shl.b32 %r59, %r51, 2;
mov.u32 %r60, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r61, %r60, %r59;
mov.u32 %r62, 0;
st.shared.u32 [%r61], %r62;

LBB69_2:
barrier.sync 0;
add.s32 %r63, %r44, -1;
and.b32 %r64, %r63, %r44;
setp.eq.s32 %p2, %r64, 0;
@%p2 bra LBB69_6;

mov.u32 %r66, %ctaid.x;
shl.b32 %r67, %r66, 9;
add.s32 %r215, %r67, %r45;
setp.ge.u32 %p3, %r215, %r44;
mov.u32 %r220, 0;
@%p3 bra LBB69_11;

cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r70, %nctaid.x;
shl.b32 %r2, %r70, 9;
mov.u32 %r220, 0;

LBB69_5:
mul.wide.u32 %rd4, %r215, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r71, [%rd5];
add.s32 %r220, %r71, %r220;
add.s32 %r215, %r215, %r2;
setp.lt.u32 %p4, %r215, %r44;
@%p4 bra LBB69_5;
bra.uni LBB69_11;

LBB69_6:
mov.u32 %r73, %ctaid.x;
shl.b32 %r74, %r73, 10;
add.s32 %r217, %r74, %r45;
setp.ge.u32 %p5, %r217, %r44;
mov.u32 %r220, 0;
@%p5 bra LBB69_11;

mov.u32 %r220, 0;
cvta.to.global.u64 %rd6, %rd2;
cvt.u64.u32 %rd11, %r44;

LBB69_8:
cvt.u64.u32 %rd7, %r217;
mul.wide.u32 %rd8, %r217, 4;
add.s64 %rd9, %rd6, %rd8;
ld.global.u32 %r81, [%rd9];
add.s32 %r220, %r81, %r220;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd11;
@%p6 bra LBB69_10;

add.s32 %r83, %r217, %r50;
mul.wide.u32 %rd13, %r83, 4;
add.s64 %rd14, %rd6, %rd13;
ld.global.u32 %r84, [%rd14];
add.s32 %r220, %r84, %r220;

LBB69_10:
mov.u32 %r85, %nctaid.x;
shl.b32 %r86, %r85, 10;
add.s32 %r217, %r217, %r86;
setp.lt.u32 %p7, %r217, %r44;
@%p7 bra LBB69_8;

LBB69_11:
shr.u32 %r94, %r51, 3;
and.b32 %r95, %r94, 536870908;
mov.u32 %r96, _ZZ20multi_warp_cg_reduceIiLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r97, %r96, %r95;
mov.u32 %r98, -1;
redux.sync.add.s32 %r99, %r220, %r98;
mov.u32 %r87, 0;
st.shared.u32 [%r97+64], %r99;
and.b32 %r16, %r51, 31;
setp.ne.s32 %p8, %r16, 0;
bar.warp.sync -1;
mov.u32 %r221, %r87;
@%p8 bra LBB69_13;

shr.u32 %r109, %r51, 8;
mul.wide.u32 %rd16, %r109, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r96;
cvta.shared.u64 %rd17, %tmp; }
add.s64 %rd18, %rd17, %rd16;
add.s64 %rd15, %rd18, 8;
mov.u32 %r101, 1;

	atom.add.release.gpu.u32 %r221,[%rd15],%r101;


LBB69_13:
mov.u32 %r111, 31;
shfl.sync.idx.b32 %r19|%p9, %r221, %r87, %r111, %r98;
add.s32 %r114, %r19, 1;
and.b32 %r115, %r114, 2147483647;
setp.eq.s32 %p10, %r115, 8;
shr.u32 %r116, %r51, 6;
and.b32 %r117, %r116, 67108860;
add.s32 %r20, %r96, %r117;
@%p10 bra LBB69_15;
bra.uni LBB69_14;

LBB69_15:
and.b32 %r128, %r51, 24;
setp.ne.s32 %p12, %r128, 0;
@%p12 bra LBB69_17;

and.b32 %r139, %r51, 7;
and.b32 %r140, %r51, -256;
shr.u32 %r141, %r140, 5;
or.b32 %r142, %r141, %r139;
shl.b32 %r143, %r142, 2;
mov.u32 %r144, 2;
add.s32 %r146, %r96, %r143;
ld.shared.u32 %r147, [%r146+64];

	mov.u32 %r129, %laneid;

	and.b32 %r148, %r129, -8;
mov.u32 %r149, 255;
shl.b32 %r150, %r149, %r148;
mov.u32 %r151, 6175;
mov.u32 %r152, 4;
shfl.sync.bfly.b32 %r153|%p13, %r147, %r152, %r151, %r150;
add.s32 %r154, %r153, %r147;

	mov.u32 %r130, %laneid;

	and.b32 %r155, %r130, -8;
shl.b32 %r156, %r149, %r155;
shfl.sync.bfly.b32 %r157|%p14, %r154, %r144, %r151, %r156;
add.s32 %r158, %r157, %r154;

	mov.u32 %r131, %laneid;

	and.b32 %r159, %r131, -8;
shl.b32 %r160, %r149, %r159;
mov.u32 %r161, 1;
shfl.sync.bfly.b32 %r162|%p15, %r158, %r161, %r151, %r160;
add.s32 %r163, %r162, %r158;
st.shared.u32 [%r146+64], %r163;

LBB69_17:
bar.warp.sync -1;
@%p8 bra LBB69_19;

ld.volatile.shared.u32 %r164, [%r20+8];
not.b32 %r165, %r164;
and.b32 %r166, %r165, -2147483648;
st.volatile.shared.u32 [%r20+8], %r166;
bra.uni LBB69_19;

LBB69_14:
ld.volatile.shared.u32 %r119, [%r20+8];
xor.b32 %r120, %r119, %r19;
setp.gt.s32 %p11, %r120, -1;
@%p11 bra LBB69_14;

LBB69_19:
ld.shared.u32 %r21, [%r97+64];
bar.warp.sync -1;
and.b32 %r178, %r51, 255;
setp.ne.s32 %p17, %r178, 0;
@%p17 bra LBB69_21;

mov.u32 %r188, __smem;
add.s32 %r189, %r188, %r117;
st.shared.u32 [%r189], %r21;

LBB69_21:
barrier.sync 0;
setp.ne.s32 %p18, %r45, 0;
@%p18 bra LBB69_30;

mul.lo.s32 %r194, %r50, %r46;
mov.u32 %r195, %ntid.z;
mad.lo.s32 %r196, %r194, %r195, 255;
shr.u32 %r22, %r196, 8;
setp.eq.s32 %p19, %r22, 0;
mov.u32 %r232, 0;
@%p19 bra LBB69_29;

add.s32 %r200, %r22, -1;
and.b32 %r231, %r22, 3;
setp.lt.u32 %p20, %r200, 3;
mov.u32 %r227, 0;
mov.u32 %r232, %r227;
@%p20 bra LBB69_26;

sub.s32 %r225, %r22, %r231;
mov.u32 %r227, 0;
mov.u32 %r222, __smem;
mov.u32 %r232, %r227;

LBB69_25:
ld.shared.u32 %r204, [%r222];
add.s32 %r205, %r204, %r232;
ld.shared.u32 %r206, [%r222+4];
add.s32 %r207, %r206, %r205;
ld.shared.u32 %r208, [%r222+8];
add.s32 %r209, %r208, %r207;
ld.shared.u32 %r210, [%r222+12];
add.s32 %r232, %r210, %r209;
add.s32 %r227, %r227, 4;
add.s32 %r222, %r222, 16;
add.s32 %r225, %r225, -4;
setp.ne.s32 %p21, %r225, 0;
@%p21 bra LBB69_25;

LBB69_26:
setp.eq.s32 %p22, %r231, 0;
@%p22 bra LBB69_29;

shl.b32 %r211, %r227, 2;
mov.u32 %r212, __smem;
add.s32 %r229, %r212, %r211;

LBB69_28:
.pragma "nounroll";
ld.shared.u32 %r213, [%r229];
add.s32 %r232, %r213, %r232;
add.s32 %r229, %r229, 4;
add.s32 %r231, %r231, -1;
setp.ne.s32 %p23, %r231, 0;
@%p23 bra LBB69_28;

LBB69_29:
mov.u32 %r214, %ctaid.x;
cvta.to.global.u64 %rd19, %rd3;
mul.wide.u32 %rd20, %r214, 4;
add.s64 %rd21, %rd19, %rd20;
st.global.u32 [%rd21], %r232;

LBB69_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<23>;
.reg .b32 %r<207>;
.reg .b64 %rd<22>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd2, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r45, [_Z20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_j_param_2];
mov.u32 %r46, %tid.x;
mov.u32 %r47, %ntid.y;
mov.u32 %r48, %tid.z;
mov.u32 %r49, %tid.y;
mad.lo.s32 %r50, %r47, %r48, %r49;
mov.u32 %r51, %ntid.x;
mad.lo.s32 %r52, %r50, %r51, %r46;
setp.gt.u32 %p1, %r52, 7;
@%p1 bra LBB70_2;

shl.b32 %r60, %r52, 2;
mov.u32 %r61, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r62, %r61, %r60;
mov.u32 %r63, 0;
st.shared.u32 [%r62], %r63;

LBB70_2:
barrier.sync 0;
add.s32 %r64, %r45, -1;
and.b32 %r65, %r64, %r45;
setp.eq.s32 %p2, %r65, 0;
@%p2 bra LBB70_6;

mov.u32 %r67, %ctaid.x;
shl.b32 %r68, %r67, 8;
add.s32 %r189, %r68, %r46;
setp.ge.u32 %p3, %r189, %r45;
mov.u32 %r194, 0;
@%p3 bra LBB70_11;

cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r71, %nctaid.x;
shl.b32 %r2, %r71, 8;
mov.u32 %r194, 0;

LBB70_5:
mul.wide.u32 %rd4, %r189, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.u32 %r72, [%rd5];
add.s32 %r194, %r72, %r194;
add.s32 %r189, %r189, %r2;
setp.lt.u32 %p4, %r189, %r45;
@%p4 bra LBB70_5;
bra.uni LBB70_11;

LBB70_6:
mov.u32 %r74, %ctaid.x;
shl.b32 %r75, %r74, 9;
add.s32 %r191, %r75, %r46;
setp.ge.u32 %p5, %r191, %r45;
mov.u32 %r194, 0;
@%p5 bra LBB70_11;

mov.u32 %r194, 0;
cvta.to.global.u64 %rd6, %rd2;
cvt.u64.u32 %rd11, %r45;

LBB70_8:
cvt.u64.u32 %rd7, %r191;
mul.wide.u32 %rd8, %r191, 4;
add.s64 %rd9, %rd6, %rd8;
ld.global.u32 %r82, [%rd9];
add.s32 %r194, %r82, %r194;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd11;
@%p6 bra LBB70_10;

add.s32 %r84, %r191, %r51;
mul.wide.u32 %rd13, %r84, 4;
add.s64 %rd14, %rd6, %rd13;
ld.global.u32 %r85, [%rd14];
add.s32 %r194, %r85, %r194;

LBB70_10:
mov.u32 %r86, %nctaid.x;
shl.b32 %r87, %r86, 9;
add.s32 %r191, %r191, %r87;
setp.lt.u32 %p7, %r191, %r45;
@%p7 bra LBB70_8;

LBB70_11:
shr.u32 %r15, %r52, 7;
shr.u32 %r96, %r52, 3;
and.b32 %r97, %r96, 536870908;
mov.u32 %r98, _ZZ20multi_warp_cg_reduceIiLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r16, %r98, %r97;
mov.u32 %r99, -1;
redux.sync.add.s32 %r100, %r194, %r99;
mov.u32 %r88, 0;
st.shared.u32 [%r16+32], %r100;
and.b32 %r17, %r52, 31;
setp.ne.s32 %p8, %r17, 0;
bar.warp.sync -1;
mov.u32 %r195, %r88;
@%p8 bra LBB70_13;

mul.wide.u32 %rd16, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r98;
cvta.shared.u64 %rd17, %tmp; }
add.s64 %rd18, %rd17, %rd16;
add.s64 %rd15, %rd18, 8;
mov.u32 %r102, 1;

	atom.add.release.gpu.u32 %r195,[%rd15],%r102;


LBB70_13:
mov.u32 %r104, 31;
shfl.sync.idx.b32 %r20|%p9, %r195, %r88, %r104, %r99;
add.s32 %r107, %r20, 1;
and.b32 %r108, %r107, 2147483647;
setp.eq.s32 %p10, %r108, 4;
shl.b32 %r109, %r15, 2;
add.s32 %r21, %r98, %r109;
@%p10 bra LBB70_15;
bra.uni LBB70_14;

LBB70_15:
and.b32 %r120, %r52, 28;
setp.ne.s32 %p12, %r120, 0;
@%p12 bra LBB70_17;

and.b32 %r130, %r52, 3;
and.b32 %r131, %r52, -128;
shr.u32 %r132, %r131, 5;
or.b32 %r133, %r132, %r130;
shl.b32 %r134, %r133, 2;
mov.u32 %r135, 2;
add.s32 %r137, %r98, %r134;
ld.shared.u32 %r138, [%r137+32];

	mov.u32 %r121, %laneid;

	and.b32 %r139, %r121, -4;
mov.u32 %r140, 15;
shl.b32 %r141, %r140, %r139;
mov.u32 %r142, 7199;
shfl.sync.bfly.b32 %r143|%p13, %r138, %r135, %r142, %r141;
add.s32 %r144, %r143, %r138;

	mov.u32 %r122, %laneid;

	and.b32 %r145, %r122, -4;
shl.b32 %r146, %r140, %r145;
mov.u32 %r147, 1;
shfl.sync.bfly.b32 %r148|%p14, %r144, %r147, %r142, %r146;
add.s32 %r149, %r148, %r144;
st.shared.u32 [%r137+32], %r149;

LBB70_17:
bar.warp.sync -1;
@%p8 bra LBB70_19;

ld.volatile.shared.u32 %r150, [%r21+8];
not.b32 %r151, %r150;
and.b32 %r152, %r151, -2147483648;
st.volatile.shared.u32 [%r21+8], %r152;
bra.uni LBB70_19;

LBB70_14:
ld.volatile.shared.u32 %r111, [%r21+8];
xor.b32 %r112, %r111, %r20;
setp.gt.s32 %p11, %r112, -1;
@%p11 bra LBB70_14;

LBB70_19:
ld.shared.u32 %r22, [%r16+32];
bar.warp.sync -1;
and.b32 %r160, %r52, 127;
setp.ne.s32 %p16, %r160, 0;
@%p16 bra LBB70_21;

mov.u32 %r162, __smem;
add.s32 %r163, %r162, %r109;
st.shared.u32 [%r163], %r22;

LBB70_21:
barrier.sync 0;
setp.ne.s32 %p17, %r46, 0;
@%p17 bra LBB70_30;

mul.lo.s32 %r168, %r51, %r47;
mov.u32 %r169, %ntid.z;
mad.lo.s32 %r170, %r168, %r169, 127;
shr.u32 %r23, %r170, 7;
setp.eq.s32 %p18, %r23, 0;
mov.u32 %r206, 0;
@%p18 bra LBB70_29;

add.s32 %r174, %r23, -1;
and.b32 %r205, %r23, 3;
setp.lt.u32 %p19, %r174, 3;
mov.u32 %r201, 0;
mov.u32 %r206, %r201;
@%p19 bra LBB70_26;

sub.s32 %r199, %r23, %r205;
mov.u32 %r201, 0;
mov.u32 %r196, __smem;
mov.u32 %r206, %r201;

LBB70_25:
ld.shared.u32 %r178, [%r196];
add.s32 %r179, %r178, %r206;
ld.shared.u32 %r180, [%r196+4];
add.s32 %r181, %r180, %r179;
ld.shared.u32 %r182, [%r196+8];
add.s32 %r183, %r182, %r181;
ld.shared.u32 %r184, [%r196+12];
add.s32 %r206, %r184, %r183;
add.s32 %r201, %r201, 4;
add.s32 %r196, %r196, 16;
add.s32 %r199, %r199, -4;
setp.ne.s32 %p20, %r199, 0;
@%p20 bra LBB70_25;

LBB70_26:
setp.eq.s32 %p21, %r205, 0;
@%p21 bra LBB70_29;

shl.b32 %r185, %r201, 2;
mov.u32 %r186, __smem;
add.s32 %r203, %r186, %r185;

LBB70_28:
.pragma "nounroll";
ld.shared.u32 %r187, [%r203];
add.s32 %r206, %r187, %r206;
add.s32 %r203, %r203, 4;
add.s32 %r205, %r205, -1;
setp.ne.s32 %p22, %r205, 0;
@%p22 bra LBB70_28;

LBB70_29:
mov.u32 %r188, %ctaid.x;
cvta.to.global.u64 %rd19, %rd3;
mul.wide.u32 %rd20, %r188, 4;
add.s64 %rd21, %rd19, %rd20;
st.global.u32 [%rd21], %r206;

LBB70_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<22>;
.reg .b32 %r<200>;
.reg .b64 %rd<22>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch[32];

ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r47, [_Z20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_j_param_2];
mov.u32 %r48, %tid.x;
mov.u32 %r49, %ntid.y;
mov.u32 %r50, %tid.z;
mov.u32 %r51, %tid.y;
mad.lo.s32 %r52, %r49, %r50, %r51;
mov.u32 %r53, %ntid.x;
mad.lo.s32 %r54, %r52, %r53, %r48;
setp.gt.u32 %p1, %r54, 3;
@%p1 bra LBB71_2;

shl.b32 %r62, %r54, 2;
mov.u32 %r63, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r64, %r63, %r62;
mov.u32 %r65, 0;
st.shared.u32 [%r64], %r65;

LBB71_2:
barrier.sync 0;
mov.u32 %r1, %nctaid.x;
add.s32 %r66, %r47, -1;
and.b32 %r67, %r66, %r47;
setp.eq.s32 %p2, %r67, 0;
@%p2 bra LBB71_6;

mov.u32 %r69, %ctaid.x;
shl.b32 %r70, %r69, 7;
add.s32 %r182, %r70, %r48;
setp.ge.u32 %p3, %r182, %r47;
mov.u32 %r187, 0;
@%p3 bra LBB71_11;

cvta.to.global.u64 %rd1, %rd3;
shl.b32 %r3, %r1, 7;
mov.u32 %r187, 0;

LBB71_5:
mul.wide.u32 %rd5, %r182, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r73, [%rd6];
add.s32 %r187, %r73, %r187;
add.s32 %r182, %r182, %r3;
setp.lt.u32 %p4, %r182, %r47;
@%p4 bra LBB71_5;
bra.uni LBB71_11;

LBB71_6:
mov.u32 %r75, %ctaid.x;
shl.b32 %r76, %r75, 8;
add.s32 %r184, %r76, %r48;
setp.ge.u32 %p5, %r184, %r47;
mov.u32 %r187, 0;
@%p5 bra LBB71_11;

cvta.to.global.u64 %rd2, %rd3;
shl.b32 %r9, %r1, 8;
mov.u32 %r187, 0;
cvt.u64.u32 %rd11, %r47;

LBB71_8:
cvt.u64.u32 %rd7, %r184;
mul.wide.u32 %rd8, %r184, 4;
add.s64 %rd9, %rd2, %rd8;
ld.global.u32 %r83, [%rd9];
add.s32 %r187, %r83, %r187;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd11;
@%p6 bra LBB71_10;

add.s32 %r85, %r184, %r53;
mul.wide.u32 %rd13, %r85, 4;
add.s64 %rd14, %rd2, %rd13;
ld.global.u32 %r86, [%rd14];
add.s32 %r187, %r86, %r187;

LBB71_10:
add.s32 %r184, %r184, %r9;
setp.lt.u32 %p7, %r184, %r47;
@%p7 bra LBB71_8;

LBB71_11:
shr.u32 %r17, %r54, 6;
shr.u32 %r95, %r54, 3;
and.b32 %r96, %r95, 536870908;
mov.u32 %r97, _ZZ20multi_warp_cg_reduceIiLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r18, %r97, %r96;
mov.u32 %r98, -1;
redux.sync.add.s32 %r99, %r187, %r98;
mov.u32 %r87, 0;
st.shared.u32 [%r18+16], %r99;
and.b32 %r19, %r54, 31;
setp.ne.s32 %p8, %r19, 0;
bar.warp.sync -1;
mov.u32 %r188, %r87;
@%p8 bra LBB71_13;

mul.wide.u32 %rd16, %r17, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r97;
cvta.shared.u64 %rd17, %tmp; }
add.s64 %rd18, %rd17, %rd16;
add.s64 %rd15, %rd18, 8;
mov.u32 %r101, 1;

	atom.add.release.gpu.u32 %r188,[%rd15],%r101;


LBB71_13:
mov.u32 %r103, 31;
shfl.sync.idx.b32 %r22|%p9, %r188, %r87, %r103, %r98;
add.s32 %r106, %r22, 1;
and.b32 %r107, %r106, 2147483647;
setp.eq.s32 %p10, %r107, 2;
shl.b32 %r108, %r17, 2;
add.s32 %r23, %r97, %r108;
@%p10 bra LBB71_15;
bra.uni LBB71_14;

LBB71_15:
and.b32 %r119, %r54, 30;
setp.ne.s32 %p12, %r119, 0;
@%p12 bra LBB71_17;

and.b32 %r128, %r54, 1;
mov.u32 %r129, 1;
and.b32 %r130, %r54, -64;
shr.u32 %r131, %r130, 5;
or.b32 %r132, %r131, %r128;
shl.b32 %r133, %r132, 2;
add.s32 %r135, %r97, %r133;
ld.shared.u32 %r136, [%r135+16];

	mov.u32 %r120, %laneid;

	and.b32 %r137, %r120, -2;
mov.u32 %r138, 3;
shl.b32 %r139, %r138, %r137;
mov.u32 %r140, 7711;
shfl.sync.bfly.b32 %r141|%p13, %r136, %r129, %r140, %r139;
add.s32 %r142, %r141, %r136;
st.shared.u32 [%r135+16], %r142;

LBB71_17:
bar.warp.sync -1;
@%p8 bra LBB71_19;

ld.volatile.shared.u32 %r143, [%r23+8];
not.b32 %r144, %r143;
and.b32 %r145, %r144, -2147483648;
st.volatile.shared.u32 [%r23+8], %r145;
bra.uni LBB71_19;

LBB71_14:
ld.volatile.shared.u32 %r110, [%r23+8];
xor.b32 %r111, %r110, %r22;
setp.gt.s32 %p11, %r111, -1;
@%p11 bra LBB71_14;

LBB71_19:
ld.shared.u32 %r24, [%r18+16];
bar.warp.sync -1;
and.b32 %r153, %r54, 63;
setp.ne.s32 %p15, %r153, 0;
@%p15 bra LBB71_21;

mov.u32 %r155, __smem;
add.s32 %r156, %r155, %r108;
st.shared.u32 [%r156], %r24;

LBB71_21:
barrier.sync 0;
setp.ne.s32 %p16, %r48, 0;
@%p16 bra LBB71_30;

mul.lo.s32 %r161, %r53, %r49;
mov.u32 %r162, %ntid.z;
mad.lo.s32 %r163, %r161, %r162, 63;
shr.u32 %r25, %r163, 6;
setp.eq.s32 %p17, %r25, 0;
mov.u32 %r199, 0;
@%p17 bra LBB71_29;

add.s32 %r167, %r25, -1;
and.b32 %r198, %r25, 3;
setp.lt.u32 %p18, %r167, 3;
mov.u32 %r194, 0;
mov.u32 %r199, %r194;
@%p18 bra LBB71_26;

sub.s32 %r192, %r25, %r198;
mov.u32 %r194, 0;
mov.u32 %r189, __smem;
mov.u32 %r199, %r194;

LBB71_25:
ld.shared.u32 %r171, [%r189];
add.s32 %r172, %r171, %r199;
ld.shared.u32 %r173, [%r189+4];
add.s32 %r174, %r173, %r172;
ld.shared.u32 %r175, [%r189+8];
add.s32 %r176, %r175, %r174;
ld.shared.u32 %r177, [%r189+12];
add.s32 %r199, %r177, %r176;
add.s32 %r194, %r194, 4;
add.s32 %r189, %r189, 16;
add.s32 %r192, %r192, -4;
setp.ne.s32 %p19, %r192, 0;
@%p19 bra LBB71_25;

LBB71_26:
setp.eq.s32 %p20, %r198, 0;
@%p20 bra LBB71_29;

shl.b32 %r178, %r194, 2;
mov.u32 %r179, __smem;
add.s32 %r196, %r179, %r178;

LBB71_28:
.pragma "nounroll";
ld.shared.u32 %r180, [%r196];
add.s32 %r199, %r180, %r199;
add.s32 %r196, %r196, 4;
add.s32 %r198, %r198, -1;
setp.ne.s32 %p21, %r198, 0;
@%p21 bra LBB71_28;

LBB71_29:
mov.u32 %r181, %ctaid.x;
cvta.to.global.u64 %rd19, %rd4;
mul.wide.u32 %rd20, %r181, 4;
add.s64 %rd21, %rd19, %rd20;
st.global.u32 [%rd21], %r199;

LBB71_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .b32 %r<117>;
.reg .b64 %rd<18>;


ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r41, [_Z20multi_warp_cg_reduceIiLm64ELm32EEvPT_S1_j_param_2];
mov.u32 %r42, %tid.x;
mov.u32 %r43, %ntid.y;
mov.u32 %r44, %tid.z;
mov.u32 %r45, %tid.y;
mad.lo.s32 %r46, %r43, %r44, %r45;
mov.u32 %r47, %ntid.x;
mad.lo.s32 %r1, %r46, %r47, %r42;
barrier.sync 0;
mov.u32 %r2, %nctaid.x;
add.s32 %r48, %r41, -1;
and.b32 %r49, %r48, %r41;
setp.eq.s32 %p1, %r49, 0;
@%p1 bra LBB72_4;

mov.u32 %r51, %ctaid.x;
shl.b32 %r52, %r51, 6;
add.s32 %r100, %r52, %r42;
setp.ge.u32 %p2, %r100, %r41;
mov.u32 %r105, 0;
@%p2 bra LBB72_9;

cvta.to.global.u64 %rd1, %rd3;
shl.b32 %r4, %r2, 6;
mov.u32 %r105, 0;

LBB72_3:
mul.wide.u32 %rd5, %r100, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.u32 %r55, [%rd6];
add.s32 %r105, %r55, %r105;
add.s32 %r100, %r100, %r4;
setp.lt.u32 %p3, %r100, %r41;
@%p3 bra LBB72_3;
bra.uni LBB72_9;

LBB72_4:
mov.u32 %r57, %ctaid.x;
shl.b32 %r58, %r57, 7;
add.s32 %r102, %r58, %r42;
setp.ge.u32 %p4, %r102, %r41;
mov.u32 %r105, 0;
@%p4 bra LBB72_9;

cvta.to.global.u64 %rd2, %rd3;
shl.b32 %r10, %r2, 7;
mov.u32 %r105, 0;
cvt.u64.u32 %rd11, %r41;

LBB72_6:
cvt.u64.u32 %rd7, %r102;
mul.wide.u32 %rd8, %r102, 4;
add.s64 %rd9, %rd2, %rd8;
ld.global.u32 %r65, [%rd9];
add.s32 %r105, %r65, %r105;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd11;
@%p5 bra LBB72_8;

add.s32 %r67, %r102, %r47;
mul.wide.u32 %rd13, %r67, 4;
add.s64 %rd14, %rd2, %rd13;
ld.global.u32 %r68, [%rd14];
add.s32 %r105, %r68, %r105;

LBB72_8:
add.s32 %r102, %r102, %r10;
setp.lt.u32 %p6, %r102, %r41;
@%p6 bra LBB72_6;

LBB72_9:
mov.u32 %r69, -1;
redux.sync.add.s32 %r18, %r105, %r69;
and.b32 %r70, %r1, 31;
setp.ne.s32 %p7, %r70, 0;
@%p7 bra LBB72_11;

shr.u32 %r71, %r1, 3;
and.b32 %r72, %r71, 536870908;
mov.u32 %r73, __smem;
add.s32 %r74, %r73, %r72;
st.shared.u32 [%r74], %r18;

LBB72_11:
barrier.sync 0;
setp.ne.s32 %p8, %r42, 0;
@%p8 bra LBB72_20;

mul.lo.s32 %r79, %r47, %r43;
mov.u32 %r80, %ntid.z;
mad.lo.s32 %r81, %r79, %r80, 31;
shr.u32 %r19, %r81, 5;
setp.eq.s32 %p9, %r19, 0;
mov.u32 %r116, 0;
@%p9 bra LBB72_19;

add.s32 %r85, %r19, -1;
and.b32 %r115, %r19, 3;
setp.lt.u32 %p10, %r85, 3;
mov.u32 %r111, 0;
mov.u32 %r116, %r111;
@%p10 bra LBB72_16;

sub.s32 %r109, %r19, %r115;
mov.u32 %r111, 0;
mov.u32 %r106, __smem;
mov.u32 %r116, %r111;

LBB72_15:
ld.shared.u32 %r89, [%r106];
add.s32 %r90, %r89, %r116;
ld.shared.u32 %r91, [%r106+4];
add.s32 %r92, %r91, %r90;
ld.shared.u32 %r93, [%r106+8];
add.s32 %r94, %r93, %r92;
ld.shared.u32 %r95, [%r106+12];
add.s32 %r116, %r95, %r94;
add.s32 %r111, %r111, 4;
add.s32 %r106, %r106, 16;
add.s32 %r109, %r109, -4;
setp.ne.s32 %p11, %r109, 0;
@%p11 bra LBB72_15;

LBB72_16:
setp.eq.s32 %p12, %r115, 0;
@%p12 bra LBB72_19;

shl.b32 %r96, %r111, 2;
mov.u32 %r97, __smem;
add.s32 %r113, %r97, %r96;

LBB72_18:
.pragma "nounroll";
ld.shared.u32 %r98, [%r113];
add.s32 %r116, %r98, %r116;
add.s32 %r113, %r113, 4;
add.s32 %r115, %r115, -1;
setp.ne.s32 %p13, %r115, 0;
@%p13 bra LBB72_18;

LBB72_19:
mov.u32 %r99, %ctaid.x;
cvta.to.global.u64 %rd15, %rd4;
mul.wide.u32 %rd16, %r99, 4;
add.s64 %rd17, %rd15, %rd16;
st.global.u32 [%rd17], %r116;

LBB72_20:
ret;

}

.visible .entry _Z7reduce0IfEvPT_S1_j(
.param .u64 _Z7reduce0IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<17>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IfEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce0IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r9;
mov.f32 %f8, 0f00000000;
@%p1 bra LBB73_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

LBB73_2:
shl.b32 %r10, %r3, 2;
mov.u32 %r11, __smem;
add.s32 %r6, %r11, %r10;
st.shared.f32 [%r6], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB73_7;

mov.u32 %r16, 1;

LBB73_4:
shl.b32 %r8, %r16, 1;
rem.u32 %r13, %r3, %r8;
setp.ne.s32 %p3, %r13, 0;
@%p3 bra LBB73_6;

shl.b32 %r14, %r16, 2;
add.s32 %r15, %r6, %r14;
ld.shared.f32 %f4, [%r6];
ld.shared.f32 %f5, [%r15];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r6], %f6;

LBB73_6:
barrier.sync 0;
setp.lt.u32 %p4, %r8, %r1;
mov.u32 %r16, %r8;
@%p4 bra LBB73_4;

LBB73_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB73_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

LBB73_9:
ret;

}

.visible .entry _Z7reduce1IfEvPT_S1_j(
.param .u64 _Z7reduce1IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IfEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .f32 %f<9>;
.reg .b32 %r<20>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IfEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IfEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f32 %f8, 0f00000000;
@%p1 bra LBB74_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f8, [%rd5];

LBB74_2:
shl.b32 %r9, %r3, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB74_7;

mov.u32 %r19, 1;

LBB74_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra LBB74_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 2;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 2;
add.s32 %r18, %r10, %r17;
ld.shared.f32 %f4, [%r18];
ld.shared.f32 %f5, [%r16];
add.f32 %f6, %f5, %f4;
st.shared.f32 [%r18], %f6;

LBB74_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra LBB74_4;

LBB74_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB74_9;

ld.shared.f32 %f7, [__smem];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f7;

LBB74_9:
ret;

}

.visible .entry _Z7reduce3IfEvPT_S1_j(
.param .u64 _Z7reduce3IfEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IfEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IfEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .f32 %f<17>;
.reg .b32 %r<18>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IfEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IfEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z7reduce3IfEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r12, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r12, %r2, %r3;
setp.ge.u32 %p1, %r4, %r11;
mov.f32 %f15, 0f00000000;
@%p1 bra LBB75_2;

mul.wide.u32 %rd4, %r4, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f15, [%rd5];

LBB75_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r11;
@%p2 bra LBB75_4;

mul.wide.u32 %rd6, %r5, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.f32 %f10, [%rd7];
add.f32 %f15, %f15, %f10;

LBB75_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r7, %r14, %r13;
st.shared.f32 [%r7], %f15;
barrier.sync 0;
shr.u32 %r17, %r1, 1;
setp.eq.s32 %p3, %r17, 0;
@%p3 bra LBB75_8;

LBB75_5:
setp.ge.u32 %p4, %r3, %r17;
@%p4 bra LBB75_7;

shl.b32 %r15, %r17, 2;
add.s32 %r16, %r7, %r15;
ld.shared.f32 %f11, [%r16];
add.f32 %f15, %f15, %f11;
st.shared.f32 [%r7], %f15;

LBB75_7:
barrier.sync 0;
shr.u32 %r17, %r17, 1;
setp.ne.s32 %p5, %r17, 0;
@%p5 bra LBB75_5;

LBB75_8:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra LBB75_10;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f15;

LBB75_10:
ret;

}

.visible .entry _Z7reduce4IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce4IfLj512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r9, %ntid.x;
shl.b32 %r10, %r9, 1;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r1, %r10, %r11, %r12;
setp.ge.u32 %p1, %r1, %r8;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra LBB76_2;

ld.global.f32 %f28, [%rd1];

LBB76_2:
add.s32 %r13, %r1, 512;
setp.ge.u32 %p2, %r13, %r8;
@%p2 bra LBB76_4;

ld.global.f32 %f12, [%rd1+2048];
add.f32 %f28, %f28, %f12;

LBB76_4:
shl.b32 %r15, %r12, 2;
mov.u32 %r16, __smem;
add.s32 %r3, %r16, %r15;
st.shared.f32 [%r3], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r9, 66;
@%p3 bra LBB76_9;

mov.u32 %r45, %r9;

LBB76_6:
shr.u32 %r6, %r45, 1;
setp.ge.u32 %p4, %r12, %r6;
@%p4 bra LBB76_8;

shl.b32 %r19, %r6, 2;
add.s32 %r20, %r3, %r19;
ld.shared.f32 %f13, [%r20];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r3], %f28;

LBB76_8:
barrier.sync 0;
setp.gt.u32 %p5, %r45, 131;
mov.u32 %r45, %r6;
@%p5 bra LBB76_6;

LBB76_9:
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mad.lo.s32 %r7, %r24, %r9, %r12;
setp.gt.u32 %p6, %r7, 31;
@%p6 bra LBB76_11;

ld.shared.f32 %f14, [%r3+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 2;
mov.u32 %r29, 31;
mov.u32 %r30, 16;
mov.u32 %r31, -1;
shfl.sync.down.b32 %r32|%p7, %r27, %r30, %r29, %r31;
mov.b32 %f16, %r32;
add.f32 %f17, %f15, %f16;
mov.b32 %r33, %f17;
mov.u32 %r34, 8;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r29, %r31;
mov.b32 %f18, %r35;
add.f32 %f19, %f17, %f18;
mov.b32 %r36, %f19;
mov.u32 %r37, 4;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r29, %r31;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
shfl.sync.down.b32 %r40|%p10, %r39, %r28, %r29, %r31;
mov.b32 %f22, %r40;
add.f32 %f23, %f21, %f22;
mov.b32 %r41, %f23;
mov.u32 %r42, 1;
shfl.sync.down.b32 %r43|%p11, %r41, %r42, %r29, %r31;
mov.b32 %f24, %r43;
add.f32 %f28, %f23, %f24;

LBB76_11:
setp.ne.s32 %p12, %r7, 0;
@%p12 bra LBB76_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r11, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

LBB76_13:
ret;

}

.visible .entry _Z7reduce4IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce4IfLj256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r9, %ntid.x;
shl.b32 %r10, %r9, 1;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r1, %r10, %r11, %r12;
setp.ge.u32 %p1, %r1, %r8;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra LBB77_2;

ld.global.f32 %f28, [%rd1];

LBB77_2:
add.s32 %r13, %r1, 256;
setp.ge.u32 %p2, %r13, %r8;
@%p2 bra LBB77_4;

ld.global.f32 %f12, [%rd1+1024];
add.f32 %f28, %f28, %f12;

LBB77_4:
shl.b32 %r15, %r12, 2;
mov.u32 %r16, __smem;
add.s32 %r3, %r16, %r15;
st.shared.f32 [%r3], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r9, 66;
@%p3 bra LBB77_9;

mov.u32 %r45, %r9;

LBB77_6:
shr.u32 %r6, %r45, 1;
setp.ge.u32 %p4, %r12, %r6;
@%p4 bra LBB77_8;

shl.b32 %r19, %r6, 2;
add.s32 %r20, %r3, %r19;
ld.shared.f32 %f13, [%r20];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r3], %f28;

LBB77_8:
barrier.sync 0;
setp.gt.u32 %p5, %r45, 131;
mov.u32 %r45, %r6;
@%p5 bra LBB77_6;

LBB77_9:
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mad.lo.s32 %r7, %r24, %r9, %r12;
setp.gt.u32 %p6, %r7, 31;
@%p6 bra LBB77_11;

ld.shared.f32 %f14, [%r3+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 2;
mov.u32 %r29, 31;
mov.u32 %r30, 16;
mov.u32 %r31, -1;
shfl.sync.down.b32 %r32|%p7, %r27, %r30, %r29, %r31;
mov.b32 %f16, %r32;
add.f32 %f17, %f15, %f16;
mov.b32 %r33, %f17;
mov.u32 %r34, 8;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r29, %r31;
mov.b32 %f18, %r35;
add.f32 %f19, %f17, %f18;
mov.b32 %r36, %f19;
mov.u32 %r37, 4;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r29, %r31;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
shfl.sync.down.b32 %r40|%p10, %r39, %r28, %r29, %r31;
mov.b32 %f22, %r40;
add.f32 %f23, %f21, %f22;
mov.b32 %r41, %f23;
mov.u32 %r42, 1;
shfl.sync.down.b32 %r43|%p11, %r41, %r42, %r29, %r31;
mov.b32 %f24, %r43;
add.f32 %f28, %f23, %f24;

LBB77_11:
setp.ne.s32 %p12, %r7, 0;
@%p12 bra LBB77_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r11, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

LBB77_13:
ret;

}

.visible .entry _Z7reduce4IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce4IfLj128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r9, %ntid.x;
shl.b32 %r10, %r9, 1;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r1, %r10, %r11, %r12;
setp.ge.u32 %p1, %r1, %r8;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra LBB78_2;

ld.global.f32 %f28, [%rd1];

LBB78_2:
add.s32 %r13, %r1, 128;
setp.ge.u32 %p2, %r13, %r8;
@%p2 bra LBB78_4;

ld.global.f32 %f12, [%rd1+512];
add.f32 %f28, %f28, %f12;

LBB78_4:
shl.b32 %r15, %r12, 2;
mov.u32 %r16, __smem;
add.s32 %r3, %r16, %r15;
st.shared.f32 [%r3], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r9, 66;
@%p3 bra LBB78_9;

mov.u32 %r45, %r9;

LBB78_6:
shr.u32 %r6, %r45, 1;
setp.ge.u32 %p4, %r12, %r6;
@%p4 bra LBB78_8;

shl.b32 %r19, %r6, 2;
add.s32 %r20, %r3, %r19;
ld.shared.f32 %f13, [%r20];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r3], %f28;

LBB78_8:
barrier.sync 0;
setp.gt.u32 %p5, %r45, 131;
mov.u32 %r45, %r6;
@%p5 bra LBB78_6;

LBB78_9:
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mad.lo.s32 %r7, %r24, %r9, %r12;
setp.gt.u32 %p6, %r7, 31;
@%p6 bra LBB78_11;

ld.shared.f32 %f14, [%r3+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 2;
mov.u32 %r29, 31;
mov.u32 %r30, 16;
mov.u32 %r31, -1;
shfl.sync.down.b32 %r32|%p7, %r27, %r30, %r29, %r31;
mov.b32 %f16, %r32;
add.f32 %f17, %f15, %f16;
mov.b32 %r33, %f17;
mov.u32 %r34, 8;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r29, %r31;
mov.b32 %f18, %r35;
add.f32 %f19, %f17, %f18;
mov.b32 %r36, %f19;
mov.u32 %r37, 4;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r29, %r31;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
shfl.sync.down.b32 %r40|%p10, %r39, %r28, %r29, %r31;
mov.b32 %f22, %r40;
add.f32 %f23, %f21, %f22;
mov.b32 %r41, %f23;
mov.u32 %r42, 1;
shfl.sync.down.b32 %r43|%p11, %r41, %r42, %r29, %r31;
mov.b32 %f24, %r43;
add.f32 %f28, %f23, %f24;

LBB78_11:
setp.ne.s32 %p12, %r7, 0;
@%p12 bra LBB78_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r11, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

LBB78_13:
ret;

}

.visible .entry _Z7reduce4IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<31>;
.reg .b32 %r<46>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce4IfLj64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r9, %ntid.x;
shl.b32 %r10, %r9, 1;
mov.u32 %r11, %ctaid.x;
mov.u32 %r12, %tid.x;
mad.lo.s32 %r1, %r10, %r11, %r12;
setp.ge.u32 %p1, %r1, %r8;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f28, 0f00000000;
@%p1 bra LBB79_2;

ld.global.f32 %f28, [%rd1];

LBB79_2:
add.s32 %r13, %r1, 64;
setp.ge.u32 %p2, %r13, %r8;
@%p2 bra LBB79_4;

ld.global.f32 %f12, [%rd1+256];
add.f32 %f28, %f28, %f12;

LBB79_4:
shl.b32 %r15, %r12, 2;
mov.u32 %r16, __smem;
add.s32 %r3, %r16, %r15;
st.shared.f32 [%r3], %f28;
barrier.sync 0;
setp.lt.u32 %p3, %r9, 66;
@%p3 bra LBB79_9;

mov.u32 %r45, %r9;

LBB79_6:
shr.u32 %r6, %r45, 1;
setp.ge.u32 %p4, %r12, %r6;
@%p4 bra LBB79_8;

shl.b32 %r19, %r6, 2;
add.s32 %r20, %r3, %r19;
ld.shared.f32 %f13, [%r20];
add.f32 %f28, %f28, %f13;
st.shared.f32 [%r3], %f28;

LBB79_8:
barrier.sync 0;
setp.gt.u32 %p5, %r45, 131;
mov.u32 %r45, %r6;
@%p5 bra LBB79_6;

LBB79_9:
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mad.lo.s32 %r7, %r24, %r9, %r12;
setp.gt.u32 %p6, %r7, 31;
@%p6 bra LBB79_11;

ld.shared.f32 %f14, [%r3+128];
add.f32 %f15, %f28, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 2;
mov.u32 %r29, 31;
mov.u32 %r30, 16;
mov.u32 %r31, -1;
shfl.sync.down.b32 %r32|%p7, %r27, %r30, %r29, %r31;
mov.b32 %f16, %r32;
add.f32 %f17, %f15, %f16;
mov.b32 %r33, %f17;
mov.u32 %r34, 8;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r29, %r31;
mov.b32 %f18, %r35;
add.f32 %f19, %f17, %f18;
mov.b32 %r36, %f19;
mov.u32 %r37, 4;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r29, %r31;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
shfl.sync.down.b32 %r40|%p10, %r39, %r28, %r29, %r31;
mov.b32 %f22, %r40;
add.f32 %f23, %f21, %f22;
mov.b32 %r41, %f23;
mov.u32 %r42, 1;
shfl.sync.down.b32 %r43|%p11, %r41, %r42, %r29, %r31;
mov.b32 %f24, %r43;
add.f32 %f28, %f23, %f24;

LBB79_11:
setp.ne.s32 %p12, %r7, 0;
@%p12 bra LBB79_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r11, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f28;

LBB79_13:
ret;

}

.visible .entry _Z7reduce4IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB80_2;

ld.global.f32 %f26, [%rd1];

LBB80_2:
add.s32 %r12, %r4, 32;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB80_4;

ld.global.f32 %f12, [%rd1+128];
add.f32 %f26, %f26, %f12;

LBB80_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB80_9;

mov.u32 %r38, %r1;

LBB80_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB80_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB80_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB80_6;

LBB80_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB80_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB80_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB80_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB80_13:
ret;

}

.visible .entry _Z7reduce4IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB81_2;

ld.global.f32 %f26, [%rd1];

LBB81_2:
add.s32 %r12, %r4, 16;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB81_4;

ld.global.f32 %f12, [%rd1+64];
add.f32 %f26, %f26, %f12;

LBB81_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB81_9;

mov.u32 %r38, %r1;

LBB81_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB81_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB81_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB81_6;

LBB81_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB81_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB81_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB81_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB81_13:
ret;

}

.visible .entry _Z7reduce4IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB82_2;

ld.global.f32 %f26, [%rd1];

LBB82_2:
add.s32 %r12, %r4, 8;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB82_4;

ld.global.f32 %f12, [%rd1+32];
add.f32 %f26, %f26, %f12;

LBB82_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB82_9;

mov.u32 %r38, %r1;

LBB82_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB82_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB82_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB82_6;

LBB82_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB82_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB82_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB82_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB82_13:
ret;

}

.visible .entry _Z7reduce4IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB83_2;

ld.global.f32 %f26, [%rd1];

LBB83_2:
add.s32 %r12, %r4, 4;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB83_4;

ld.global.f32 %f12, [%rd1+16];
add.f32 %f26, %f26, %f12;

LBB83_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB83_9;

mov.u32 %r38, %r1;

LBB83_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB83_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB83_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB83_6;

LBB83_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB83_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB83_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB83_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB83_13:
ret;

}

.visible .entry _Z7reduce4IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB84_2;

ld.global.f32 %f26, [%rd1];

LBB84_2:
add.s32 %r12, %r4, 2;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB84_4;

ld.global.f32 %f12, [%rd1+8];
add.f32 %f26, %f26, %f12;

LBB84_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB84_9;

mov.u32 %r38, %r1;

LBB84_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB84_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB84_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB84_6;

LBB84_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB84_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB84_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB84_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB84_13:
ret;

}

.visible .entry _Z7reduce4IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce4IfLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB85_2;

ld.global.f32 %f26, [%rd1];

LBB85_2:
add.s32 %r12, %r4, 1;
setp.ge.u32 %p2, %r12, %r10;
@%p2 bra LBB85_4;

ld.global.f32 %f12, [%rd1+4];
add.f32 %f26, %f26, %f12;

LBB85_4:
shl.b32 %r13, %r3, 2;
mov.u32 %r14, __smem;
add.s32 %r6, %r14, %r13;
st.shared.f32 [%r6], %f26;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB85_9;

mov.u32 %r38, %r1;

LBB85_6:
shr.u32 %r8, %r38, 1;
setp.ge.u32 %p4, %r3, %r8;
@%p4 bra LBB85_8;

shl.b32 %r15, %r8, 2;
add.s32 %r16, %r6, %r15;
ld.shared.f32 %f13, [%r16];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r6], %f26;

LBB85_8:
barrier.sync 0;
setp.gt.u32 %p5, %r38, 131;
mov.u32 %r38, %r8;
@%p5 bra LBB85_6;

LBB85_9:
mov.u32 %r17, %ntid.y;
mov.u32 %r18, %tid.z;
mov.u32 %r19, %tid.y;
mad.lo.s32 %r20, %r17, %r18, %r19;
mad.lo.s32 %r9, %r20, %r1, %r3;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB85_11;

mov.b32 %r21, %f26;
mov.u32 %r22, 2;
mov.u32 %r23, 31;
mov.u32 %r24, 16;
mov.u32 %r25, -1;
shfl.sync.down.b32 %r26|%p7, %r21, %r24, %r23, %r25;
mov.b32 %f14, %r26;
add.f32 %f15, %f26, %f14;
mov.b32 %r27, %f15;
mov.u32 %r28, 8;
shfl.sync.down.b32 %r29|%p8, %r27, %r28, %r23, %r25;
mov.b32 %f16, %r29;
add.f32 %f17, %f15, %f16;
mov.b32 %r30, %f17;
mov.u32 %r31, 4;
shfl.sync.down.b32 %r32|%p9, %r30, %r31, %r23, %r25;
mov.b32 %f18, %r32;
add.f32 %f19, %f17, %f18;
mov.b32 %r33, %f19;
shfl.sync.down.b32 %r34|%p10, %r33, %r22, %r23, %r25;
mov.b32 %f20, %r34;
add.f32 %f21, %f19, %f20;
mov.b32 %r35, %f21;
mov.u32 %r36, 1;
shfl.sync.down.b32 %r37|%p11, %r35, %r36, %r23, %r25;
mov.b32 %f22, %r37;
add.f32 %f26, %f21, %f22;

LBB85_11:
setp.ne.s32 %p12, %r9, 0;
@%p12 bra LBB85_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB85_13:
ret;

}

.visible .entry _Z7reduce5IfLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<50>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce5IfLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj512EEvPT_S1_j_param_1];
ld.param.u32 %r3, [_Z7reduce5IfLj512EEvPT_S1_j_param_2];
mov.u32 %r4, %ctaid.x;
shl.b32 %r5, %r4, 10;
mov.u32 %r6, %tid.x;
add.s32 %r7, %r5, %r6;
setp.ge.u32 %p1, %r7, %r3;
mov.f32 %f30, 0f00000000;
@%p1 bra LBB86_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r7, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f30, [%rd5];

LBB86_2:
add.s32 %r16, %r7, 512;
setp.ge.u32 %p2, %r16, %r3;
@%p2 bra LBB86_4;

cvta.to.global.u64 %rd6, %rd1;
mul.wide.u32 %rd7, %r7, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.f32 %f14, [%rd8+2048];
add.f32 %f30, %f30, %f14;

LBB86_4:
shl.b32 %r22, %r6, 2;
mov.u32 %r23, __smem;
add.s32 %r1, %r23, %r22;
st.shared.f32 [%r1], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r6, 255;
@%p3 bra LBB86_6;

ld.shared.f32 %f15, [%r1+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r1], %f30;

LBB86_6:
barrier.sync 0;
setp.gt.u32 %p4, %r6, 127;
@%p4 bra LBB86_8;

ld.shared.f32 %f16, [%r1+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r1], %f30;

LBB86_8:
barrier.sync 0;
setp.gt.u32 %p5, %r6, 63;
@%p5 bra LBB86_10;

ld.shared.f32 %f17, [%r1+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r1], %f30;

LBB86_10:
barrier.sync 0;
mov.u32 %r26, %ntid.y;
mov.u32 %r27, %tid.z;
mov.u32 %r28, %tid.y;
mad.lo.s32 %r29, %r26, %r27, %r28;
mov.u32 %r30, %ntid.x;
mad.lo.s32 %r2, %r29, %r30, %r6;
setp.gt.u32 %p6, %r2, 31;
@%p6 bra LBB86_12;

ld.shared.f32 %f18, [%r1+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r32, %f19;
mov.u32 %r33, 2;
mov.u32 %r34, 31;
mov.u32 %r35, 16;
mov.u32 %r36, -1;
shfl.sync.down.b32 %r37|%p7, %r32, %r35, %r34, %r36;
mov.b32 %f20, %r37;
add.f32 %f21, %f19, %f20;
mov.b32 %r38, %f21;
mov.u32 %r39, 8;
shfl.sync.down.b32 %r40|%p8, %r38, %r39, %r34, %r36;
mov.b32 %f22, %r40;
add.f32 %f23, %f21, %f22;
mov.b32 %r41, %f23;
mov.u32 %r42, 4;
shfl.sync.down.b32 %r43|%p9, %r41, %r42, %r34, %r36;
mov.b32 %f24, %r43;
add.f32 %f25, %f23, %f24;
mov.b32 %r44, %f25;
shfl.sync.down.b32 %r45|%p10, %r44, %r33, %r34, %r36;
mov.b32 %f26, %r45;
add.f32 %f27, %f25, %f26;
mov.b32 %r46, %f27;
mov.u32 %r47, 1;
shfl.sync.down.b32 %r48|%p11, %r46, %r47, %r34, %r36;
mov.b32 %f28, %r48;
add.f32 %f30, %f27, %f28;

LBB86_12:
setp.ne.s32 %p12, %r2, 0;
@%p12 bra LBB86_14;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r4, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f30;

LBB86_14:
ret;

}

.visible .entry _Z7reduce5IfLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<49>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce5IfLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj256EEvPT_S1_j_param_1];
ld.param.u32 %r3, [_Z7reduce5IfLj256EEvPT_S1_j_param_2];
mov.u32 %r4, %ctaid.x;
shl.b32 %r5, %r4, 9;
mov.u32 %r6, %tid.x;
add.s32 %r7, %r5, %r6;
setp.ge.u32 %p1, %r7, %r3;
mov.f32 %f27, 0f00000000;
@%p1 bra LBB87_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r7, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f27, [%rd5];

LBB87_2:
add.s32 %r16, %r7, 256;
setp.ge.u32 %p2, %r16, %r3;
@%p2 bra LBB87_4;

cvta.to.global.u64 %rd6, %rd1;
mul.wide.u32 %rd7, %r7, 4;
add.s64 %rd8, %rd6, %rd7;
ld.global.f32 %f12, [%rd8+1024];
add.f32 %f27, %f27, %f12;

LBB87_4:
shl.b32 %r22, %r6, 2;
mov.u32 %r23, __smem;
add.s32 %r1, %r23, %r22;
st.shared.f32 [%r1], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r6, 127;
@%p3 bra LBB87_6;

ld.shared.f32 %f13, [%r1+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r1], %f27;

LBB87_6:
barrier.sync 0;
setp.gt.u32 %p4, %r6, 63;
@%p4 bra LBB87_8;

ld.shared.f32 %f14, [%r1+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r1], %f27;

LBB87_8:
barrier.sync 0;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %tid.z;
mov.u32 %r27, %tid.y;
mad.lo.s32 %r28, %r25, %r26, %r27;
mov.u32 %r29, %ntid.x;
mad.lo.s32 %r2, %r28, %r29, %r6;
setp.gt.u32 %p5, %r2, 31;
@%p5 bra LBB87_10;

ld.shared.f32 %f15, [%r1+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r31, %f16;
mov.u32 %r32, 2;
mov.u32 %r33, 31;
mov.u32 %r34, 16;
mov.u32 %r35, -1;
shfl.sync.down.b32 %r36|%p6, %r31, %r34, %r33, %r35;
mov.b32 %f17, %r36;
add.f32 %f18, %f16, %f17;
mov.b32 %r37, %f18;
mov.u32 %r38, 8;
shfl.sync.down.b32 %r39|%p7, %r37, %r38, %r33, %r35;
mov.b32 %f19, %r39;
add.f32 %f20, %f18, %f19;
mov.b32 %r40, %f20;
mov.u32 %r41, 4;
shfl.sync.down.b32 %r42|%p8, %r40, %r41, %r33, %r35;
mov.b32 %f21, %r42;
add.f32 %f22, %f20, %f21;
mov.b32 %r43, %f22;
shfl.sync.down.b32 %r44|%p9, %r43, %r32, %r33, %r35;
mov.b32 %f23, %r44;
add.f32 %f24, %f22, %f23;
mov.b32 %r45, %f24;
mov.u32 %r46, 1;
shfl.sync.down.b32 %r47|%p10, %r45, %r46, %r33, %r35;
mov.b32 %f25, %r47;
add.f32 %f27, %f24, %f25;

LBB87_10:
setp.ne.s32 %p11, %r2, 0;
@%p11 bra LBB87_12;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r4, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f27;

LBB87_12:
ret;

}

.visible .entry _Z7reduce5IfLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<40>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj128EEvPT_S1_j_param_1];
ld.param.u32 %r3, [_Z7reduce5IfLj128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r4, %ctaid.x;
shl.b32 %r5, %r4, 8;
mov.u32 %r6, %tid.x;
add.s32 %r7, %r5, %r6;
setp.ge.u32 %p1, %r7, %r3;
mul.wide.u32 %rd5, %r7, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f24, 0f00000000;
@%p1 bra LBB88_2;

ld.global.f32 %f24, [%rd1];

LBB88_2:
add.s32 %r12, %r7, 128;
setp.ge.u32 %p2, %r12, %r3;
@%p2 bra LBB88_4;

ld.global.f32 %f10, [%rd1+512];
add.f32 %f24, %f24, %f10;

LBB88_4:
shl.b32 %r14, %r6, 2;
mov.u32 %r15, __smem;
add.s32 %r1, %r15, %r14;
st.shared.f32 [%r1], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r6, 63;
@%p3 bra LBB88_6;

ld.shared.f32 %f11, [%r1+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r1], %f24;

LBB88_6:
barrier.sync 0;
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mov.u32 %r20, %ntid.x;
mad.lo.s32 %r2, %r19, %r20, %r6;
setp.gt.u32 %p4, %r2, 31;
@%p4 bra LBB88_8;

ld.shared.f32 %f12, [%r1+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r22, %f13;
mov.u32 %r23, 2;
mov.u32 %r24, 31;
mov.u32 %r25, 16;
mov.u32 %r26, -1;
shfl.sync.down.b32 %r27|%p5, %r22, %r25, %r24, %r26;
mov.b32 %f14, %r27;
add.f32 %f15, %f13, %f14;
mov.b32 %r28, %f15;
mov.u32 %r29, 8;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r24, %r26;
mov.b32 %f16, %r30;
add.f32 %f17, %f15, %f16;
mov.b32 %r31, %f17;
mov.u32 %r32, 4;
shfl.sync.down.b32 %r33|%p7, %r31, %r32, %r24, %r26;
mov.b32 %f18, %r33;
add.f32 %f19, %f17, %f18;
mov.b32 %r34, %f19;
shfl.sync.down.b32 %r35|%p8, %r34, %r23, %r24, %r26;
mov.b32 %f20, %r35;
add.f32 %f21, %f19, %f20;
mov.b32 %r36, %f21;
mov.u32 %r37, 1;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r24, %r26;
mov.b32 %f22, %r38;
add.f32 %f24, %f21, %f22;

LBB88_8:
setp.ne.s32 %p10, %r2, 0;
@%p10 bra LBB88_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

LBB88_10:
ret;

}

.visible .entry _Z7reduce5IfLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj64EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd4, %rd3;
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 7;
mov.u32 %r7, %tid.x;
add.s32 %r1, %r6, %r7;
setp.ge.u32 %p1, %r1, %r4;
mul.wide.u32 %rd5, %r1, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB89_2;

ld.global.f32 %f21, [%rd1];

LBB89_2:
add.s32 %r8, %r1, 64;
setp.ge.u32 %p2, %r8, %r4;
@%p2 bra LBB89_4;

ld.global.f32 %f8, [%rd1+256];
add.f32 %f21, %f21, %f8;

LBB89_4:
shl.b32 %r10, %r7, 2;
mov.u32 %r11, __smem;
add.s32 %r2, %r11, %r10;
st.shared.f32 [%r2], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r3, %r15, %r16, %r7;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB89_6;

ld.shared.f32 %f9, [%r2+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r17, %f10;
mov.u32 %r18, 2;
mov.u32 %r19, 31;
mov.u32 %r20, 16;
mov.u32 %r21, -1;
shfl.sync.down.b32 %r22|%p4, %r17, %r20, %r19, %r21;
mov.b32 %f11, %r22;
add.f32 %f12, %f10, %f11;
mov.b32 %r23, %f12;
mov.u32 %r24, 8;
shfl.sync.down.b32 %r25|%p5, %r23, %r24, %r19, %r21;
mov.b32 %f13, %r25;
add.f32 %f14, %f12, %f13;
mov.b32 %r26, %f14;
mov.u32 %r27, 4;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r19, %r21;
mov.b32 %f15, %r28;
add.f32 %f16, %f14, %f15;
mov.b32 %r29, %f16;
shfl.sync.down.b32 %r30|%p7, %r29, %r18, %r19, %r21;
mov.b32 %f17, %r30;
add.f32 %f18, %f16, %f17;
mov.b32 %r31, %f18;
mov.u32 %r32, 1;
shfl.sync.down.b32 %r33|%p8, %r31, %r32, %r19, %r21;
mov.b32 %f19, %r33;
add.f32 %f21, %f18, %f19;

LBB89_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB89_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

LBB89_8:
ret;

}

.visible .entry _Z7reduce5IfLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj32EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj32EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 6;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB90_2;

ld.global.f32 %f19, [%rd1];

LBB90_2:
add.s32 %r7, %r2, 32;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB90_4;

ld.global.f32 %f8, [%rd1+128];
add.f32 %f19, %f19, %f8;

LBB90_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB90_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB90_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB90_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB90_8:
ret;

}

.visible .entry _Z7reduce5IfLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj16EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj16EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 5;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB91_2;

ld.global.f32 %f19, [%rd1];

LBB91_2:
add.s32 %r7, %r2, 16;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB91_4;

ld.global.f32 %f8, [%rd1+64];
add.f32 %f19, %f19, %f8;

LBB91_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB91_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB91_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB91_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB91_8:
ret;

}

.visible .entry _Z7reduce5IfLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj8EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj8EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 4;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB92_2;

ld.global.f32 %f19, [%rd1];

LBB92_2:
add.s32 %r7, %r2, 8;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB92_4;

ld.global.f32 %f8, [%rd1+32];
add.f32 %f19, %f19, %f8;

LBB92_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB92_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB92_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB92_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB92_8:
ret;

}

.visible .entry _Z7reduce5IfLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj4EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj4EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 3;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB93_2;

ld.global.f32 %f19, [%rd1];

LBB93_2:
add.s32 %r7, %r2, 4;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB93_4;

ld.global.f32 %f8, [%rd1+16];
add.f32 %f19, %f19, %f8;

LBB93_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB93_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB93_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB93_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB93_8:
ret;

}

.visible .entry _Z7reduce5IfLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj2EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj2EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 2;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB94_2;

ld.global.f32 %f19, [%rd1];

LBB94_2:
add.s32 %r7, %r2, 2;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB94_4;

ld.global.f32 %f8, [%rd1+8];
add.f32 %f19, %f19, %f8;

LBB94_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB94_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB94_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB94_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB94_8:
ret;

}

.visible .entry _Z7reduce5IfLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IfLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IfLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<34>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IfLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IfLj1EEvPT_S1_j_param_1];
ld.param.u32 %r4, [_Z7reduce5IfLj1EEvPT_S1_j_param_2];
mov.u32 %r5, %ctaid.x;
shl.b32 %r6, %r5, 1;
mov.u32 %r1, %tid.x;
add.s32 %r2, %r6, %r1;
setp.ge.u32 %p1, %r2, %r4;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r2, 4;
add.s64 %rd1, %rd4, %rd5;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB95_2;

ld.global.f32 %f19, [%rd1];

LBB95_2:
add.s32 %r7, %r2, 1;
setp.ge.u32 %p2, %r7, %r4;
@%p2 bra LBB95_4;

ld.global.f32 %f8, [%rd1+4];
add.f32 %f19, %f19, %f8;

LBB95_4:
shl.b32 %r8, %r1, 2;
mov.u32 %r9, __smem;
add.s32 %r10, %r9, %r8;
st.shared.f32 [%r10], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r3, %r14, %r15, %r1;
setp.gt.u32 %p3, %r3, 31;
@%p3 bra LBB95_6;

mov.b32 %r16, %f19;
mov.u32 %r17, 2;
mov.u32 %r18, 31;
mov.u32 %r19, 16;
mov.u32 %r20, -1;
shfl.sync.down.b32 %r21|%p4, %r16, %r19, %r18, %r20;
mov.b32 %f9, %r21;
add.f32 %f10, %f19, %f9;
mov.b32 %r22, %f10;
mov.u32 %r23, 8;
shfl.sync.down.b32 %r24|%p5, %r22, %r23, %r18, %r20;
mov.b32 %f11, %r24;
add.f32 %f12, %f10, %f11;
mov.b32 %r25, %f12;
mov.u32 %r26, 4;
shfl.sync.down.b32 %r27|%p6, %r25, %r26, %r18, %r20;
mov.b32 %f13, %r27;
add.f32 %f14, %f12, %f13;
mov.b32 %r28, %f14;
shfl.sync.down.b32 %r29|%p7, %r28, %r17, %r18, %r20;
mov.b32 %f15, %r29;
add.f32 %f16, %f14, %f15;
mov.b32 %r30, %f16;
mov.u32 %r31, 1;
shfl.sync.down.b32 %r32|%p8, %r30, %r31, %r18, %r20;
mov.b32 %f17, %r32;
add.f32 %f19, %f16, %f17;

LBB95_6:
setp.ne.s32 %p9, %r3, 0;
@%p9 bra LBB95_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r5, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB95_8:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<39>;
.reg .b32 %r<47>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj512ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 10;
add.s32 %r46, %r10, %r8;
setp.ge.u32 %p1, %r46, %r7;
mov.f32 %f32, 0f00000000;
@%p1 bra LBB96_5;

mov.f32 %f32, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB96_2:
mul.wide.u32 %rd4, %r46, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f16, [%rd5];
add.f32 %f32, %f32, %f16;
add.s32 %r3, %r46, 512;
setp.ge.u32 %p2, %r3, %r7;
@%p2 bra LBB96_4;

mul.wide.u32 %rd7, %r3, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f17, [%rd8];
add.f32 %f32, %f32, %f17;

LBB96_4:
mov.u32 %r15, %nctaid.x;
shl.b32 %r16, %r15, 10;
add.s32 %r46, %r46, %r16;
setp.lt.u32 %p3, %r46, %r7;
@%p3 bra LBB96_2;

LBB96_5:
shl.b32 %r18, %r8, 2;
mov.u32 %r19, __smem;
add.s32 %r5, %r19, %r18;
st.shared.f32 [%r5], %f32;
barrier.sync 0;
setp.gt.u32 %p4, %r8, 255;
@%p4 bra LBB96_7;

ld.shared.f32 %f18, [%r5+1024];
add.f32 %f32, %f32, %f18;
st.shared.f32 [%r5], %f32;

LBB96_7:
barrier.sync 0;
setp.gt.u32 %p5, %r8, 127;
@%p5 bra LBB96_9;

ld.shared.f32 %f19, [%r5+512];
add.f32 %f32, %f32, %f19;
st.shared.f32 [%r5], %f32;

LBB96_9:
barrier.sync 0;
setp.gt.u32 %p6, %r8, 63;
@%p6 bra LBB96_11;

ld.shared.f32 %f20, [%r5+256];
add.f32 %f32, %f32, %f20;
st.shared.f32 [%r5], %f32;

LBB96_11:
barrier.sync 0;
mov.u32 %r22, %ntid.y;
mov.u32 %r23, %tid.z;
mov.u32 %r24, %tid.y;
mad.lo.s32 %r25, %r22, %r23, %r24;
mov.u32 %r26, %ntid.x;
mad.lo.s32 %r6, %r25, %r26, %r8;
setp.gt.u32 %p7, %r6, 31;
@%p7 bra LBB96_13;

ld.shared.f32 %f21, [%r5+128];
add.f32 %f22, %f32, %f21;
mov.b32 %r28, %f22;
mov.u32 %r29, 2;
mov.u32 %r30, 31;
mov.u32 %r31, 16;
mov.u32 %r32, -1;
shfl.sync.down.b32 %r33|%p8, %r28, %r31, %r30, %r32;
mov.b32 %f23, %r33;
add.f32 %f24, %f22, %f23;
mov.b32 %r34, %f24;
mov.u32 %r35, 8;
shfl.sync.down.b32 %r36|%p9, %r34, %r35, %r30, %r32;
mov.b32 %f25, %r36;
add.f32 %f26, %f24, %f25;
mov.b32 %r37, %f26;
mov.u32 %r38, 4;
shfl.sync.down.b32 %r39|%p10, %r37, %r38, %r30, %r32;
mov.b32 %f27, %r39;
add.f32 %f28, %f26, %f27;
mov.b32 %r40, %f28;
shfl.sync.down.b32 %r41|%p11, %r40, %r29, %r30, %r32;
mov.b32 %f29, %r41;
add.f32 %f30, %f28, %f29;
mov.b32 %r42, %f30;
mov.u32 %r43, 1;
shfl.sync.down.b32 %r44|%p12, %r42, %r43, %r30, %r32;
mov.b32 %f31, %r44;
add.f32 %f32, %f30, %f31;

LBB96_13:
setp.ne.s32 %p13, %r6, 0;
@%p13 bra LBB96_15;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f32;

LBB96_15:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<46>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj256ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 9;
add.s32 %r45, %r10, %r8;
setp.ge.u32 %p1, %r45, %r7;
mov.f32 %f29, 0f00000000;
@%p1 bra LBB97_5;

mov.f32 %f29, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB97_2:
mul.wide.u32 %rd4, %r45, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f29, %f29, %f14;
add.s32 %r3, %r45, 256;
setp.ge.u32 %p2, %r3, %r7;
@%p2 bra LBB97_4;

mul.wide.u32 %rd7, %r3, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f15, [%rd8];
add.f32 %f29, %f29, %f15;

LBB97_4:
mov.u32 %r15, %nctaid.x;
shl.b32 %r16, %r15, 9;
add.s32 %r45, %r45, %r16;
setp.lt.u32 %p3, %r45, %r7;
@%p3 bra LBB97_2;

LBB97_5:
shl.b32 %r18, %r8, 2;
mov.u32 %r19, __smem;
add.s32 %r5, %r19, %r18;
st.shared.f32 [%r5], %f29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r8, 127;
@%p4 bra LBB97_7;

ld.shared.f32 %f16, [%r5+512];
add.f32 %f29, %f29, %f16;
st.shared.f32 [%r5], %f29;

LBB97_7:
barrier.sync 0;
setp.gt.u32 %p5, %r8, 63;
@%p5 bra LBB97_9;

ld.shared.f32 %f17, [%r5+256];
add.f32 %f29, %f29, %f17;
st.shared.f32 [%r5], %f29;

LBB97_9:
barrier.sync 0;
mov.u32 %r21, %ntid.y;
mov.u32 %r22, %tid.z;
mov.u32 %r23, %tid.y;
mad.lo.s32 %r24, %r21, %r22, %r23;
mov.u32 %r25, %ntid.x;
mad.lo.s32 %r6, %r24, %r25, %r8;
setp.gt.u32 %p6, %r6, 31;
@%p6 bra LBB97_11;

ld.shared.f32 %f18, [%r5+128];
add.f32 %f19, %f29, %f18;
mov.b32 %r27, %f19;
mov.u32 %r28, 2;
mov.u32 %r29, 31;
mov.u32 %r30, 16;
mov.u32 %r31, -1;
shfl.sync.down.b32 %r32|%p7, %r27, %r30, %r29, %r31;
mov.b32 %f20, %r32;
add.f32 %f21, %f19, %f20;
mov.b32 %r33, %f21;
mov.u32 %r34, 8;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r29, %r31;
mov.b32 %f22, %r35;
add.f32 %f23, %f21, %f22;
mov.b32 %r36, %f23;
mov.u32 %r37, 4;
shfl.sync.down.b32 %r38|%p9, %r36, %r37, %r29, %r31;
mov.b32 %f24, %r38;
add.f32 %f25, %f23, %f24;
mov.b32 %r39, %f25;
shfl.sync.down.b32 %r40|%p10, %r39, %r28, %r29, %r31;
mov.b32 %f26, %r40;
add.f32 %f27, %f25, %f26;
mov.b32 %r41, %f27;
mov.u32 %r42, 1;
shfl.sync.down.b32 %r43|%p11, %r41, %r42, %r29, %r31;
mov.b32 %f28, %r43;
add.f32 %f29, %f27, %f28;

LBB97_11:
setp.ne.s32 %p12, %r6, 0;
@%p12 bra LBB97_13;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f29;

LBB97_13:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<45>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj128ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 8;
add.s32 %r44, %r10, %r8;
setp.ge.u32 %p1, %r44, %r7;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB98_5;

mov.f32 %f26, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB98_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r3, %r44, 128;
setp.ge.u32 %p2, %r3, %r7;
@%p2 bra LBB98_4;

mul.wide.u32 %rd7, %r3, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f13, [%rd8];
add.f32 %f26, %f26, %f13;

LBB98_4:
mov.u32 %r15, %nctaid.x;
shl.b32 %r16, %r15, 8;
add.s32 %r44, %r44, %r16;
setp.lt.u32 %p3, %r44, %r7;
@%p3 bra LBB98_2;

LBB98_5:
shl.b32 %r18, %r8, 2;
mov.u32 %r19, __smem;
add.s32 %r5, %r19, %r18;
st.shared.f32 [%r5], %f26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r8, 63;
@%p4 bra LBB98_7;

ld.shared.f32 %f14, [%r5+256];
add.f32 %f26, %f26, %f14;
st.shared.f32 [%r5], %f26;

LBB98_7:
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p5, %r6, 31;
@%p5 bra LBB98_9;

ld.shared.f32 %f15, [%r5+128];
add.f32 %f16, %f26, %f15;
mov.b32 %r26, %f16;
mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p6, %r26, %r29, %r28, %r30;
mov.b32 %f17, %r31;
add.f32 %f18, %f16, %f17;
mov.b32 %r32, %f18;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p7, %r32, %r33, %r28, %r30;
mov.b32 %f19, %r34;
add.f32 %f20, %f18, %f19;
mov.b32 %r35, %f20;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p8, %r35, %r36, %r28, %r30;
mov.b32 %f21, %r37;
add.f32 %f22, %f20, %f21;
mov.b32 %r38, %f22;
shfl.sync.down.b32 %r39|%p9, %r38, %r27, %r28, %r30;
mov.b32 %f23, %r39;
add.f32 %f24, %f22, %f23;
mov.b32 %r40, %f24;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p10, %r40, %r41, %r28, %r30;
mov.b32 %f25, %r42;
add.f32 %f26, %f24, %f25;

LBB98_9:
setp.ne.s32 %p11, %r6, 0;
@%p11 bra LBB98_11;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f26;

LBB98_11:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj64ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 7;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f23, 0f00000000;
@%p1 bra LBB99_5;

mov.f32 %f23, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB99_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f23, %f23, %f10;
add.s32 %r3, %r43, 64;
setp.ge.u32 %p2, %r3, %r7;
@%p2 bra LBB99_4;

mul.wide.u32 %rd7, %r3, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f23, %f23, %f11;

LBB99_4:
mov.u32 %r15, %nctaid.x;
shl.b32 %r16, %r15, 7;
add.s32 %r43, %r43, %r16;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB99_2;

LBB99_5:
shl.b32 %r18, %r8, 2;
mov.u32 %r19, __smem;
add.s32 %r5, %r19, %r18;
st.shared.f32 [%r5], %f23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB99_7;

ld.shared.f32 %f12, [%r5+128];
add.f32 %f13, %f23, %f12;
mov.b32 %r25, %f13;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f14, %r30;
add.f32 %f15, %f13, %f14;
mov.b32 %r31, %f15;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f16, %r33;
add.f32 %f17, %f15, %f16;
mov.b32 %r34, %f17;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f18, %r36;
add.f32 %f19, %f17, %f18;
mov.b32 %r37, %f19;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f22, %r41;
add.f32 %f23, %f21, %f22;

LBB99_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB99_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f23;

LBB99_9:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj32ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 6;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB100_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 6;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB100_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 32;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB100_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB100_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB100_2;

LBB100_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB100_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB100_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB100_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB100_9:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj16ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 5;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB101_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 5;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB101_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 16;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB101_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB101_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB101_2;

LBB101_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB101_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB101_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB101_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB101_9:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj8ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 4;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB102_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 4;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB102_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 8;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB102_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB102_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB102_2;

LBB102_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB102_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB102_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB102_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB102_9:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj4ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 3;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB103_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 3;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB103_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 4;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB103_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB103_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB103_2;

LBB103_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB103_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB103_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB103_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB103_9:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj2ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 2;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB104_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 2;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB104_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 2;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB104_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB104_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB104_2;

LBB104_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB104_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB104_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB104_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB104_9:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<25>;
.reg .b32 %r<44>;
.reg .b64 %rd<12>;


ld.param.u64 %rd1, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj1ELb1EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 1;
add.s32 %r43, %r10, %r8;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB105_5;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 1;
mov.f32 %f21, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB105_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f21, %f21, %f10;
add.s32 %r4, %r43, 1;
setp.ge.u32 %p2, %r4, %r7;
@%p2 bra LBB105_4;

mul.wide.u32 %rd7, %r4, 4;
add.s64 %rd8, %rd3, %rd7;
ld.global.f32 %f11, [%rd8];
add.f32 %f21, %f21, %f11;

LBB105_4:
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p3, %r43, %r7;
@%p3 bra LBB105_2;

LBB105_5:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r19, %r18, %r17;
st.shared.f32 [%r19], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB105_7;

mov.b32 %r25, %f21;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f12, %r30;
add.f32 %f13, %f21, %f12;
mov.b32 %r31, %f13;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f14, %r33;
add.f32 %f15, %f13, %f14;
mov.b32 %r34, %f15;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f16, %r36;
add.f32 %f17, %f15, %f16;
mov.b32 %r37, %f17;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f18, %r38;
add.f32 %f19, %f17, %f18;
mov.b32 %r39, %f19;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f20, %r41;
add.f32 %f21, %f19, %f20;

LBB105_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB105_9;

cvta.to.global.u64 %rd9, %rd2;
mul.wide.u32 %rd10, %r9, 4;
add.s64 %rd11, %rd9, %rd10;
st.global.f32 [%rd11], %f21;

LBB105_9:
ret;

}

.visible .entry _Z7reduce6IfLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<35>;
.reg .b32 %r<62>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce6IfLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r6, %tid.x;
mov.u32 %r7, %ctaid.x;
shl.b32 %r8, %r7, 9;
add.s32 %r61, %r8, %r6;
setp.ge.u32 %p1, %r61, %r5;
mov.f32 %f30, 0f00000000;
@%p1 bra LBB106_3;

mov.f32 %f30, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;
mov.u32 %r13, %nctaid.x;
shl.b32 %r14, %r13, 9;

LBB106_2:
mul.wide.u32 %rd4, %r61, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f14, [%rd5];
add.f32 %f30, %f30, %f14;
add.s32 %r61, %r61, %r14;
setp.lt.u32 %p2, %r61, %r5;
@%p2 bra LBB106_2;

LBB106_3:
shl.b32 %r16, %r6, 2;
mov.u32 %r17, __smem;
add.s32 %r18, %r17, %r16;
st.shared.f32 [%r18], %f30;
barrier.sync 0;
setp.gt.u32 %p3, %r6, 255;
@%p3 bra LBB106_5;

ld.shared.f32 %f15, [%r18+1024];
add.f32 %f30, %f30, %f15;
st.shared.f32 [%r18], %f30;

LBB106_5:
barrier.sync 0;
setp.gt.u32 %p4, %r6, 127;
@%p4 bra LBB106_7;

ld.shared.f32 %f16, [%r18+512];
add.f32 %f30, %f30, %f16;
st.shared.f32 [%r18], %f30;

LBB106_7:
barrier.sync 0;
setp.gt.u32 %p5, %r6, 63;
@%p5 bra LBB106_9;

ld.shared.f32 %f17, [%r18+256];
add.f32 %f30, %f30, %f17;
st.shared.f32 [%r18], %f30;

LBB106_9:
barrier.sync 0;
mov.u32 %r33, %ntid.y;
mov.u32 %r34, %tid.z;
mov.u32 %r35, %tid.y;
mad.lo.s32 %r36, %r33, %r34, %r35;
mov.u32 %r37, %ntid.x;
mad.lo.s32 %r4, %r36, %r37, %r6;
setp.gt.u32 %p6, %r4, 31;
@%p6 bra LBB106_11;

mov.u32 %r43, 2;
ld.shared.f32 %f18, [%r18+128];
add.f32 %f19, %f30, %f18;
mov.b32 %r44, %f19;
mov.u32 %r45, 31;
mov.u32 %r46, 16;
mov.u32 %r47, -1;
shfl.sync.down.b32 %r48|%p7, %r44, %r46, %r45, %r47;
mov.b32 %f20, %r48;
add.f32 %f21, %f19, %f20;
mov.b32 %r49, %f21;
mov.u32 %r50, 8;
shfl.sync.down.b32 %r51|%p8, %r49, %r50, %r45, %r47;
mov.b32 %f22, %r51;
add.f32 %f23, %f21, %f22;
mov.b32 %r52, %f23;
mov.u32 %r53, 4;
shfl.sync.down.b32 %r54|%p9, %r52, %r53, %r45, %r47;
mov.b32 %f24, %r54;
add.f32 %f25, %f23, %f24;
mov.b32 %r55, %f25;
shfl.sync.down.b32 %r56|%p10, %r55, %r43, %r45, %r47;
mov.b32 %f26, %r56;
add.f32 %f27, %f25, %f26;
mov.b32 %r57, %f27;
mov.u32 %r58, 1;
shfl.sync.down.b32 %r59|%p11, %r57, %r58, %r45, %r47;
mov.b32 %f28, %r59;
add.f32 %f30, %f27, %f28;

LBB106_11:
setp.ne.s32 %p12, %r4, 0;
@%p12 bra LBB106_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r7, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f30;

LBB106_13:
ret;

}

.visible .entry _Z7reduce6IfLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<12>;
.reg .f32 %f<31>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %tid.x;
mov.u32 %r9, %ctaid.x;
shl.b32 %r10, %r9, 8;
add.s32 %r44, %r10, %r8;
setp.ge.u32 %p1, %r44, %r7;
mov.f32 %f27, 0f00000000;
@%p1 bra LBB107_3;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 8;
mov.f32 %f27, 0f00000000;
cvta.to.global.u64 %rd3, %rd1;

LBB107_2:
mul.wide.u32 %rd4, %r44, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f27, %f27, %f12;
add.s32 %r44, %r44, %r2;
setp.lt.u32 %p2, %r44, %r7;
@%p2 bra LBB107_2;

LBB107_3:
shl.b32 %r17, %r8, 2;
mov.u32 %r18, __smem;
add.s32 %r5, %r18, %r17;
st.shared.f32 [%r5], %f27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r8, 127;
@%p3 bra LBB107_5;

ld.shared.f32 %f13, [%r5+512];
add.f32 %f27, %f27, %f13;
st.shared.f32 [%r5], %f27;

LBB107_5:
barrier.sync 0;
setp.gt.u32 %p4, %r8, 63;
@%p4 bra LBB107_7;

ld.shared.f32 %f14, [%r5+256];
add.f32 %f27, %f27, %f14;
st.shared.f32 [%r5], %f27;

LBB107_7:
barrier.sync 0;
mov.u32 %r20, %ntid.y;
mov.u32 %r21, %tid.z;
mov.u32 %r22, %tid.y;
mad.lo.s32 %r23, %r20, %r21, %r22;
mov.u32 %r24, %ntid.x;
mad.lo.s32 %r6, %r23, %r24, %r8;
setp.gt.u32 %p5, %r6, 31;
@%p5 bra LBB107_9;

ld.shared.f32 %f15, [%r5+128];
add.f32 %f16, %f27, %f15;
mov.b32 %r26, %f16;
mov.u32 %r27, 2;
mov.u32 %r28, 31;
mov.u32 %r29, 16;
mov.u32 %r30, -1;
shfl.sync.down.b32 %r31|%p6, %r26, %r29, %r28, %r30;
mov.b32 %f17, %r31;
add.f32 %f18, %f16, %f17;
mov.b32 %r32, %f18;
mov.u32 %r33, 8;
shfl.sync.down.b32 %r34|%p7, %r32, %r33, %r28, %r30;
mov.b32 %f19, %r34;
add.f32 %f20, %f18, %f19;
mov.b32 %r35, %f20;
mov.u32 %r36, 4;
shfl.sync.down.b32 %r37|%p8, %r35, %r36, %r28, %r30;
mov.b32 %f21, %r37;
add.f32 %f22, %f20, %f21;
mov.b32 %r38, %f22;
shfl.sync.down.b32 %r39|%p9, %r38, %r27, %r28, %r30;
mov.b32 %f23, %r39;
add.f32 %f24, %f22, %f23;
mov.b32 %r40, %f24;
mov.u32 %r41, 1;
shfl.sync.down.b32 %r42|%p10, %r40, %r41, %r28, %r30;
mov.b32 %f25, %r42;
add.f32 %f27, %f24, %f25;

LBB107_9:
setp.ne.s32 %p11, %r6, 0;
@%p11 bra LBB107_11;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r9, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f27;

LBB107_11:
ret;

}

.visible .entry _Z7reduce6IfLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<11>;
.reg .f32 %f<27>;
.reg .b32 %r<44>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 7;
mov.u32 %r10, %tid.x;
add.s32 %r43, %r9, %r10;
setp.ge.u32 %p1, %r43, %r7;
mov.f32 %f24, 0f00000000;
@%p1 bra LBB108_3;

mov.u32 %r15, %nctaid.x;
shl.b32 %r2, %r15, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f24, 0f00000000;

LBB108_2:
mul.wide.u32 %rd4, %r43, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f10, [%rd5];
add.f32 %f24, %f24, %f10;
add.s32 %r43, %r43, %r2;
setp.lt.u32 %p2, %r43, %r7;
@%p2 bra LBB108_2;

LBB108_3:
shl.b32 %r17, %r10, 2;
mov.u32 %r18, __smem;
add.s32 %r5, %r18, %r17;
st.shared.f32 [%r5], %f24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r10, 63;
@%p3 bra LBB108_5;

ld.shared.f32 %f11, [%r5+256];
add.f32 %f24, %f24, %f11;
st.shared.f32 [%r5], %f24;

LBB108_5:
barrier.sync 0;
mov.u32 %r19, %ntid.y;
mov.u32 %r20, %tid.z;
mov.u32 %r21, %tid.y;
mad.lo.s32 %r22, %r19, %r20, %r21;
mov.u32 %r23, %ntid.x;
mad.lo.s32 %r6, %r22, %r23, %r10;
setp.gt.u32 %p4, %r6, 31;
@%p4 bra LBB108_7;

ld.shared.f32 %f12, [%r5+128];
add.f32 %f13, %f24, %f12;
mov.b32 %r25, %f13;
mov.u32 %r26, 2;
mov.u32 %r27, 31;
mov.u32 %r28, 16;
mov.u32 %r29, -1;
shfl.sync.down.b32 %r30|%p5, %r25, %r28, %r27, %r29;
mov.b32 %f14, %r30;
add.f32 %f15, %f13, %f14;
mov.b32 %r31, %f15;
mov.u32 %r32, 8;
shfl.sync.down.b32 %r33|%p6, %r31, %r32, %r27, %r29;
mov.b32 %f16, %r33;
add.f32 %f17, %f15, %f16;
mov.b32 %r34, %f17;
mov.u32 %r35, 4;
shfl.sync.down.b32 %r36|%p7, %r34, %r35, %r27, %r29;
mov.b32 %f18, %r36;
add.f32 %f19, %f17, %f18;
mov.b32 %r37, %f19;
shfl.sync.down.b32 %r38|%p8, %r37, %r26, %r27, %r29;
mov.b32 %f20, %r38;
add.f32 %f21, %f19, %f20;
mov.b32 %r39, %f21;
mov.u32 %r40, 1;
shfl.sync.down.b32 %r41|%p9, %r39, %r40, %r27, %r29;
mov.b32 %f22, %r41;
add.f32 %f24, %f21, %f22;

LBB108_7:
setp.ne.s32 %p10, %r6, 0;
@%p10 bra LBB108_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f24;

LBB108_9:
ret;

}

.visible .entry _Z7reduce6IfLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<23>;
.reg .b32 %r<39>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 6;
mov.u32 %r10, %tid.x;
add.s32 %r38, %r9, %r10;
setp.ge.u32 %p1, %r38, %r7;
mov.f32 %f21, 0f00000000;
@%p1 bra LBB109_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r2, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f21, 0f00000000;

LBB109_2:
mul.wide.u32 %rd4, %r38, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f21, %f21, %f8;
add.s32 %r38, %r38, %r2;
setp.lt.u32 %p2, %r38, %r7;
@%p2 bra LBB109_2;

LBB109_3:
shl.b32 %r13, %r10, 2;
mov.u32 %r14, __smem;
add.s32 %r5, %r14, %r13;
st.shared.f32 [%r5], %f21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r6, %r18, %r19, %r10;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB109_5;

ld.shared.f32 %f9, [%r5+128];
add.f32 %f10, %f21, %f9;
mov.b32 %r20, %f10;
mov.u32 %r21, 2;
mov.u32 %r22, 31;
mov.u32 %r23, 16;
mov.u32 %r24, -1;
shfl.sync.down.b32 %r25|%p4, %r20, %r23, %r22, %r24;
mov.b32 %f11, %r25;
add.f32 %f12, %f10, %f11;
mov.b32 %r26, %f12;
mov.u32 %r27, 8;
shfl.sync.down.b32 %r28|%p5, %r26, %r27, %r22, %r24;
mov.b32 %f13, %r28;
add.f32 %f14, %f12, %f13;
mov.b32 %r29, %f14;
mov.u32 %r30, 4;
shfl.sync.down.b32 %r31|%p6, %r29, %r30, %r22, %r24;
mov.b32 %f15, %r31;
add.f32 %f16, %f14, %f15;
mov.b32 %r32, %f16;
shfl.sync.down.b32 %r33|%p7, %r32, %r21, %r22, %r24;
mov.b32 %f17, %r33;
add.f32 %f18, %f16, %f17;
mov.b32 %r34, %f18;
mov.u32 %r35, 1;
shfl.sync.down.b32 %r36|%p8, %r34, %r35, %r22, %r24;
mov.b32 %f19, %r36;
add.f32 %f21, %f18, %f19;

LBB109_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB109_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f21;

LBB109_7:
ret;

}

.visible .entry _Z7reduce6IfLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 5;
mov.u32 %r1, %tid.x;
add.s32 %r37, %r9, %r1;
setp.ge.u32 %p1, %r37, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB110_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r3, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB110_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r37, %r37, %r3;
setp.lt.u32 %p2, %r37, %r7;
@%p2 bra LBB110_2;

LBB110_3:
shl.b32 %r11, %r1, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r6, %r17, %r18, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB110_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

LBB110_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB110_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB110_7:
ret;

}

.visible .entry _Z7reduce6IfLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 4;
mov.u32 %r1, %tid.x;
add.s32 %r37, %r9, %r1;
setp.ge.u32 %p1, %r37, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB111_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r3, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB111_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r37, %r37, %r3;
setp.lt.u32 %p2, %r37, %r7;
@%p2 bra LBB111_2;

LBB111_3:
shl.b32 %r11, %r1, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r6, %r17, %r18, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB111_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

LBB111_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB111_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB111_7:
ret;

}

.visible .entry _Z7reduce6IfLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 3;
mov.u32 %r1, %tid.x;
add.s32 %r37, %r9, %r1;
setp.ge.u32 %p1, %r37, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB112_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r3, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB112_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r37, %r37, %r3;
setp.lt.u32 %p2, %r37, %r7;
@%p2 bra LBB112_2;

LBB112_3:
shl.b32 %r11, %r1, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r6, %r17, %r18, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB112_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

LBB112_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB112_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB112_7:
ret;

}

.visible .entry _Z7reduce6IfLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 2;
mov.u32 %r1, %tid.x;
add.s32 %r37, %r9, %r1;
setp.ge.u32 %p1, %r37, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB113_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r3, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB113_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r37, %r37, %r3;
setp.lt.u32 %p2, %r37, %r7;
@%p2 bra LBB113_2;

LBB113_3:
shl.b32 %r11, %r1, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r6, %r17, %r18, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB113_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

LBB113_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB113_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB113_7:
ret;

}

.visible .entry _Z7reduce6IfLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<38>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
shl.b32 %r9, %r8, 1;
mov.u32 %r1, %tid.x;
add.s32 %r37, %r9, %r1;
setp.ge.u32 %p1, %r37, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB114_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r3, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB114_2:
mul.wide.u32 %rd4, %r37, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r37, %r37, %r3;
setp.lt.u32 %p2, %r37, %r7;
@%p2 bra LBB114_2;

LBB114_3:
shl.b32 %r11, %r1, 2;
mov.u32 %r12, __smem;
add.s32 %r13, %r12, %r11;
st.shared.f32 [%r13], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r6, %r17, %r18, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB114_5;

mov.b32 %r19, %f19;
mov.u32 %r20, 2;
mov.u32 %r21, 31;
mov.u32 %r22, 16;
mov.u32 %r23, -1;
shfl.sync.down.b32 %r24|%p4, %r19, %r22, %r21, %r23;
mov.b32 %f9, %r24;
add.f32 %f10, %f19, %f9;
mov.b32 %r25, %f10;
mov.u32 %r26, 8;
shfl.sync.down.b32 %r27|%p5, %r25, %r26, %r21, %r23;
mov.b32 %f11, %r27;
add.f32 %f12, %f10, %f11;
mov.b32 %r28, %f12;
mov.u32 %r29, 4;
shfl.sync.down.b32 %r30|%p6, %r28, %r29, %r21, %r23;
mov.b32 %f13, %r30;
add.f32 %f14, %f12, %f13;
mov.b32 %r31, %f14;
shfl.sync.down.b32 %r32|%p7, %r31, %r20, %r21, %r23;
mov.b32 %f15, %r32;
add.f32 %f16, %f14, %f15;
mov.b32 %r33, %f16;
mov.u32 %r34, 1;
shfl.sync.down.b32 %r35|%p8, %r33, %r34, %r21, %r23;
mov.b32 %f17, %r35;
add.f32 %f19, %f16, %f17;

LBB114_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB114_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB114_7:
ret;

}

.visible .entry _Z7reduce6IfLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<10>;
.reg .f32 %f<21>;
.reg .b32 %r<36>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r7, [_Z7reduce6IfLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r8, %ctaid.x;
mov.u32 %r1, %tid.x;
add.s32 %r35, %r8, %r1;
setp.ge.u32 %p1, %r35, %r7;
mov.f32 %f19, 0f00000000;
@%p1 bra LBB115_3;

mov.u32 %r3, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB115_2:
mul.wide.u32 %rd4, %r35, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f8, [%rd5];
add.f32 %f19, %f19, %f8;
add.s32 %r35, %r35, %r3;
setp.lt.u32 %p2, %r35, %r7;
@%p2 bra LBB115_2;

LBB115_3:
shl.b32 %r9, %r1, 2;
mov.u32 %r10, __smem;
add.s32 %r11, %r10, %r9;
st.shared.f32 [%r11], %f19;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r6, %r15, %r16, %r1;
setp.gt.u32 %p3, %r6, 31;
@%p3 bra LBB115_5;

mov.b32 %r17, %f19;
mov.u32 %r18, 2;
mov.u32 %r19, 31;
mov.u32 %r20, 16;
mov.u32 %r21, -1;
shfl.sync.down.b32 %r22|%p4, %r17, %r20, %r19, %r21;
mov.b32 %f9, %r22;
add.f32 %f10, %f19, %f9;
mov.b32 %r23, %f10;
mov.u32 %r24, 8;
shfl.sync.down.b32 %r25|%p5, %r23, %r24, %r19, %r21;
mov.b32 %f11, %r25;
add.f32 %f12, %f10, %f11;
mov.b32 %r26, %f12;
mov.u32 %r27, 4;
shfl.sync.down.b32 %r28|%p6, %r26, %r27, %r19, %r21;
mov.b32 %f13, %r28;
add.f32 %f14, %f12, %f13;
mov.b32 %r29, %f14;
shfl.sync.down.b32 %r30|%p7, %r29, %r18, %r19, %r21;
mov.b32 %f15, %r30;
add.f32 %f16, %f14, %f15;
mov.b32 %r31, %f16;
mov.u32 %r32, 1;
shfl.sync.down.b32 %r33|%p8, %r31, %r32, %r19, %r21;
mov.b32 %f17, %r33;
add.f32 %f19, %f16, %f17;

LBB115_5:
setp.ne.s32 %p9, %r6, 0;
@%p9 bra LBB115_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r8, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB115_7:
ret;

}

.visible .entry _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB116_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 11;
mov.f32 %f19, 0f00000000;

LBB116_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 1024;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB116_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB116_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB116_2;

LBB116_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB116_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB116_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB116_7;

LBB116_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB116_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB116_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 1024;
mov.u32 %r44, 1;
@%p9 bra LBB116_12;

mov.u32 %r32, 1024;
div.u32 %r44, %r32, %r45;

LBB116_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB116_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB116_16;

mov.u32 %r40, 31;

LBB116_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB116_15;

LBB116_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB116_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB116_18:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB117_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 10;
mov.f32 %f19, 0f00000000;

LBB117_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 512;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB117_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB117_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB117_2;

LBB117_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB117_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB117_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB117_7;

LBB117_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB117_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB117_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 512;
mov.u32 %r44, 1;
@%p9 bra LBB117_12;

mov.u32 %r32, 512;
div.u32 %r44, %r32, %r45;

LBB117_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB117_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB117_16;

mov.u32 %r40, 31;

LBB117_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB117_15;

LBB117_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB117_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB117_18:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB118_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 9;
mov.f32 %f19, 0f00000000;

LBB118_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 256;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB118_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB118_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB118_2;

LBB118_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB118_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB118_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB118_7;

LBB118_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB118_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB118_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 256;
mov.u32 %r44, 1;
@%p9 bra LBB118_12;

mov.u32 %r32, 256;
div.u32 %r44, %r32, %r45;

LBB118_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB118_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB118_16;

mov.u32 %r40, 31;

LBB118_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB118_15;

LBB118_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB118_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB118_18:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB119_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 8;
mov.f32 %f19, 0f00000000;

LBB119_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 128;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB119_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB119_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB119_2;

LBB119_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB119_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB119_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB119_7;

LBB119_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB119_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB119_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 128;
mov.u32 %r44, 1;
@%p9 bra LBB119_12;

mov.u32 %r32, 128;
div.u32 %r44, %r32, %r45;

LBB119_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB119_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB119_16;

mov.u32 %r40, 31;

LBB119_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB119_15;

LBB119_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB119_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB119_18:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB120_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 7;
mov.f32 %f19, 0f00000000;

LBB120_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 64;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB120_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB120_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB120_2;

LBB120_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB120_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB120_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB120_7;

LBB120_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB120_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB120_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 64;
mov.u32 %r44, 1;
@%p9 bra LBB120_12;

mov.u32 %r32, 64;
div.u32 %r44, %r32, %r45;

LBB120_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB120_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB120_16;

mov.u32 %r40, 31;

LBB120_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB120_15;

LBB120_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB120_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB120_18:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB121_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 6;
mov.f32 %f19, 0f00000000;

LBB121_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 32;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB121_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB121_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB121_2;

LBB121_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB121_8;

mov.u32 %r23, 31;
mov.u32 %r24, -1;
mov.u32 %r43, %r45;

LBB121_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB121_7;

LBB121_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB121_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB121_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 32;
mov.u32 %r44, 1;
@%p9 bra LBB121_12;

mov.u32 %r32, 32;
div.u32 %r44, %r32, %r45;

LBB121_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, -1;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB121_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB121_16;

mov.u32 %r40, 31;

LBB121_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB121_15;

LBB121_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB121_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB121_18:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB122_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 5;
mov.f32 %f19, 0f00000000;

LBB122_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 16;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB122_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB122_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB122_2;

LBB122_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB122_8;

mov.u32 %r23, 31;
mov.u32 %r24, 65535;
mov.u32 %r43, %r45;

LBB122_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB122_7;

LBB122_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB122_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB122_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 16;
mov.u32 %r44, 1;
@%p9 bra LBB122_12;

mov.u32 %r32, 16;
div.u32 %r44, %r32, %r45;

LBB122_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, 65535;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB122_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB122_16;

mov.u32 %r40, 31;

LBB122_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB122_15;

LBB122_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB122_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB122_18:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB123_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 4;
mov.f32 %f19, 0f00000000;

LBB123_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 8;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB123_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB123_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB123_2;

LBB123_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB123_8;

mov.u32 %r23, 31;
mov.u32 %r24, 255;
mov.u32 %r43, %r45;

LBB123_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB123_7;

LBB123_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB123_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB123_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 8;
mov.u32 %r44, 1;
@%p9 bra LBB123_12;

mov.u32 %r32, 8;
div.u32 %r44, %r32, %r45;

LBB123_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, 255;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB123_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB123_16;

mov.u32 %r40, 31;

LBB123_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB123_15;

LBB123_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB123_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB123_18:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB124_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 3;
mov.f32 %f19, 0f00000000;

LBB124_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 4;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB124_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB124_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB124_2;

LBB124_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB124_8;

mov.u32 %r23, 31;
mov.u32 %r24, 15;
mov.u32 %r43, %r45;

LBB124_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB124_7;

LBB124_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB124_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB124_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 4;
mov.u32 %r44, 1;
@%p9 bra LBB124_12;

mov.u32 %r32, 4;
div.u32 %r44, %r32, %r45;

LBB124_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, 15;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB124_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB124_16;

mov.u32 %r40, 31;

LBB124_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB124_15;

LBB124_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB124_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB124_18:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .f32 %f<26>;
.reg .b32 %r<46>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IfLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r42, %r18, %r2;
setp.ge.u32 %p2, %r42, %r17;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB125_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 2;
mov.f32 %f19, 0f00000000;

LBB125_2:
mul.wide.u32 %rd4, %r42, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r42, 2;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB125_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB125_4:
add.s32 %r42, %r42, %r4;
setp.lt.u32 %p4, %r42, %r17;
@%p4 bra LBB125_2;

LBB125_5:
mov.u32 %r45, WARP_SZ;
setp.lt.s32 %p5, %r45, 2;
@%p5 bra LBB125_8;

mov.u32 %r23, 31;
mov.u32 %r24, 3;
mov.u32 %r43, %r45;

LBB125_7:
mov.b32 %r20, %f19;
shr.u32 %r21, %r43, 31;
add.s32 %r22, %r43, %r21;
shr.s32 %r10, %r22, 1;
shfl.sync.down.b32 %r25|%p6, %r20, %r10, %r23, %r24;
mov.b32 %f17, %r25;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r43, 3;
mov.u32 %r43, %r10;
@%p7 bra LBB125_7;

LBB125_8:
rem.u32 %r26, %r2, %r45;
setp.ne.s32 %p8, %r26, 0;
@%p8 bra LBB125_10;

div.u32 %r27, %r2, %r45;
shl.b32 %r28, %r27, 2;
mov.u32 %r29, __smem;
add.s32 %r30, %r29, %r28;
st.shared.f32 [%r30], %f19;

LBB125_10:
bar.sync 0;
setp.gt.u32 %p9, %r45, 2;
mov.u32 %r44, 1;
@%p9 bra LBB125_12;

mov.u32 %r32, 2;
div.u32 %r44, %r32, %r45;

LBB125_12:
setp.ge.u32 %p10, %r2, %r44;
setp.lt.u32 %p11, %r2, %r44;
mov.u32 %r33, 3;
vote.sync.ballot.b32 %r13, %p11, %r33;
@%p10 bra LBB125_16;

shl.b32 %r34, %r2, 2;
mov.u32 %r35, __smem;
add.s32 %r36, %r35, %r34;
ld.shared.f32 %f19, [%r36];
@%p5 bra LBB125_16;

mov.u32 %r40, 31;

LBB125_15:
mov.b32 %r37, %f19;
shr.u32 %r38, %r45, 31;
add.s32 %r39, %r45, %r38;
shr.s32 %r16, %r39, 1;
shfl.sync.down.b32 %r41|%p13, %r37, %r16, %r40, %r13;
mov.b32 %f18, %r41;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p14, %r45, 3;
mov.u32 %r45, %r16;
@%p14 bra LBB125_15;

LBB125_16:
setp.ne.s32 %p15, %r2, 0;
@%p15 bra LBB125_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB125_18:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<26>;
.reg .b32 %r<38>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IfLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r35, %r16, %r2;
setp.ge.u32 %p2, %r35, %r15;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB126_5;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
mov.f32 %f19, 0f00000000;

LBB126_2:
mul.wide.u32 %rd4, %r35, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f15, [%rd5];
add.f32 %f19, %f19, %f15;
add.s32 %r6, %r35, 1;
setp.ge.u32 %p3, %r6, %r15;
@%p3 bra LBB126_4;

mul.wide.u32 %rd6, %r6, 4;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f32 %f16, [%rd7];
add.f32 %f19, %f19, %f16;

LBB126_4:
add.s32 %r35, %r35, %r4;
setp.lt.u32 %p4, %r35, %r15;
@%p4 bra LBB126_2;

LBB126_5:
mov.u32 %r37, WARP_SZ;
setp.lt.s32 %p5, %r37, 2;
@%p5 bra LBB126_8;

mov.u32 %r21, 31;
mov.u32 %r22, 1;
mov.u32 %r36, %r37;

LBB126_7:
mov.b32 %r18, %f19;
shr.u32 %r19, %r36, 31;
add.s32 %r20, %r36, %r19;
shr.s32 %r10, %r20, 1;
shfl.sync.down.b32 %r23|%p6, %r18, %r10, %r21, %r22;
mov.b32 %f17, %r23;
add.f32 %f19, %f19, %f17;
setp.gt.s32 %p7, %r36, 3;
mov.u32 %r36, %r10;
@%p7 bra LBB126_7;

LBB126_8:
rem.u32 %r24, %r2, %r37;
setp.ne.s32 %p8, %r24, 0;
@%p8 bra LBB126_10;

div.u32 %r25, %r2, %r37;
shl.b32 %r26, %r25, 2;
mov.u32 %r27, __smem;
add.s32 %r28, %r27, %r26;
st.shared.f32 [%r28], %f19;

LBB126_10:
bar.sync 0;
setp.ne.s32 %p9, %r2, 0;
setp.eq.s32 %p10, %r2, 0;
mov.u32 %r29, 1;
vote.sync.ballot.b32 %r11, %p10, %r29;
@%p9 bra LBB126_14;

ld.shared.f32 %f19, [__smem];
@%p5 bra LBB126_14;

mov.u32 %r33, 31;

LBB126_13:
mov.b32 %r30, %f19;
shr.u32 %r31, %r37, 31;
add.s32 %r32, %r37, %r31;
shr.s32 %r14, %r32, 1;
shfl.sync.down.b32 %r34|%p12, %r30, %r14, %r33, %r11;
mov.b32 %f18, %r34;
add.f32 %f19, %f19, %f18;
setp.gt.s32 %p13, %r37, 3;
mov.u32 %r37, %r14;
@%p13 bra LBB126_13;

LBB126_14:
@%p9 bra LBB126_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 4;
add.s64 %rd10, %rd8, %rd9;
st.global.f32 [%rd10], %f19;

LBB126_16:
ret;

}

.visible .entry _Z7reduce7IfLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB127_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB127_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB127_2;

LBB127_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB127_6;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

LBB127_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB127_5;

LBB127_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB127_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB127_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 512;
mov.u32 %r43, 1;
@%p8 bra LBB127_10;

mov.u32 %r31, 512;
div.u32 %r43, %r31, %r44;

LBB127_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB127_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB127_14;

mov.u32 %r39, 31;

LBB127_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB127_13;

LBB127_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB127_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB127_16:
ret;

}

.visible .entry _Z7reduce7IfLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB128_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB128_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB128_2;

LBB128_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB128_6;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

LBB128_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB128_5;

LBB128_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB128_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB128_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 256;
mov.u32 %r43, 1;
@%p8 bra LBB128_10;

mov.u32 %r31, 256;
div.u32 %r43, %r31, %r44;

LBB128_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB128_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB128_14;

mov.u32 %r39, 31;

LBB128_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB128_13;

LBB128_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB128_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB128_16:
ret;

}

.visible .entry _Z7reduce7IfLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB129_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB129_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB129_2;

LBB129_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB129_6;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

LBB129_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB129_5;

LBB129_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB129_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB129_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 128;
mov.u32 %r43, 1;
@%p8 bra LBB129_10;

mov.u32 %r31, 128;
div.u32 %r43, %r31, %r44;

LBB129_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB129_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB129_14;

mov.u32 %r39, 31;

LBB129_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB129_13;

LBB129_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB129_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB129_16:
ret;

}

.visible .entry _Z7reduce7IfLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB130_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB130_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB130_2;

LBB130_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB130_6;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

LBB130_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB130_5;

LBB130_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB130_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB130_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 64;
mov.u32 %r43, 1;
@%p8 bra LBB130_10;

mov.u32 %r31, 64;
div.u32 %r43, %r31, %r44;

LBB130_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB130_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB130_14;

mov.u32 %r39, 31;

LBB130_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB130_13;

LBB130_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB130_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB130_16:
ret;

}

.visible .entry _Z7reduce7IfLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB131_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB131_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB131_2;

LBB131_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB131_6;

mov.u32 %r22, 31;
mov.u32 %r23, -1;
mov.u32 %r42, %r44;

LBB131_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB131_5;

LBB131_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB131_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB131_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 32;
mov.u32 %r43, 1;
@%p8 bra LBB131_10;

mov.u32 %r31, 32;
div.u32 %r43, %r31, %r44;

LBB131_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, -1;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB131_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB131_14;

mov.u32 %r39, 31;

LBB131_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB131_13;

LBB131_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB131_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB131_16:
ret;

}

.visible .entry _Z7reduce7IfLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB132_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB132_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB132_2;

LBB132_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB132_6;

mov.u32 %r22, 31;
mov.u32 %r23, 65535;
mov.u32 %r42, %r44;

LBB132_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB132_5;

LBB132_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB132_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB132_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 16;
mov.u32 %r43, 1;
@%p8 bra LBB132_10;

mov.u32 %r31, 16;
div.u32 %r43, %r31, %r44;

LBB132_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 65535;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB132_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB132_14;

mov.u32 %r39, 31;

LBB132_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB132_13;

LBB132_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB132_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB132_16:
ret;

}

.visible .entry _Z7reduce7IfLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB133_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB133_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB133_2;

LBB133_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB133_6;

mov.u32 %r22, 31;
mov.u32 %r23, 255;
mov.u32 %r42, %r44;

LBB133_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB133_5;

LBB133_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB133_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB133_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 8;
mov.u32 %r43, 1;
@%p8 bra LBB133_10;

mov.u32 %r31, 8;
div.u32 %r43, %r31, %r44;

LBB133_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 255;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB133_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB133_14;

mov.u32 %r39, 31;

LBB133_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB133_13;

LBB133_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB133_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB133_16:
ret;

}

.visible .entry _Z7reduce7IfLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB134_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB134_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB134_2;

LBB134_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB134_6;

mov.u32 %r22, 31;
mov.u32 %r23, 15;
mov.u32 %r42, %r44;

LBB134_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB134_5;

LBB134_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB134_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB134_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 4;
mov.u32 %r43, 1;
@%p8 bra LBB134_10;

mov.u32 %r31, 4;
div.u32 %r43, %r31, %r44;

LBB134_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 15;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB134_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB134_14;

mov.u32 %r39, 31;

LBB134_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB134_13;

LBB134_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB134_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB134_16:
ret;

}

.visible .entry _Z7reduce7IfLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<15>;
.reg .f32 %f<22>;
.reg .b32 %r<45>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IfLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r41, %r17, %r2;
setp.ge.u32 %p2, %r41, %r16;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB135_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB135_2:
mul.wide.u32 %rd4, %r41, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r41, %r41, %r4;
setp.lt.u32 %p3, %r41, %r16;
@%p3 bra LBB135_2;

LBB135_3:
mov.u32 %r44, WARP_SZ;
setp.lt.s32 %p4, %r44, 2;
@%p4 bra LBB135_6;

mov.u32 %r22, 31;
mov.u32 %r23, 3;
mov.u32 %r42, %r44;

LBB135_5:
mov.b32 %r19, %f19;
shr.u32 %r20, %r42, 31;
add.s32 %r21, %r42, %r20;
shr.s32 %r9, %r21, 1;
shfl.sync.down.b32 %r24|%p5, %r19, %r9, %r22, %r23;
mov.b32 %f14, %r24;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r42, 3;
mov.u32 %r42, %r9;
@%p6 bra LBB135_5;

LBB135_6:
rem.u32 %r25, %r2, %r44;
setp.ne.s32 %p7, %r25, 0;
@%p7 bra LBB135_8;

div.u32 %r26, %r2, %r44;
shl.b32 %r27, %r26, 2;
mov.u32 %r28, __smem;
add.s32 %r29, %r28, %r27;
st.shared.f32 [%r29], %f19;

LBB135_8:
bar.sync 0;
setp.gt.u32 %p8, %r44, 2;
mov.u32 %r43, 1;
@%p8 bra LBB135_10;

mov.u32 %r31, 2;
div.u32 %r43, %r31, %r44;

LBB135_10:
setp.ge.u32 %p9, %r2, %r43;
setp.lt.u32 %p10, %r2, %r43;
mov.u32 %r32, 3;
vote.sync.ballot.b32 %r12, %p10, %r32;
@%p9 bra LBB135_14;

shl.b32 %r33, %r2, 2;
mov.u32 %r34, __smem;
add.s32 %r35, %r34, %r33;
ld.shared.f32 %f19, [%r35];
@%p4 bra LBB135_14;

mov.u32 %r39, 31;

LBB135_13:
mov.b32 %r36, %f19;
shr.u32 %r37, %r44, 31;
add.s32 %r38, %r44, %r37;
shr.s32 %r15, %r38, 1;
shfl.sync.down.b32 %r40|%p12, %r36, %r15, %r39, %r12;
mov.b32 %f15, %r40;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p13, %r44, 3;
mov.u32 %r44, %r15;
@%p13 bra LBB135_13;

LBB135_14:
setp.ne.s32 %p14, %r2, 0;
@%p14 bra LBB135_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB135_16:
ret;

}

.visible .entry _Z7reduce7IfLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<14>;
.reg .f32 %f<22>;
.reg .b32 %r<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IfLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r32, %r1, %r2;
setp.ge.u32 %p2, %r32, %r14;
mov.f32 %f19, 0f00000000;
@%p2 bra LBB136_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f19, 0f00000000;

LBB136_2:
mul.wide.u32 %rd4, %r32, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f32 %f13, [%rd5];
add.f32 %f19, %f19, %f13;
add.s32 %r32, %r32, %r4;
setp.lt.u32 %p3, %r32, %r14;
@%p3 bra LBB136_2;

LBB136_3:
mov.u32 %r34, WARP_SZ;
setp.lt.s32 %p4, %r34, 2;
@%p4 bra LBB136_6;

mov.u32 %r18, 31;
mov.u32 %r19, 1;
mov.u32 %r33, %r34;

LBB136_5:
mov.b32 %r15, %f19;
shr.u32 %r16, %r33, 31;
add.s32 %r17, %r33, %r16;
shr.s32 %r9, %r17, 1;
shfl.sync.down.b32 %r20|%p5, %r15, %r9, %r18, %r19;
mov.b32 %f14, %r20;
add.f32 %f19, %f19, %f14;
setp.gt.s32 %p6, %r33, 3;
mov.u32 %r33, %r9;
@%p6 bra LBB136_5;

LBB136_6:
rem.u32 %r21, %r2, %r34;
setp.ne.s32 %p7, %r21, 0;
@%p7 bra LBB136_8;

div.u32 %r22, %r2, %r34;
shl.b32 %r23, %r22, 2;
mov.u32 %r24, __smem;
add.s32 %r25, %r24, %r23;
st.shared.f32 [%r25], %f19;

LBB136_8:
bar.sync 0;
setp.ne.s32 %p8, %r2, 0;
setp.eq.s32 %p9, %r2, 0;
mov.u32 %r26, 1;
vote.sync.ballot.b32 %r10, %p9, %r26;
@%p8 bra LBB136_12;

ld.shared.f32 %f19, [__smem];
@%p4 bra LBB136_12;

mov.u32 %r30, 31;

LBB136_11:
mov.b32 %r27, %f19;
shr.u32 %r28, %r34, 31;
add.s32 %r29, %r34, %r28;
shr.s32 %r13, %r29, 1;
shfl.sync.down.b32 %r31|%p11, %r27, %r13, %r30, %r10;
mov.b32 %f15, %r31;
add.f32 %f19, %f19, %f15;
setp.gt.s32 %p12, %r34, 3;
mov.u32 %r34, %r13;
@%p12 bra LBB136_11;

LBB136_12:
@%p8 bra LBB136_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f19;

LBB136_14:
ret;

}

.visible .entry _Z9cg_reduceIfEvPT_S1_j(
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIfEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIfEvPT_S1_j_param_2
)
{
.reg .pred %p<13>;
.reg .f32 %f<29>;
.reg .b32 %r<97>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIfEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIfEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z9cg_reduceIfEvPT_S1_j_param_2];
mov.u32 %r11, %tid.x;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r17, %r15, %r16, %r11;
mul.lo.s32 %r18, %r16, %r12;
mov.u32 %r19, %ntid.z;
mul.lo.s32 %r96, %r18, %r19;
mov.u32 %r20, %ctaid.x;
mad.lo.s32 %r95, %r96, %r20, %r17;
setp.ge.u32 %p1, %r95, %r10;
mov.f32 %f26, 0f00000000;
@%p1 bra LBB137_3;

mov.u32 %r33, %nctaid.x;
mul.lo.s32 %r3, %r96, %r33;
cvta.to.global.u64 %rd1, %rd2;
mov.f32 %f26, 0f00000000;

LBB137_2:
mul.wide.u32 %rd4, %r95, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f12, [%rd5];
add.f32 %f26, %f26, %f12;
add.s32 %r95, %r95, %r3;
setp.lt.u32 %p2, %r95, %r10;
@%p2 bra LBB137_2;

LBB137_3:
shl.b32 %r40, %r17, 2;
mov.u32 %r41, __smem;
add.s32 %r42, %r41, %r40;
st.shared.f32 [%r42], %f26;
setp.lt.u32 %p3, %r96, 64;
@%p3 bra LBB137_7;

LBB137_4:
barrier.sync 0;
shr.u32 %r9, %r96, 1;
setp.ge.u32 %p4, %r17, %r9;
@%p4 bra LBB137_6;

shl.b32 %r60, %r9, 2;
add.s32 %r61, %r42, %r60;
ld.shared.f32 %f13, [%r61];
add.f32 %f26, %f26, %f13;
st.shared.f32 [%r42], %f26;

LBB137_6:
setp.gt.u32 %p5, %r96, 127;
mov.u32 %r96, %r9;
@%p5 bra LBB137_4;

LBB137_7:
barrier.sync 0;
shl.b32 %r69, %r17, 11;
setp.gt.u32 %p6, %r69, 65535;
@%p6 bra LBB137_9;

mov.b32 %r70, %f26;
mov.u32 %r71, 31;
mov.u32 %r72, 16;
mov.u32 %r73, -1;
shfl.sync.bfly.b32 %r74|%p7, %r70, %r72, %r71, %r73;
mov.b32 %f14, %r74;
add.f32 %f15, %f26, %f14;
mov.b32 %r75, %f15;
mov.u32 %r76, 8;
shfl.sync.bfly.b32 %r77|%p8, %r75, %r76, %r71, %r73;
mov.b32 %f16, %r77;
add.f32 %f17, %f15, %f16;
mov.b32 %r78, %f17;
mov.u32 %r79, 4;
shfl.sync.bfly.b32 %r80|%p9, %r78, %r79, %r71, %r73;
mov.b32 %f18, %r80;
add.f32 %f19, %f17, %f18;
mov.b32 %r81, %f19;
mov.u32 %r82, 2;
shfl.sync.bfly.b32 %r83|%p10, %r81, %r82, %r71, %r73;
mov.b32 %f20, %r83;
add.f32 %f21, %f19, %f20;
mov.b32 %r84, %f21;
mov.u32 %r85, 1;
shfl.sync.bfly.b32 %r86|%p11, %r84, %r85, %r71, %r73;
mov.b32 %f22, %r86;
add.f32 %f26, %f21, %f22;

LBB137_9:
setp.ne.s32 %p12, %r17, 0;
@%p12 bra LBB137_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r20, 4;
add.s64 %rd8, %rd6, %rd7;
st.global.f32 [%rd8], %f26;

LBB137_11:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<30>;
.reg .f32 %f<63>;
.reg .b32 %r<142>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch[256];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 31;
@%p1 bra LBB138_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

LBB138_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB138_6;

shl.b32 %r47, %r6, 10;
add.s32 %r133, %r47, %r3;
setp.ge.u32 %p3, %r133, %r37;
mov.f32 %f57, 0f00000000;
@%p3 bra LBB138_11;

shl.b32 %r8, %r5, 10;
mov.f32 %f57, 0f00000000;

LBB138_5:
mul.wide.u32 %rd5, %r133, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f57, %f57, %f18;
add.s32 %r133, %r133, %r8;
setp.lt.u32 %p4, %r133, %r37;
@%p4 bra LBB138_5;
bra.uni LBB138_11;

LBB138_6:
shl.b32 %r48, %r6, 11;
add.s32 %r134, %r48, %r3;
setp.ge.u32 %p5, %r134, %r37;
mov.f32 %f57, 0f00000000;
@%p5 bra LBB138_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 11;
mov.f32 %f57, 0f00000000;

LBB138_8:
cvt.u64.u32 %rd7, %r134;
mul.wide.u32 %rd8, %r134, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f57, %f57, %f21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB138_10;

add.s32 %r49, %r134, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f57, %f57, %f22;

LBB138_10:
add.s32 %r134, %r134, %r12;
setp.lt.u32 %p7, %r134, %r37;
@%p7 bra LBB138_8;

LBB138_11:
shr.u32 %r15, %r4, 9;
shr.u32 %r51, %r4, 3;
and.b32 %r52, %r51, 536870908;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r16, %r54, %r52;
mov.b32 %r55, %f57;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f57, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r16+128], %f32;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p13, %r17, 0;
bar.warp.sync -1;
mov.u32 %r135, %r50;
@%p13 bra LBB138_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r54;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r135,[%rd13],%r69;


LBB138_13:
shfl.sync.idx.b32 %r20|%p14, %r135, %r50, %r56, %r58;
add.s32 %r77, %r20, 1;
and.b32 %r78, %r77, 2147483647;
setp.eq.s32 %p15, %r78, 16;
shl.b32 %r79, %r15, 2;
add.s32 %r21, %r54, %r79;
@%p15 bra LBB138_15;
bra.uni LBB138_14;

LBB138_15:
and.b32 %r83, %r4, 16;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra LBB138_17;

and.b32 %r88, %r4, 15;
and.b32 %r89, %r4, -512;
shr.u32 %r90, %r89, 5;
or.b32 %r91, %r90, %r88;
shl.b32 %r92, %r91, 2;
add.s32 %r95, %r54, %r92;
ld.shared.f32 %f33, [%r95+128];

	mov.u32 %r84, %laneid;

	and.b32 %r96, %r84, -16;
mov.u32 %r97, 65535;
shl.b32 %r98, %r97, %r96;
mov.b32 %r99, %f33;
mov.u32 %r100, 4127;
shfl.sync.bfly.b32 %r102|%p18, %r99, %r61, %r100, %r98;
mov.b32 %f34, %r102;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r103, %r85, -16;
shl.b32 %r104, %r97, %r103;
mov.b32 %r105, %f35;
shfl.sync.bfly.b32 %r107|%p19, %r105, %r64, %r100, %r104;
mov.b32 %f36, %r107;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r108, %r86, -16;
shl.b32 %r109, %r97, %r108;
mov.b32 %r110, %f37;
shfl.sync.bfly.b32 %r111|%p20, %r110, %r53, %r100, %r109;
mov.b32 %f38, %r111;
add.f32 %f39, %f37, %f38;

	mov.u32 %r87, %laneid;

	and.b32 %r112, %r87, -16;
shl.b32 %r113, %r97, %r112;
mov.b32 %r114, %f39;
shfl.sync.bfly.b32 %r116|%p21, %r114, %r69, %r100, %r113;
mov.b32 %f40, %r116;
add.f32 %f41, %f39, %f40;
st.shared.f32 [%r95+128], %f41;

LBB138_17:
bar.warp.sync -1;
@%p13 bra LBB138_19;

ld.volatile.shared.u32 %r117, [%r21+8];
not.b32 %r118, %r117;
and.b32 %r119, %r118, -2147483648;
st.volatile.shared.u32 [%r21+8], %r119;
bra.uni LBB138_19;

LBB138_14:
ld.volatile.shared.u32 %r81, [%r21+8];
xor.b32 %r82, %r81, %r20;
setp.gt.s32 %p16, %r82, -1;
@%p16 bra LBB138_14;

LBB138_19:
ld.shared.f32 %f8, [%r16+128];
bar.warp.sync -1;
and.b32 %r120, %r4, 511;
setp.ne.s32 %p23, %r120, 0;
@%p23 bra LBB138_21;

mov.u32 %r122, __smem;
add.s32 %r123, %r122, %r79;
st.shared.f32 [%r123], %f8;

LBB138_21:
barrier.sync 0;
setp.ne.s32 %p24, %r3, 0;
@%p24 bra LBB138_30;

mul.lo.s32 %r124, %r2, %r1;
mov.u32 %r125, %ntid.z;
mad.lo.s32 %r126, %r124, %r125, 511;
shr.u32 %r22, %r126, 9;
setp.eq.s32 %p25, %r22, 0;
mov.f32 %f62, 0f00000000;
@%p25 bra LBB138_29;

add.s32 %r128, %r22, -1;
and.b32 %r141, %r22, 3;
setp.lt.u32 %p26, %r128, 3;
mov.f32 %f62, 0f00000000;
mov.u32 %r139, 0;
@%p26 bra LBB138_26;

sub.s32 %r138, %r22, %r141;
mov.f32 %f62, 0f00000000;
mov.u32 %r139, 0;
mov.u32 %r136, __smem;

LBB138_25:
ld.shared.f32 %f46, [%r136];
add.f32 %f47, %f62, %f46;
ld.shared.f32 %f48, [%r136+4];
add.f32 %f49, %f47, %f48;
ld.shared.f32 %f50, [%r136+8];
add.f32 %f51, %f49, %f50;
ld.shared.f32 %f52, [%r136+12];
add.f32 %f62, %f51, %f52;
add.s32 %r139, %r139, 4;
add.s32 %r136, %r136, 16;
add.s32 %r138, %r138, -4;
setp.ne.s32 %p27, %r138, 0;
@%p27 bra LBB138_25;

LBB138_26:
setp.eq.s32 %p28, %r141, 0;
@%p28 bra LBB138_29;

shl.b32 %r131, %r139, 2;
mov.u32 %r132, __smem;
add.s32 %r140, %r132, %r131;

LBB138_28:
.pragma "nounroll";
ld.shared.f32 %f53, [%r140];
add.f32 %f62, %f62, %f53;
add.s32 %r140, %r140, 4;
add.s32 %r141, %r141, -1;
setp.ne.s32 %p29, %r141, 0;
@%p29 bra LBB138_28;

LBB138_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 4;
add.s64 %rd19, %rd17, %rd18;
st.global.f32 [%rd19], %f62;

LBB138_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<29>;
.reg .f32 %f<61>;
.reg .b32 %r<136>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch[128];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 15;
@%p1 bra LBB139_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

LBB139_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB139_6;

shl.b32 %r47, %r6, 9;
add.s32 %r127, %r47, %r3;
setp.ge.u32 %p3, %r127, %r37;
mov.f32 %f55, 0f00000000;
@%p3 bra LBB139_11;

shl.b32 %r8, %r5, 9;
mov.f32 %f55, 0f00000000;

LBB139_5:
mul.wide.u32 %rd5, %r127, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f55, %f55, %f18;
add.s32 %r127, %r127, %r8;
setp.lt.u32 %p4, %r127, %r37;
@%p4 bra LBB139_5;
bra.uni LBB139_11;

LBB139_6:
shl.b32 %r48, %r6, 10;
add.s32 %r128, %r48, %r3;
setp.ge.u32 %p5, %r128, %r37;
mov.f32 %f55, 0f00000000;
@%p5 bra LBB139_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 10;
mov.f32 %f55, 0f00000000;

LBB139_8:
cvt.u64.u32 %rd7, %r128;
mul.wide.u32 %rd8, %r128, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f55, %f55, %f21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB139_10;

add.s32 %r49, %r128, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f55, %f55, %f22;

LBB139_10:
add.s32 %r128, %r128, %r12;
setp.lt.u32 %p7, %r128, %r37;
@%p7 bra LBB139_8;

LBB139_11:
shr.u32 %r15, %r4, 8;
mov.u32 %r51, 8;
shr.u32 %r52, %r4, 3;
and.b32 %r53, %r52, 536870908;
mov.u32 %r54, 2;
mov.u32 %r55, _ZZ20multi_warp_cg_reduceIfLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r16, %r55, %r53;
mov.b32 %r56, %f55;
mov.u32 %r57, 31;
mov.u32 %r58, 16;
mov.u32 %r59, -1;
shfl.sync.bfly.b32 %r60|%p8, %r56, %r58, %r57, %r59;
mov.b32 %f23, %r60;
add.f32 %f24, %f55, %f23;
mov.b32 %r61, %f24;
shfl.sync.bfly.b32 %r62|%p9, %r61, %r51, %r57, %r59;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r57, %r59;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r54, %r57, %r59;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r57, %r59;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r16+64], %f32;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p13, %r17, 0;
bar.warp.sync -1;
mov.u32 %r129, %r50;
@%p13 bra LBB139_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r55;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r129,[%rd13],%r69;


LBB139_13:
shfl.sync.idx.b32 %r20|%p14, %r129, %r50, %r57, %r59;
add.s32 %r77, %r20, 1;
and.b32 %r78, %r77, 2147483647;
setp.eq.s32 %p15, %r78, 8;
shl.b32 %r79, %r15, 2;
add.s32 %r21, %r55, %r79;
@%p15 bra LBB139_15;
bra.uni LBB139_14;

LBB139_15:
and.b32 %r83, %r4, 24;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra LBB139_17;

and.b32 %r87, %r4, 7;
and.b32 %r88, %r4, -256;
shr.u32 %r89, %r88, 5;
or.b32 %r90, %r89, %r87;
shl.b32 %r91, %r90, 2;
add.s32 %r94, %r55, %r91;
ld.shared.f32 %f33, [%r94+64];

	mov.u32 %r84, %laneid;

	and.b32 %r95, %r84, -8;
mov.u32 %r96, 255;
shl.b32 %r97, %r96, %r95;
mov.b32 %r98, %f33;
mov.u32 %r99, 6175;
shfl.sync.bfly.b32 %r101|%p18, %r98, %r64, %r99, %r97;
mov.b32 %f34, %r101;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r102, %r85, -8;
shl.b32 %r103, %r96, %r102;
mov.b32 %r104, %f35;
shfl.sync.bfly.b32 %r105|%p19, %r104, %r54, %r99, %r103;
mov.b32 %f36, %r105;
add.f32 %f37, %f35, %f36;

	mov.u32 %r86, %laneid;

	and.b32 %r106, %r86, -8;
shl.b32 %r107, %r96, %r106;
mov.b32 %r108, %f37;
shfl.sync.bfly.b32 %r110|%p20, %r108, %r69, %r99, %r107;
mov.b32 %f38, %r110;
add.f32 %f39, %f37, %f38;
st.shared.f32 [%r94+64], %f39;

LBB139_17:
bar.warp.sync -1;
@%p13 bra LBB139_19;

ld.volatile.shared.u32 %r111, [%r21+8];
not.b32 %r112, %r111;
and.b32 %r113, %r112, -2147483648;
st.volatile.shared.u32 [%r21+8], %r113;
bra.uni LBB139_19;

LBB139_14:
ld.volatile.shared.u32 %r81, [%r21+8];
xor.b32 %r82, %r81, %r20;
setp.gt.s32 %p16, %r82, -1;
@%p16 bra LBB139_14;

LBB139_19:
ld.shared.f32 %f8, [%r16+64];
bar.warp.sync -1;
and.b32 %r114, %r4, 255;
setp.ne.s32 %p22, %r114, 0;
@%p22 bra LBB139_21;

mov.u32 %r116, __smem;
add.s32 %r117, %r116, %r79;
st.shared.f32 [%r117], %f8;

LBB139_21:
barrier.sync 0;
setp.ne.s32 %p23, %r3, 0;
@%p23 bra LBB139_30;

mul.lo.s32 %r118, %r2, %r1;
mov.u32 %r119, %ntid.z;
mad.lo.s32 %r120, %r118, %r119, 255;
shr.u32 %r22, %r120, 8;
setp.eq.s32 %p24, %r22, 0;
mov.f32 %f60, 0f00000000;
@%p24 bra LBB139_29;

add.s32 %r122, %r22, -1;
and.b32 %r135, %r22, 3;
setp.lt.u32 %p25, %r122, 3;
mov.f32 %f60, 0f00000000;
mov.u32 %r133, 0;
@%p25 bra LBB139_26;

sub.s32 %r132, %r22, %r135;
mov.f32 %f60, 0f00000000;
mov.u32 %r133, 0;
mov.u32 %r130, __smem;

LBB139_25:
ld.shared.f32 %f44, [%r130];
add.f32 %f45, %f60, %f44;
ld.shared.f32 %f46, [%r130+4];
add.f32 %f47, %f45, %f46;
ld.shared.f32 %f48, [%r130+8];
add.f32 %f49, %f47, %f48;
ld.shared.f32 %f50, [%r130+12];
add.f32 %f60, %f49, %f50;
add.s32 %r133, %r133, 4;
add.s32 %r130, %r130, 16;
add.s32 %r132, %r132, -4;
setp.ne.s32 %p26, %r132, 0;
@%p26 bra LBB139_25;

LBB139_26:
setp.eq.s32 %p27, %r135, 0;
@%p27 bra LBB139_29;

shl.b32 %r125, %r133, 2;
mov.u32 %r126, __smem;
add.s32 %r134, %r126, %r125;

LBB139_28:
.pragma "nounroll";
ld.shared.f32 %f51, [%r134];
add.f32 %f60, %f60, %f51;
add.s32 %r134, %r134, 4;
add.s32 %r135, %r135, -1;
setp.ne.s32 %p28, %r135, 0;
@%p28 bra LBB139_28;

LBB139_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 4;
add.s64 %rd19, %rd17, %rd18;
st.global.f32 [%rd19], %f60;

LBB139_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<28>;
.reg .f32 %f<59>;
.reg .b32 %r<130>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch[64];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra LBB140_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

LBB140_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB140_6;

shl.b32 %r47, %r6, 8;
add.s32 %r121, %r47, %r3;
setp.ge.u32 %p3, %r121, %r37;
mov.f32 %f53, 0f00000000;
@%p3 bra LBB140_11;

shl.b32 %r8, %r5, 8;
mov.f32 %f53, 0f00000000;

LBB140_5:
mul.wide.u32 %rd5, %r121, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f53, %f53, %f18;
add.s32 %r121, %r121, %r8;
setp.lt.u32 %p4, %r121, %r37;
@%p4 bra LBB140_5;
bra.uni LBB140_11;

LBB140_6:
shl.b32 %r48, %r6, 9;
add.s32 %r122, %r48, %r3;
setp.ge.u32 %p5, %r122, %r37;
mov.f32 %f53, 0f00000000;
@%p5 bra LBB140_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 9;
mov.f32 %f53, 0f00000000;

LBB140_8:
cvt.u64.u32 %rd7, %r122;
mul.wide.u32 %rd8, %r122, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f53, %f53, %f21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB140_10;

add.s32 %r49, %r122, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f53, %f53, %f22;

LBB140_10:
add.s32 %r122, %r122, %r12;
setp.lt.u32 %p7, %r122, %r37;
@%p7 bra LBB140_8;

LBB140_11:
shr.u32 %r15, %r4, 7;
shr.u32 %r51, %r4, 3;
and.b32 %r52, %r51, 536870908;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r16, %r54, %r52;
mov.b32 %r55, %f53;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f53, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r16+32], %f32;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p13, %r17, 0;
bar.warp.sync -1;
mov.u32 %r123, %r50;
@%p13 bra LBB140_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r54;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r123,[%rd13],%r69;


LBB140_13:
shfl.sync.idx.b32 %r20|%p14, %r123, %r50, %r56, %r58;
add.s32 %r77, %r20, 1;
and.b32 %r78, %r77, 2147483647;
setp.eq.s32 %p15, %r78, 4;
shl.b32 %r79, %r15, 2;
add.s32 %r21, %r54, %r79;
@%p15 bra LBB140_15;
bra.uni LBB140_14;

LBB140_15:
and.b32 %r83, %r4, 28;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra LBB140_17;

and.b32 %r86, %r4, 3;
and.b32 %r87, %r4, -128;
shr.u32 %r88, %r87, 5;
or.b32 %r89, %r88, %r86;
shl.b32 %r90, %r89, 2;
add.s32 %r93, %r54, %r90;
ld.shared.f32 %f33, [%r93+32];

	mov.u32 %r84, %laneid;

	and.b32 %r94, %r84, -4;
mov.u32 %r95, 15;
shl.b32 %r96, %r95, %r94;
mov.b32 %r97, %f33;
mov.u32 %r98, 7199;
shfl.sync.bfly.b32 %r99|%p18, %r97, %r53, %r98, %r96;
mov.b32 %f34, %r99;
add.f32 %f35, %f33, %f34;

	mov.u32 %r85, %laneid;

	and.b32 %r100, %r85, -4;
shl.b32 %r101, %r95, %r100;
mov.b32 %r102, %f35;
shfl.sync.bfly.b32 %r104|%p19, %r102, %r69, %r98, %r101;
mov.b32 %f36, %r104;
add.f32 %f37, %f35, %f36;
st.shared.f32 [%r93+32], %f37;

LBB140_17:
bar.warp.sync -1;
@%p13 bra LBB140_19;

ld.volatile.shared.u32 %r105, [%r21+8];
not.b32 %r106, %r105;
and.b32 %r107, %r106, -2147483648;
st.volatile.shared.u32 [%r21+8], %r107;
bra.uni LBB140_19;

LBB140_14:
ld.volatile.shared.u32 %r81, [%r21+8];
xor.b32 %r82, %r81, %r20;
setp.gt.s32 %p16, %r82, -1;
@%p16 bra LBB140_14;

LBB140_19:
ld.shared.f32 %f8, [%r16+32];
bar.warp.sync -1;
and.b32 %r108, %r4, 127;
setp.ne.s32 %p21, %r108, 0;
@%p21 bra LBB140_21;

mov.u32 %r110, __smem;
add.s32 %r111, %r110, %r79;
st.shared.f32 [%r111], %f8;

LBB140_21:
barrier.sync 0;
setp.ne.s32 %p22, %r3, 0;
@%p22 bra LBB140_30;

mul.lo.s32 %r112, %r2, %r1;
mov.u32 %r113, %ntid.z;
mad.lo.s32 %r114, %r112, %r113, 127;
shr.u32 %r22, %r114, 7;
setp.eq.s32 %p23, %r22, 0;
mov.f32 %f58, 0f00000000;
@%p23 bra LBB140_29;

add.s32 %r116, %r22, -1;
and.b32 %r129, %r22, 3;
setp.lt.u32 %p24, %r116, 3;
mov.f32 %f58, 0f00000000;
mov.u32 %r127, 0;
@%p24 bra LBB140_26;

sub.s32 %r126, %r22, %r129;
mov.f32 %f58, 0f00000000;
mov.u32 %r127, 0;
mov.u32 %r124, __smem;

LBB140_25:
ld.shared.f32 %f42, [%r124];
add.f32 %f43, %f58, %f42;
ld.shared.f32 %f44, [%r124+4];
add.f32 %f45, %f43, %f44;
ld.shared.f32 %f46, [%r124+8];
add.f32 %f47, %f45, %f46;
ld.shared.f32 %f48, [%r124+12];
add.f32 %f58, %f47, %f48;
add.s32 %r127, %r127, 4;
add.s32 %r124, %r124, 16;
add.s32 %r126, %r126, -4;
setp.ne.s32 %p25, %r126, 0;
@%p25 bra LBB140_25;

LBB140_26:
setp.eq.s32 %p26, %r129, 0;
@%p26 bra LBB140_29;

shl.b32 %r119, %r127, 2;
mov.u32 %r120, __smem;
add.s32 %r128, %r120, %r119;

LBB140_28:
.pragma "nounroll";
ld.shared.f32 %f49, [%r128];
add.f32 %f58, %f58, %f49;
add.s32 %r128, %r128, 4;
add.s32 %r129, %r129, -1;
setp.ne.s32 %p27, %r129, 0;
@%p27 bra LBB140_28;

LBB140_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 4;
add.s64 %rd19, %rd17, %rd18;
st.global.f32 [%rd19], %f58;

LBB140_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<27>;
.reg .f32 %f<57>;
.reg .b32 %r<124>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch[32];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r37, [_Z20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r38, %tid.z;
mov.u32 %r39, %tid.y;
mad.lo.s32 %r40, %r1, %r38, %r39;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r40, %r2, %r3;
setp.gt.u32 %p1, %r4, 3;
@%p1 bra LBB141_2;

shl.b32 %r41, %r4, 2;
mov.u32 %r42, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r43, %r42, %r41;
mov.u32 %r44, 0;
st.shared.u32 [%r43], %r44;

LBB141_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r45, %r37, -1;
and.b32 %r46, %r45, %r37;
setp.eq.s32 %p2, %r46, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB141_6;

shl.b32 %r47, %r6, 7;
add.s32 %r115, %r47, %r3;
setp.ge.u32 %p3, %r115, %r37;
mov.f32 %f51, 0f00000000;
@%p3 bra LBB141_11;

shl.b32 %r8, %r5, 7;
mov.f32 %f51, 0f00000000;

LBB141_5:
mul.wide.u32 %rd5, %r115, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f18, [%rd6];
add.f32 %f51, %f51, %f18;
add.s32 %r115, %r115, %r8;
setp.lt.u32 %p4, %r115, %r37;
@%p4 bra LBB141_5;
bra.uni LBB141_11;

LBB141_6:
shl.b32 %r48, %r6, 8;
add.s32 %r116, %r48, %r3;
setp.ge.u32 %p5, %r116, %r37;
mov.f32 %f51, 0f00000000;
@%p5 bra LBB141_11;

cvt.u64.u32 %rd2, %r37;
shl.b32 %r12, %r5, 8;
mov.f32 %f51, 0f00000000;

LBB141_8:
cvt.u64.u32 %rd7, %r116;
mul.wide.u32 %rd8, %r116, 4;
add.s64 %rd9, %rd1, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f51, %f51, %f21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB141_10;

add.s32 %r49, %r116, %r2;
mul.wide.u32 %rd11, %r49, 4;
add.s64 %rd12, %rd1, %rd11;
ld.global.f32 %f22, [%rd12];
add.f32 %f51, %f51, %f22;

LBB141_10:
add.s32 %r116, %r116, %r12;
setp.lt.u32 %p7, %r116, %r37;
@%p7 bra LBB141_8;

LBB141_11:
shr.u32 %r15, %r4, 6;
shr.u32 %r51, %r4, 3;
and.b32 %r52, %r51, 536870908;
mov.u32 %r53, 2;
mov.u32 %r54, _ZZ20multi_warp_cg_reduceIfLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r16, %r54, %r52;
mov.b32 %r55, %f51;
mov.u32 %r56, 31;
mov.u32 %r57, 16;
mov.u32 %r58, -1;
shfl.sync.bfly.b32 %r59|%p8, %r55, %r57, %r56, %r58;
mov.b32 %f23, %r59;
add.f32 %f24, %f51, %f23;
mov.b32 %r60, %f24;
mov.u32 %r61, 8;
shfl.sync.bfly.b32 %r62|%p9, %r60, %r61, %r56, %r58;
mov.b32 %f25, %r62;
add.f32 %f26, %f24, %f25;
mov.b32 %r63, %f26;
mov.u32 %r64, 4;
shfl.sync.bfly.b32 %r65|%p10, %r63, %r64, %r56, %r58;
mov.b32 %f27, %r65;
add.f32 %f28, %f26, %f27;
mov.b32 %r66, %f28;
shfl.sync.bfly.b32 %r67|%p11, %r66, %r53, %r56, %r58;
mov.b32 %f29, %r67;
add.f32 %f30, %f28, %f29;
mov.b32 %r68, %f30;
mov.u32 %r69, 1;
shfl.sync.bfly.b32 %r70|%p12, %r68, %r69, %r56, %r58;
mov.b32 %f31, %r70;
add.f32 %f32, %f30, %f31;
mov.u32 %r50, 0;
st.shared.f32 [%r16+16], %f32;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p13, %r17, 0;
bar.warp.sync -1;
mov.u32 %r117, %r50;
@%p13 bra LBB141_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r54;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r117,[%rd13],%r69;


LBB141_13:
shfl.sync.idx.b32 %r20|%p14, %r117, %r50, %r56, %r58;
add.s32 %r77, %r20, 1;
and.b32 %r78, %r77, 2147483647;
setp.eq.s32 %p15, %r78, 2;
shl.b32 %r79, %r15, 2;
add.s32 %r21, %r54, %r79;
@%p15 bra LBB141_15;
bra.uni LBB141_14;

LBB141_15:
and.b32 %r83, %r4, 30;
setp.ne.s32 %p17, %r83, 0;
@%p17 bra LBB141_17;

and.b32 %r85, %r4, 1;
and.b32 %r87, %r4, -64;
shr.u32 %r88, %r87, 5;
or.b32 %r89, %r88, %r85;
shl.b32 %r90, %r89, 2;
add.s32 %r92, %r54, %r90;
ld.shared.f32 %f33, [%r92+16];

	mov.u32 %r84, %laneid;

	and.b32 %r93, %r84, -2;
mov.u32 %r94, 3;
shl.b32 %r95, %r94, %r93;
mov.b32 %r96, %f33;
mov.u32 %r97, 7711;
shfl.sync.bfly.b32 %r98|%p18, %r96, %r69, %r97, %r95;
mov.b32 %f34, %r98;
add.f32 %f35, %f33, %f34;
st.shared.f32 [%r92+16], %f35;

LBB141_17:
bar.warp.sync -1;
@%p13 bra LBB141_19;

ld.volatile.shared.u32 %r99, [%r21+8];
not.b32 %r100, %r99;
and.b32 %r101, %r100, -2147483648;
st.volatile.shared.u32 [%r21+8], %r101;
bra.uni LBB141_19;

LBB141_14:
ld.volatile.shared.u32 %r81, [%r21+8];
xor.b32 %r82, %r81, %r20;
setp.gt.s32 %p16, %r82, -1;
@%p16 bra LBB141_14;

LBB141_19:
ld.shared.f32 %f8, [%r16+16];
bar.warp.sync -1;
and.b32 %r102, %r4, 63;
setp.ne.s32 %p20, %r102, 0;
@%p20 bra LBB141_21;

mov.u32 %r104, __smem;
add.s32 %r105, %r104, %r79;
st.shared.f32 [%r105], %f8;

LBB141_21:
barrier.sync 0;
setp.ne.s32 %p21, %r3, 0;
@%p21 bra LBB141_30;

mul.lo.s32 %r106, %r2, %r1;
mov.u32 %r107, %ntid.z;
mad.lo.s32 %r108, %r106, %r107, 63;
shr.u32 %r22, %r108, 6;
setp.eq.s32 %p22, %r22, 0;
mov.f32 %f56, 0f00000000;
@%p22 bra LBB141_29;

add.s32 %r110, %r22, -1;
and.b32 %r123, %r22, 3;
setp.lt.u32 %p23, %r110, 3;
mov.f32 %f56, 0f00000000;
mov.u32 %r121, 0;
@%p23 bra LBB141_26;

sub.s32 %r120, %r22, %r123;
mov.f32 %f56, 0f00000000;
mov.u32 %r121, 0;
mov.u32 %r118, __smem;

LBB141_25:
ld.shared.f32 %f40, [%r118];
add.f32 %f41, %f56, %f40;
ld.shared.f32 %f42, [%r118+4];
add.f32 %f43, %f41, %f42;
ld.shared.f32 %f44, [%r118+8];
add.f32 %f45, %f43, %f44;
ld.shared.f32 %f46, [%r118+12];
add.f32 %f56, %f45, %f46;
add.s32 %r121, %r121, 4;
add.s32 %r118, %r118, 16;
add.s32 %r120, %r120, -4;
setp.ne.s32 %p24, %r120, 0;
@%p24 bra LBB141_25;

LBB141_26:
setp.eq.s32 %p25, %r123, 0;
@%p25 bra LBB141_29;

shl.b32 %r113, %r121, 2;
mov.u32 %r114, __smem;
add.s32 %r122, %r114, %r113;

LBB141_28:
.pragma "nounroll";
ld.shared.f32 %f47, [%r122];
add.f32 %f56, %f56, %f47;
add.s32 %r122, %r122, 4;
add.s32 %r123, %r123, -1;
setp.ne.s32 %p26, %r123, 0;
@%p26 bra LBB141_28;

LBB141_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 4;
add.s64 %rd19, %rd17, %rd18;
st.global.f32 [%rd19], %f56;

LBB141_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .f32 %f<53>;
.reg .b32 %r<98>;
.reg .b64 %rd<18>;


ld.param.u64 %rd2, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r23, [_Z20multi_warp_cg_reduceIfLm64ELm32EEvPT_S1_j_param_2];
barrier.sync 0;
add.s32 %r24, %r23, -1;
and.b32 %r25, %r24, %r23;
setp.eq.s32 %p1, %r25, 0;
@%p1 bra LBB142_4;

mov.u32 %r26, %ctaid.x;
shl.b32 %r27, %r26, 6;
mov.u32 %r28, %tid.x;
add.s32 %r90, %r27, %r28;
setp.ge.u32 %p2, %r90, %r23;
mov.f32 %f47, 0f00000000;
@%p2 bra LBB142_9;

cvta.to.global.u64 %rd1, %rd2;
mov.u32 %r29, %nctaid.x;
shl.b32 %r2, %r29, 6;
mov.f32 %f47, 0f00000000;

LBB142_3:
mul.wide.u32 %rd4, %r90, 4;
add.s64 %rd5, %rd1, %rd4;
ld.global.f32 %f18, [%rd5];
add.f32 %f47, %f47, %f18;
add.s32 %r90, %r90, %r2;
setp.lt.u32 %p3, %r90, %r23;
@%p3 bra LBB142_3;
bra.uni LBB142_9;

LBB142_4:
mov.u32 %r30, %ctaid.x;
shl.b32 %r31, %r30, 7;
mov.u32 %r32, %tid.x;
add.s32 %r91, %r31, %r32;
setp.ge.u32 %p4, %r91, %r23;
mov.f32 %f47, 0f00000000;
@%p4 bra LBB142_9;

mov.f32 %f47, 0f00000000;
cvta.to.global.u64 %rd6, %rd2;
cvt.u64.u32 %rd11, %r23;
mov.u32 %r37, %ntid.x;
mov.u32 %r39, %nctaid.x;
shl.b32 %r40, %r39, 7;

LBB142_6:
cvt.u64.u32 %rd7, %r91;
mul.wide.u32 %rd8, %r91, 4;
add.s64 %rd9, %rd6, %rd8;
ld.global.f32 %f21, [%rd9];
add.f32 %f47, %f47, %f21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd11;
@%p5 bra LBB142_8;

add.s32 %r38, %r91, %r37;
mul.wide.u32 %rd13, %r38, 4;
add.s64 %rd14, %rd6, %rd13;
ld.global.f32 %f22, [%rd14];
add.f32 %f47, %f47, %f22;

LBB142_8:
add.s32 %r91, %r91, %r40;
setp.lt.u32 %p6, %r91, %r23;
@%p6 bra LBB142_6;

LBB142_9:
mov.b32 %r41, %f47;
mov.u32 %r42, 31;
mov.u32 %r43, 16;
mov.u32 %r44, -1;
shfl.sync.bfly.b32 %r45|%p7, %r41, %r43, %r42, %r44;
mov.b32 %f23, %r45;
add.f32 %f24, %f47, %f23;
mov.b32 %r46, %f24;
mov.u32 %r47, 8;
shfl.sync.bfly.b32 %r48|%p8, %r46, %r47, %r42, %r44;
mov.b32 %f25, %r48;
add.f32 %f26, %f24, %f25;
mov.b32 %r49, %f26;
mov.u32 %r50, 4;
shfl.sync.bfly.b32 %r51|%p9, %r49, %r50, %r42, %r44;
mov.b32 %f27, %r51;
add.f32 %f28, %f26, %f27;
mov.b32 %r52, %f28;
mov.u32 %r53, 2;
shfl.sync.bfly.b32 %r54|%p10, %r52, %r53, %r42, %r44;
mov.b32 %f29, %r54;
add.f32 %f30, %f28, %f29;
mov.b32 %r55, %f30;
mov.u32 %r56, 1;
shfl.sync.bfly.b32 %r57|%p11, %r55, %r56, %r42, %r44;
mov.b32 %f31, %r57;
add.f32 %f8, %f30, %f31;
mov.u32 %r58, %tid.z;
mov.u32 %r59, %ntid.y;
mov.u32 %r60, %tid.y;
mad.lo.s32 %r61, %r59, %r58, %r60;
mov.u32 %r62, %ntid.x;
mov.u32 %r63, %tid.x;
mad.lo.s32 %r64, %r61, %r62, %r63;
and.b32 %r65, %r64, 31;
setp.ne.s32 %p12, %r65, 0;
@%p12 bra LBB142_11;

shr.u32 %r73, %r64, 3;
and.b32 %r74, %r73, 536870908;
mov.u32 %r75, __smem;
add.s32 %r76, %r75, %r74;
st.shared.f32 [%r76], %f8;

LBB142_11:
barrier.sync 0;
setp.ne.s32 %p13, %r63, 0;
@%p13 bra LBB142_20;

mul.lo.s32 %r80, %r62, %r59;
mov.u32 %r81, %ntid.z;
mad.lo.s32 %r82, %r80, %r81, 31;
shr.u32 %r8, %r82, 5;
setp.eq.s32 %p14, %r8, 0;
mov.f32 %f52, 0f00000000;
@%p14 bra LBB142_19;

add.s32 %r84, %r8, -1;
and.b32 %r97, %r8, 3;
setp.lt.u32 %p15, %r84, 3;
mov.f32 %f52, 0f00000000;
mov.u32 %r95, 0;
@%p15 bra LBB142_16;

sub.s32 %r94, %r8, %r97;
mov.f32 %f52, 0f00000000;
mov.u32 %r95, 0;
mov.u32 %r92, __smem;

LBB142_15:
ld.shared.f32 %f36, [%r92];
add.f32 %f37, %f52, %f36;
ld.shared.f32 %f38, [%r92+4];
add.f32 %f39, %f37, %f38;
ld.shared.f32 %f40, [%r92+8];
add.f32 %f41, %f39, %f40;
ld.shared.f32 %f42, [%r92+12];
add.f32 %f52, %f41, %f42;
add.s32 %r95, %r95, 4;
add.s32 %r92, %r92, 16;
add.s32 %r94, %r94, -4;
setp.ne.s32 %p16, %r94, 0;
@%p16 bra LBB142_15;

LBB142_16:
setp.eq.s32 %p17, %r97, 0;
@%p17 bra LBB142_19;

shl.b32 %r87, %r95, 2;
mov.u32 %r88, __smem;
add.s32 %r96, %r88, %r87;

LBB142_18:
.pragma "nounroll";
ld.shared.f32 %f43, [%r96];
add.f32 %f52, %f52, %f43;
add.s32 %r96, %r96, 4;
add.s32 %r97, %r97, -1;
setp.ne.s32 %p18, %r97, 0;
@%p18 bra LBB142_18;

LBB142_19:
mov.u32 %r89, %ctaid.x;
cvta.to.global.u64 %rd15, %rd3;
mul.wide.u32 %rd16, %r89, 4;
add.s64 %rd17, %rd15, %rd16;
st.global.f32 [%rd17], %f52;

LBB142_20:
ret;

}

.visible .entry _Z7reduce0IdEvPT_S1_j(
.param .u64 _Z7reduce0IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce0IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce0IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<16>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce0IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce0IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce0IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra LBB143_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

LBB143_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r5, %r10, %r9;
st.shared.f64 [%r5], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB143_7;

mov.u32 %r15, 1;

LBB143_4:
shl.b32 %r7, %r15, 1;
rem.u32 %r12, %r3, %r7;
setp.ne.s32 %p3, %r12, 0;
@%p3 bra LBB143_6;

shl.b32 %r13, %r15, 3;
add.s32 %r14, %r5, %r13;
ld.shared.f64 %fd4, [%r5];
ld.shared.f64 %fd5, [%r14];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r5], %fd6;

LBB143_6:
barrier.sync 0;
setp.lt.u32 %p4, %r7, %r1;
mov.u32 %r15, %r7;
@%p4 bra LBB143_4;

LBB143_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB143_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

LBB143_9:
ret;

}

.visible .entry _Z7reduce1IdEvPT_S1_j(
.param .u64 _Z7reduce1IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce1IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce1IdEvPT_S1_j_param_2
)
{
.reg .pred %p<6>;
.reg .b32 %r<20>;
.reg .f64 %fd<9>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z7reduce1IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce1IdEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce1IdEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r2, %r1, %r3;
setp.ge.u32 %p1, %r4, %r8;
mov.f64 %fd8, 0d0000000000000000;
@%p1 bra LBB144_2;

cvta.to.global.u64 %rd3, %rd1;
mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd3, %rd4;
ld.global.f64 %fd8, [%rd5];

LBB144_2:
shl.b32 %r9, %r3, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd8;
barrier.sync 0;
setp.lt.u32 %p2, %r1, 2;
@%p2 bra LBB144_7;

mov.u32 %r19, 1;

LBB144_4:
shl.b32 %r6, %r19, 1;
mul.lo.s32 %r7, %r6, %r3;
setp.ge.u32 %p3, %r7, %r1;
@%p3 bra LBB144_6;

add.s32 %r13, %r7, %r19;
shl.b32 %r14, %r13, 3;
add.s32 %r16, %r10, %r14;
shl.b32 %r17, %r7, 3;
add.s32 %r18, %r10, %r17;
ld.shared.f64 %fd4, [%r18];
ld.shared.f64 %fd5, [%r16];
add.f64 %fd6, %fd5, %fd4;
st.shared.f64 [%r18], %fd6;

LBB144_6:
barrier.sync 0;
setp.lt.u32 %p4, %r6, %r1;
mov.u32 %r19, %r6;
@%p4 bra LBB144_4;

LBB144_7:
setp.ne.s32 %p5, %r3, 0;
@%p5 bra LBB144_9;

ld.shared.f64 %fd7, [__smem_d];
cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd7;

LBB144_9:
ret;

}

.visible .entry _Z7reduce3IdEvPT_S1_j(
.param .u64 _Z7reduce3IdEvPT_S1_j_param_0,
.param .u64 _Z7reduce3IdEvPT_S1_j_param_1,
.param .u32 _Z7reduce3IdEvPT_S1_j_param_2
)
{
.reg .pred %p<7>;
.reg .b32 %r<17>;
.reg .f64 %fd<17>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce3IdEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce3IdEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce3IdEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ntid.x;
shl.b32 %r11, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r11, %r2, %r3;
setp.ge.u32 %p1, %r4, %r10;
mov.f64 %fd15, 0d0000000000000000;
@%p1 bra LBB145_2;

mul.wide.u32 %rd4, %r4, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd15, [%rd5];

LBB145_2:
add.s32 %r5, %r4, %r1;
setp.ge.u32 %p2, %r5, %r10;
@%p2 bra LBB145_4;

mul.wide.u32 %rd6, %r5, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd10, [%rd7];
add.f64 %fd15, %fd15, %fd10;

LBB145_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r6, %r13, %r12;
st.shared.f64 [%r6], %fd15;
barrier.sync 0;
shr.u32 %r16, %r1, 1;
setp.eq.s32 %p3, %r16, 0;
@%p3 bra LBB145_8;

LBB145_5:
setp.ge.u32 %p4, %r3, %r16;
@%p4 bra LBB145_7;

shl.b32 %r14, %r16, 3;
add.s32 %r15, %r6, %r14;
ld.shared.f64 %fd11, [%r15];
add.f64 %fd15, %fd15, %fd11;
st.shared.f64 [%r6], %fd15;

LBB145_7:
barrier.sync 0;
shr.u32 %r16, %r16, 1;
setp.ne.s32 %p5, %r16, 0;
@%p5 bra LBB145_5;

LBB145_8:
setp.ne.s32 %p6, %r3, 0;
@%p6 bra LBB145_10;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r2, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd15;

LBB145_10:
ret;

}

.visible .entry _Z7reduce4IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra LBB146_2;

ld.global.f64 %fd28, [%rd1];

LBB146_2:
add.s32 %r11, %r4, 512;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB146_4;

ld.global.f64 %fd12, [%rd1+4096];
add.f64 %fd28, %fd28, %fd12;

LBB146_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB146_9;

mov.u32 %r47, %r1;

LBB146_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB146_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

LBB146_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB146_6;

LBB146_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB146_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

LBB146_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB146_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

LBB146_13:
ret;

}

.visible .entry _Z7reduce4IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra LBB147_2;

ld.global.f64 %fd28, [%rd1];

LBB147_2:
add.s32 %r11, %r4, 256;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB147_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd28, %fd28, %fd12;

LBB147_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB147_9;

mov.u32 %r47, %r1;

LBB147_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB147_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

LBB147_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB147_6;

LBB147_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB147_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

LBB147_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB147_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

LBB147_13:
ret;

}

.visible .entry _Z7reduce4IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra LBB148_2;

ld.global.f64 %fd28, [%rd1];

LBB148_2:
add.s32 %r11, %r4, 128;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB148_4;

ld.global.f64 %fd12, [%rd1+1024];
add.f64 %fd28, %fd28, %fd12;

LBB148_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB148_9;

mov.u32 %r47, %r1;

LBB148_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB148_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

LBB148_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB148_6;

LBB148_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB148_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

LBB148_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB148_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

LBB148_13:
ret;

}

.visible .entry _Z7reduce4IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd28, 0d0000000000000000;
@%p1 bra LBB149_2;

ld.global.f64 %fd28, [%rd1];

LBB149_2:
add.s32 %r11, %r4, 64;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB149_4;

ld.global.f64 %fd12, [%rd1+512];
add.f64 %fd28, %fd28, %fd12;

LBB149_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd28;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB149_9;

mov.u32 %r47, %r1;

LBB149_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB149_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd28, %fd28, %fd13;
st.shared.f64 [%r5], %fd28;

LBB149_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB149_6;

LBB149_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB149_11;

ld.shared.f64 %fd24, [%r5+256];
add.f64 %fd14, %fd28, %fd24;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd28, %fd22, %fd23;

LBB149_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB149_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd28;

LBB149_13:
ret;

}

.visible .entry _Z7reduce4IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB150_2;

ld.global.f64 %fd27, [%rd1];

LBB150_2:
add.s32 %r11, %r4, 32;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB150_4;

ld.global.f64 %fd12, [%rd1+256];
add.f64 %fd27, %fd27, %fd12;

LBB150_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB150_9;

mov.u32 %r47, %r1;

LBB150_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB150_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB150_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB150_6;

LBB150_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB150_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB150_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB150_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB150_13:
ret;

}

.visible .entry _Z7reduce4IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB151_2;

ld.global.f64 %fd27, [%rd1];

LBB151_2:
add.s32 %r11, %r4, 16;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB151_4;

ld.global.f64 %fd12, [%rd1+128];
add.f64 %fd27, %fd27, %fd12;

LBB151_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB151_9;

mov.u32 %r47, %r1;

LBB151_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB151_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB151_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB151_6;

LBB151_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB151_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB151_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB151_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB151_13:
ret;

}

.visible .entry _Z7reduce4IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB152_2;

ld.global.f64 %fd27, [%rd1];

LBB152_2:
add.s32 %r11, %r4, 8;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB152_4;

ld.global.f64 %fd12, [%rd1+64];
add.f64 %fd27, %fd27, %fd12;

LBB152_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB152_9;

mov.u32 %r47, %r1;

LBB152_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB152_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB152_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB152_6;

LBB152_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB152_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB152_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB152_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB152_13:
ret;

}

.visible .entry _Z7reduce4IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB153_2;

ld.global.f64 %fd27, [%rd1];

LBB153_2:
add.s32 %r11, %r4, 4;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB153_4;

ld.global.f64 %fd12, [%rd1+32];
add.f64 %fd27, %fd27, %fd12;

LBB153_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB153_9;

mov.u32 %r47, %r1;

LBB153_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB153_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB153_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB153_6;

LBB153_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB153_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB153_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB153_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB153_13:
ret;

}

.visible .entry _Z7reduce4IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB154_2;

ld.global.f64 %fd27, [%rd1];

LBB154_2:
add.s32 %r11, %r4, 2;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB154_4;

ld.global.f64 %fd12, [%rd1+16];
add.f64 %fd27, %fd27, %fd12;

LBB154_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB154_9;

mov.u32 %r47, %r1;

LBB154_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB154_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB154_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB154_6;

LBB154_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB154_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB154_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB154_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB154_13:
ret;

}

.visible .entry _Z7reduce4IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce4IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce4IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce4IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce4IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce4IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ntid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %ctaid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r10, %r2, %r3;
setp.ge.u32 %p1, %r4, %r9;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r4, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB155_2;

ld.global.f64 %fd27, [%rd1];

LBB155_2:
add.s32 %r11, %r4, 1;
setp.ge.u32 %p2, %r11, %r9;
@%p2 bra LBB155_4;

ld.global.f64 %fd12, [%rd1+8];
add.f64 %fd27, %fd27, %fd12;

LBB155_4:
shl.b32 %r12, %r3, 3;
mov.u32 %r13, __smem_d;
add.s32 %r5, %r13, %r12;
st.shared.f64 [%r5], %fd27;
barrier.sync 0;
setp.lt.u32 %p3, %r1, 66;
@%p3 bra LBB155_9;

mov.u32 %r47, %r1;

LBB155_6:
shr.u32 %r7, %r47, 1;
setp.ge.u32 %p4, %r3, %r7;
@%p4 bra LBB155_8;

shl.b32 %r14, %r7, 3;
add.s32 %r15, %r5, %r14;
ld.shared.f64 %fd13, [%r15];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r5], %fd27;

LBB155_8:
barrier.sync 0;
setp.gt.u32 %p5, %r47, 131;
mov.u32 %r47, %r7;
@%p5 bra LBB155_6;

LBB155_9:
mov.u32 %r16, %ntid.y;
mov.u32 %r17, %tid.z;
mov.u32 %r18, %tid.y;
mad.lo.s32 %r19, %r16, %r17, %r18;
mad.lo.s32 %r8, %r19, %r1, %r3;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB155_11;


	mov.b64 {%r20,%r21}, %fd27;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r36,%r37}, %fd22;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd23, {%r38,%r39};

	add.f64 %fd27, %fd22, %fd23;

LBB155_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB155_13;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r2, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB155_13:
ret;

}

.visible .entry _Z7reduce5IdLj512EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj512EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj512EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<43>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj512EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj512EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj512EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra LBB156_2;

ld.global.f64 %fd30, [%rd1];

LBB156_2:
add.s32 %r8, %r3, 512;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra LBB156_4;

ld.global.f64 %fd14, [%rd1+4096];
add.f64 %fd30, %fd30, %fd14;

LBB156_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra LBB156_6;

ld.shared.f64 %fd15, [%r4+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r4], %fd30;

LBB156_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra LBB156_8;

ld.shared.f64 %fd16, [%r4+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r4], %fd30;

LBB156_8:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra LBB156_10;

ld.shared.f64 %fd17, [%r4+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r4], %fd30;

LBB156_10:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p6, %r5, 31;
@%p6 bra LBB156_12;

ld.shared.f64 %fd28, [%r4+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r16,%r17}, %fd18;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p7, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p8, %r16, %r38, %r37, %r39;

	mov.b64 %fd19, {%r18,%r19};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r20,%r21}, %fd20;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p9, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p10, %r20, %r40, %r37, %r39;

	mov.b64 %fd21, {%r22,%r23};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r24,%r25}, %fd22;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p11, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p12, %r24, %r41, %r37, %r39;

	mov.b64 %fd23, {%r26,%r27};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r28,%r29}, %fd24;

	shfl.sync.down.b32 %r31|%p13, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p14, %r28, %r36, %r37, %r39;

	mov.b64 %fd25, {%r30,%r31};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r32,%r33}, %fd26;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p15, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p16, %r32, %r42, %r37, %r39;

	mov.b64 %fd27, {%r34,%r35};

	add.f64 %fd30, %fd26, %fd27;

LBB156_12:
setp.ne.s32 %p17, %r5, 0;
@%p17 bra LBB156_14;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

LBB156_14:
ret;

}

.visible .entry _Z7reduce5IdLj256EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj256EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj256EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<43>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj256EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj256EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj256EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB157_2;

ld.global.f64 %fd27, [%rd1];

LBB157_2:
add.s32 %r8, %r3, 256;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra LBB157_4;

ld.global.f64 %fd12, [%rd1+2048];
add.f64 %fd27, %fd27, %fd12;

LBB157_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra LBB157_6;

ld.shared.f64 %fd13, [%r4+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r4], %fd27;

LBB157_6:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra LBB157_8;

ld.shared.f64 %fd14, [%r4+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r4], %fd27;

LBB157_8:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p5, %r5, 31;
@%p5 bra LBB157_10;

ld.shared.f64 %fd25, [%r4+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r16,%r17}, %fd15;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p6, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p7, %r16, %r38, %r37, %r39;

	mov.b64 %fd16, {%r18,%r19};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r20,%r21}, %fd17;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p8, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p9, %r20, %r40, %r37, %r39;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r24,%r25}, %fd19;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p10, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p11, %r24, %r41, %r37, %r39;

	mov.b64 %fd20, {%r26,%r27};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r28,%r29}, %fd21;

	shfl.sync.down.b32 %r31|%p12, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p13, %r28, %r36, %r37, %r39;

	mov.b64 %fd22, {%r30,%r31};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r32,%r33}, %fd23;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p14, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p15, %r32, %r42, %r37, %r39;

	mov.b64 %fd24, {%r34,%r35};

	add.f64 %fd27, %fd23, %fd24;

LBB157_10:
setp.ne.s32 %p16, %r5, 0;
@%p16 bra LBB157_12;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB157_12:
ret;

}

.visible .entry _Z7reduce5IdLj128EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj128EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj128EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<43>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj128EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj128EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj128EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra LBB158_2;

ld.global.f64 %fd24, [%rd1];

LBB158_2:
add.s32 %r8, %r3, 128;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra LBB158_4;

ld.global.f64 %fd10, [%rd1+1024];
add.f64 %fd24, %fd24, %fd10;

LBB158_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra LBB158_6;

ld.shared.f64 %fd11, [%r4+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r4], %fd24;

LBB158_6:
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p4, %r5, 31;
@%p4 bra LBB158_8;

ld.shared.f64 %fd22, [%r4+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r16,%r17}, %fd12;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p5, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p6, %r16, %r38, %r37, %r39;

	mov.b64 %fd13, {%r18,%r19};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r20,%r21}, %fd14;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p7, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p8, %r20, %r40, %r37, %r39;

	mov.b64 %fd15, {%r22,%r23};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r24,%r25}, %fd16;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p9, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p10, %r24, %r41, %r37, %r39;

	mov.b64 %fd17, {%r26,%r27};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r28,%r29}, %fd18;

	shfl.sync.down.b32 %r31|%p11, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p12, %r28, %r36, %r37, %r39;

	mov.b64 %fd19, {%r30,%r31};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r32,%r33}, %fd20;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p13, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p14, %r32, %r42, %r37, %r39;

	mov.b64 %fd21, {%r34,%r35};

	add.f64 %fd24, %fd20, %fd21;

LBB158_8:
setp.ne.s32 %p15, %r5, 0;
@%p15 bra LBB158_10;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

LBB158_10:
ret;

}

.visible .entry _Z7reduce5IdLj64EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj64EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj64EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj64EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj64EEvPT_S1_j_param_1];
ld.param.u32 %r6, [_Z7reduce5IdLj64EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r7, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r7, %r2;
setp.ge.u32 %p1, %r3, %r6;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra LBB159_2;

ld.global.f64 %fd21, [%rd1];

LBB159_2:
add.s32 %r8, %r3, 64;
setp.ge.u32 %p2, %r8, %r6;
@%p2 bra LBB159_4;

ld.global.f64 %fd8, [%rd1+512];
add.f64 %fd21, %fd21, %fd8;

LBB159_4:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r4, %r10, %r9;
st.shared.f64 [%r4], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r5, %r14, %r15, %r2;
setp.gt.u32 %p3, %r5, 31;
@%p3 bra LBB159_6;

ld.shared.f64 %fd19, [%r4+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r16,%r17}, %fd9;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd21, %fd17, %fd18;

LBB159_6:
setp.ne.s32 %p14, %r5, 0;
@%p14 bra LBB159_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB159_8:
ret;

}

.visible .entry _Z7reduce5IdLj32EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj32EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj32EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj32EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj32EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj32EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB160_2;

ld.global.f64 %fd20, [%rd1];

LBB160_2:
add.s32 %r7, %r3, 32;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB160_4;

ld.global.f64 %fd8, [%rd1+256];
add.f64 %fd20, %fd20, %fd8;

LBB160_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB160_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB160_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB160_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB160_8:
ret;

}

.visible .entry _Z7reduce5IdLj16EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj16EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj16EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj16EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj16EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj16EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB161_2;

ld.global.f64 %fd20, [%rd1];

LBB161_2:
add.s32 %r7, %r3, 16;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB161_4;

ld.global.f64 %fd8, [%rd1+128];
add.f64 %fd20, %fd20, %fd8;

LBB161_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB161_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB161_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB161_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB161_8:
ret;

}

.visible .entry _Z7reduce5IdLj8EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj8EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj8EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj8EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj8EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj8EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB162_2;

ld.global.f64 %fd20, [%rd1];

LBB162_2:
add.s32 %r7, %r3, 8;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB162_4;

ld.global.f64 %fd8, [%rd1+64];
add.f64 %fd20, %fd20, %fd8;

LBB162_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB162_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB162_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB162_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB162_8:
ret;

}

.visible .entry _Z7reduce5IdLj4EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj4EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj4EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj4EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj4EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj4EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB163_2;

ld.global.f64 %fd20, [%rd1];

LBB163_2:
add.s32 %r7, %r3, 4;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB163_4;

ld.global.f64 %fd8, [%rd1+32];
add.f64 %fd20, %fd20, %fd8;

LBB163_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB163_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB163_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB163_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB163_8:
ret;

}

.visible .entry _Z7reduce5IdLj2EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj2EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj2EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj2EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj2EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj2EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB164_2;

ld.global.f64 %fd20, [%rd1];

LBB164_2:
add.s32 %r7, %r3, 2;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB164_4;

ld.global.f64 %fd8, [%rd1+16];
add.f64 %fd20, %fd20, %fd8;

LBB164_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB164_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB164_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB164_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB164_8:
ret;

}

.visible .entry _Z7reduce5IdLj1EEvPT_S1_j(
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce5IdLj1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce5IdLj1EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<43>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd3, [_Z7reduce5IdLj1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce5IdLj1EEvPT_S1_j_param_1];
ld.param.u32 %r5, [_Z7reduce5IdLj1EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r6, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r3, %r6, %r2;
setp.ge.u32 %p1, %r3, %r5;
cvta.to.global.u64 %rd4, %rd3;
mul.wide.u32 %rd5, %r3, 8;
add.s64 %rd1, %rd4, %rd5;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB165_2;

ld.global.f64 %fd20, [%rd1];

LBB165_2:
add.s32 %r7, %r3, 1;
setp.ge.u32 %p2, %r7, %r5;
@%p2 bra LBB165_4;

ld.global.f64 %fd8, [%rd1+8];
add.f64 %fd20, %fd20, %fd8;

LBB165_4:
shl.b32 %r8, %r2, 3;
mov.u32 %r9, __smem_d;
add.s32 %r10, %r9, %r8;
st.shared.f64 [%r10], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r11, %ntid.y;
mov.u32 %r12, %tid.z;
mov.u32 %r13, %tid.y;
mad.lo.s32 %r14, %r11, %r12, %r13;
mov.u32 %r15, %ntid.x;
mad.lo.s32 %r4, %r14, %r15, %r2;
setp.gt.u32 %p3, %r4, 31;
@%p3 bra LBB165_6;


	mov.b64 {%r16,%r17}, %fd20;

	mov.u32 %r36, 2;
mov.u32 %r37, 31;
mov.u32 %r38, 16;
mov.u32 %r39, -1;
shfl.sync.down.b32 %r19|%p4, %r17, %r38, %r37, %r39;
shfl.sync.down.b32 %r18|%p5, %r16, %r38, %r37, %r39;

	mov.b64 %fd10, {%r18,%r19};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r20,%r21}, %fd11;

	mov.u32 %r40, 8;
shfl.sync.down.b32 %r23|%p6, %r21, %r40, %r37, %r39;
shfl.sync.down.b32 %r22|%p7, %r20, %r40, %r37, %r39;

	mov.b64 %fd12, {%r22,%r23};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r24,%r25}, %fd13;

	mov.u32 %r41, 4;
shfl.sync.down.b32 %r27|%p8, %r25, %r41, %r37, %r39;
shfl.sync.down.b32 %r26|%p9, %r24, %r41, %r37, %r39;

	mov.b64 %fd14, {%r26,%r27};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r28,%r29}, %fd15;

	shfl.sync.down.b32 %r31|%p10, %r29, %r36, %r37, %r39;
shfl.sync.down.b32 %r30|%p11, %r28, %r36, %r37, %r39;

	mov.b64 %fd16, {%r30,%r31};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r32,%r33}, %fd17;

	mov.u32 %r42, 1;
shfl.sync.down.b32 %r35|%p12, %r33, %r42, %r37, %r39;
shfl.sync.down.b32 %r34|%p13, %r32, %r42, %r37, %r39;

	mov.b64 %fd18, {%r34,%r35};

	add.f64 %fd20, %fd17, %fd18;

LBB165_6:
setp.ne.s32 %p14, %r4, 0;
@%p14 bra LBB165_8;

cvta.to.global.u64 %rd6, %rd2;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB165_8:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<19>;
.reg .b32 %r<48>;
.reg .f64 %fd<39>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj512ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd32, 0d0000000000000000;
@%p1 bra LBB166_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 10;
mov.f64 %fd32, 0d0000000000000000;

LBB166_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd16, [%rd5];
add.f64 %fd32, %fd32, %fd16;
add.s32 %r6, %r47, 512;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra LBB166_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd17, [%rd7];
add.f64 %fd32, %fd32, %fd17;

LBB166_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra LBB166_2;

LBB166_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd32;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 255;
@%p4 bra LBB166_7;

ld.shared.f64 %fd18, [%r8+2048];
add.f64 %fd32, %fd32, %fd18;
st.shared.f64 [%r8], %fd32;

LBB166_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 127;
@%p5 bra LBB166_9;

ld.shared.f64 %fd19, [%r8+1024];
add.f64 %fd32, %fd32, %fd19;
st.shared.f64 [%r8], %fd32;

LBB166_9:
barrier.sync 0;
setp.gt.u32 %p6, %r2, 63;
@%p6 bra LBB166_11;

ld.shared.f64 %fd20, [%r8+512];
add.f64 %fd32, %fd32, %fd20;
st.shared.f64 [%r8], %fd32;

LBB166_11:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p7, %r9, 31;
@%p7 bra LBB166_13;

ld.shared.f64 %fd31, [%r8+256];
add.f64 %fd21, %fd32, %fd31;

	mov.b64 {%r20,%r21}, %fd21;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p8, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p9, %r20, %r42, %r41, %r43;

	mov.b64 %fd22, {%r22,%r23};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r24,%r25}, %fd23;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p10, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p11, %r24, %r44, %r41, %r43;

	mov.b64 %fd24, {%r26,%r27};

	add.f64 %fd25, %fd23, %fd24;

	mov.b64 {%r28,%r29}, %fd25;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p12, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p13, %r28, %r45, %r41, %r43;

	mov.b64 %fd26, {%r30,%r31};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r32,%r33}, %fd27;

	shfl.sync.down.b32 %r35|%p14, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p15, %r32, %r40, %r41, %r43;

	mov.b64 %fd28, {%r34,%r35};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r36,%r37}, %fd29;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p16, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p17, %r36, %r46, %r41, %r43;

	mov.b64 %fd30, {%r38,%r39};

	add.f64 %fd32, %fd29, %fd30;

LBB166_13:
setp.ne.s32 %p18, %r9, 0;
@%p18 bra LBB166_15;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd32;

LBB166_15:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<48>;
.reg .f64 %fd<35>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj256ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd29, 0d0000000000000000;
@%p1 bra LBB167_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 9;
mov.f64 %fd29, 0d0000000000000000;

LBB167_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd29, %fd29, %fd14;
add.s32 %r6, %r47, 256;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra LBB167_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd15, [%rd7];
add.f64 %fd29, %fd29, %fd15;

LBB167_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra LBB167_2;

LBB167_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd29;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra LBB167_7;

ld.shared.f64 %fd16, [%r8+1024];
add.f64 %fd29, %fd29, %fd16;
st.shared.f64 [%r8], %fd29;

LBB167_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra LBB167_9;

ld.shared.f64 %fd17, [%r8+512];
add.f64 %fd29, %fd29, %fd17;
st.shared.f64 [%r8], %fd29;

LBB167_9:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p6, %r9, 31;
@%p6 bra LBB167_11;

ld.shared.f64 %fd28, [%r8+256];
add.f64 %fd18, %fd29, %fd28;

	mov.b64 {%r20,%r21}, %fd18;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p7, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p8, %r20, %r42, %r41, %r43;

	mov.b64 %fd19, {%r22,%r23};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r24,%r25}, %fd20;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p9, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p10, %r24, %r44, %r41, %r43;

	mov.b64 %fd21, {%r26,%r27};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r28,%r29}, %fd22;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p11, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p12, %r28, %r45, %r41, %r43;

	mov.b64 %fd23, {%r30,%r31};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r32,%r33}, %fd24;

	shfl.sync.down.b32 %r35|%p13, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p14, %r32, %r40, %r41, %r43;

	mov.b64 %fd25, {%r34,%r35};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r36,%r37}, %fd26;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p15, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p16, %r36, %r46, %r41, %r43;

	mov.b64 %fd27, {%r38,%r39};

	add.f64 %fd29, %fd26, %fd27;

LBB167_11:
setp.ne.s32 %p17, %r9, 0;
@%p17 bra LBB167_13;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd29;

LBB167_13:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<48>;
.reg .f64 %fd<31>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj128ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd26, 0d0000000000000000;
@%p1 bra LBB168_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 8;
mov.f64 %fd26, 0d0000000000000000;

LBB168_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd26, %fd26, %fd12;
add.s32 %r6, %r47, 128;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra LBB168_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd13, [%rd7];
add.f64 %fd26, %fd26, %fd13;

LBB168_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra LBB168_2;

LBB168_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd26;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra LBB168_7;

ld.shared.f64 %fd14, [%r8+512];
add.f64 %fd26, %fd26, %fd14;
st.shared.f64 [%r8], %fd26;

LBB168_7:
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p5, %r9, 31;
@%p5 bra LBB168_9;

ld.shared.f64 %fd25, [%r8+256];
add.f64 %fd15, %fd26, %fd25;

	mov.b64 {%r20,%r21}, %fd15;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p6, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p7, %r20, %r42, %r41, %r43;

	mov.b64 %fd16, {%r22,%r23};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r24,%r25}, %fd17;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p8, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p9, %r24, %r44, %r41, %r43;

	mov.b64 %fd18, {%r26,%r27};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r28,%r29}, %fd19;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p10, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p11, %r28, %r45, %r41, %r43;

	mov.b64 %fd20, {%r30,%r31};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r32,%r33}, %fd21;

	shfl.sync.down.b32 %r35|%p12, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p13, %r32, %r40, %r41, %r43;

	mov.b64 %fd22, {%r34,%r35};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r36,%r37}, %fd23;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p14, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p15, %r36, %r46, %r41, %r43;

	mov.b64 %fd24, {%r38,%r39};

	add.f64 %fd26, %fd23, %fd24;

LBB168_9:
setp.ne.s32 %p16, %r9, 0;
@%p16 bra LBB168_11;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd26;

LBB168_11:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<27>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r10, [_Z7reduce6IdLj64ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r11, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r11, %r2;
setp.ge.u32 %p1, %r47, %r10;
mov.f64 %fd23, 0d0000000000000000;
@%p1 bra LBB169_5;

mov.u32 %r12, %nctaid.x;
shl.b32 %r4, %r12, 7;
mov.f64 %fd23, 0d0000000000000000;

LBB169_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd23, %fd23, %fd10;
add.s32 %r6, %r47, 64;
setp.ge.u32 %p2, %r6, %r10;
@%p2 bra LBB169_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd23, %fd23, %fd11;

LBB169_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r10;
@%p3 bra LBB169_2;

LBB169_5:
shl.b32 %r13, %r2, 3;
mov.u32 %r14, __smem_d;
add.s32 %r8, %r14, %r13;
st.shared.f64 [%r8], %fd23;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r9, %r18, %r19, %r2;
setp.gt.u32 %p4, %r9, 31;
@%p4 bra LBB169_7;

ld.shared.f64 %fd22, [%r8+256];
add.f64 %fd12, %fd23, %fd22;

	mov.b64 {%r20,%r21}, %fd12;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd23, %fd20, %fd21;

LBB169_7:
setp.ne.s32 %p15, %r9, 0;
@%p15 bra LBB169_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd23;

LBB169_9:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj32ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB170_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
mov.f64 %fd22, 0d0000000000000000;

LBB170_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 32;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB170_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB170_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB170_2;

LBB170_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB170_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB170_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB170_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB170_9:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj16ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB171_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 5;
mov.f64 %fd22, 0d0000000000000000;

LBB171_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 16;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB171_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB171_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB171_2;

LBB171_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB171_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB171_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB171_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB171_9:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj8ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB172_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 4;
mov.f64 %fd22, 0d0000000000000000;

LBB172_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 8;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB172_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB172_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB172_2;

LBB172_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB172_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB172_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB172_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB172_9:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj4ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB173_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 3;
mov.f64 %fd22, 0d0000000000000000;

LBB173_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 4;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB173_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB173_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB173_2;

LBB173_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB173_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB173_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB173_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB173_9:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj2ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB174_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 2;
mov.f64 %fd22, 0d0000000000000000;

LBB174_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 2;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB174_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB174_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB174_2;

LBB174_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB174_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB174_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB174_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB174_9:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb1EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<48>;
.reg .f64 %fd<26>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_0];
ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj1ELb1EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r47, %r10, %r2;
setp.ge.u32 %p1, %r47, %r9;
mov.f64 %fd22, 0d0000000000000000;
@%p1 bra LBB175_5;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 1;
mov.f64 %fd22, 0d0000000000000000;

LBB175_2:
mul.wide.u32 %rd4, %r47, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd22, %fd22, %fd10;
add.s32 %r6, %r47, 1;
setp.ge.u32 %p2, %r6, %r9;
@%p2 bra LBB175_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.f64 %fd11, [%rd7];
add.f64 %fd22, %fd22, %fd11;

LBB175_4:
add.s32 %r47, %r47, %r4;
setp.lt.u32 %p3, %r47, %r9;
@%p3 bra LBB175_2;

LBB175_5:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r14, %r13, %r12;
st.shared.f64 [%r14], %fd22;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r15, %ntid.y;
mov.u32 %r16, %tid.z;
mov.u32 %r17, %tid.y;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mad.lo.s32 %r8, %r18, %r19, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB175_7;


	mov.b64 {%r20,%r21}, %fd22;

	mov.u32 %r40, 2;
mov.u32 %r41, 31;
mov.u32 %r42, 16;
mov.u32 %r43, -1;
shfl.sync.down.b32 %r23|%p5, %r21, %r42, %r41, %r43;
shfl.sync.down.b32 %r22|%p6, %r20, %r42, %r41, %r43;

	mov.b64 %fd13, {%r22,%r23};

	add.f64 %fd14, %fd22, %fd13;

	mov.b64 {%r24,%r25}, %fd14;

	mov.u32 %r44, 8;
shfl.sync.down.b32 %r27|%p7, %r25, %r44, %r41, %r43;
shfl.sync.down.b32 %r26|%p8, %r24, %r44, %r41, %r43;

	mov.b64 %fd15, {%r26,%r27};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r28,%r29}, %fd16;

	mov.u32 %r45, 4;
shfl.sync.down.b32 %r31|%p9, %r29, %r45, %r41, %r43;
shfl.sync.down.b32 %r30|%p10, %r28, %r45, %r41, %r43;

	mov.b64 %fd17, {%r30,%r31};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r32,%r33}, %fd18;

	shfl.sync.down.b32 %r35|%p11, %r33, %r40, %r41, %r43;
shfl.sync.down.b32 %r34|%p12, %r32, %r40, %r41, %r43;

	mov.b64 %fd19, {%r34,%r35};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r36,%r37}, %fd20;

	mov.u32 %r46, 1;
shfl.sync.down.b32 %r39|%p13, %r37, %r46, %r41, %r43;
shfl.sync.down.b32 %r38|%p14, %r36, %r46, %r41, %r43;

	mov.b64 %fd21, {%r38,%r39};

	add.f64 %fd22, %fd20, %fd21;

LBB175_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB175_9;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd22;

LBB175_9:
ret;

}

.visible .entry _Z7reduce6IdLj512ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<47>;
.reg .f64 %fd<35>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj512ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd30, 0d0000000000000000;
@%p1 bra LBB176_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 9;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd30, 0d0000000000000000;

LBB176_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd14, [%rd5];
add.f64 %fd30, %fd30, %fd14;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra LBB176_2;

LBB176_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd30;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 255;
@%p3 bra LBB176_5;

ld.shared.f64 %fd15, [%r7+2048];
add.f64 %fd30, %fd30, %fd15;
st.shared.f64 [%r7], %fd30;

LBB176_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 127;
@%p4 bra LBB176_7;

ld.shared.f64 %fd16, [%r7+1024];
add.f64 %fd30, %fd30, %fd16;
st.shared.f64 [%r7], %fd30;

LBB176_7:
barrier.sync 0;
setp.gt.u32 %p5, %r2, 63;
@%p5 bra LBB176_9;

ld.shared.f64 %fd17, [%r7+512];
add.f64 %fd30, %fd30, %fd17;
st.shared.f64 [%r7], %fd30;

LBB176_9:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p6, %r8, 31;
@%p6 bra LBB176_11;

ld.shared.f64 %fd28, [%r7+256];
add.f64 %fd18, %fd30, %fd28;

	mov.b64 {%r19,%r20}, %fd18;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p7, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p8, %r19, %r41, %r40, %r42;

	mov.b64 %fd19, {%r21,%r22};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r23,%r24}, %fd20;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p9, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p10, %r23, %r43, %r40, %r42;

	mov.b64 %fd21, {%r25,%r26};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r27,%r28}, %fd22;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p11, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p12, %r27, %r44, %r40, %r42;

	mov.b64 %fd23, {%r29,%r30};

	add.f64 %fd24, %fd22, %fd23;

	mov.b64 {%r31,%r32}, %fd24;

	shfl.sync.down.b32 %r34|%p13, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p14, %r31, %r39, %r40, %r42;

	mov.b64 %fd25, {%r33,%r34};

	add.f64 %fd26, %fd24, %fd25;

	mov.b64 {%r35,%r36}, %fd26;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p15, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p16, %r35, %r45, %r40, %r42;

	mov.b64 %fd27, {%r37,%r38};

	add.f64 %fd30, %fd26, %fd27;

LBB176_11:
setp.ne.s32 %p17, %r8, 0;
@%p17 bra LBB176_13;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd30;

LBB176_13:
ret;

}

.visible .entry _Z7reduce6IdLj256ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<47>;
.reg .f64 %fd<31>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj256ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB177_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 8;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd27, 0d0000000000000000;

LBB177_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra LBB177_2;

LBB177_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd27;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 127;
@%p3 bra LBB177_5;

ld.shared.f64 %fd13, [%r7+1024];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r7], %fd27;

LBB177_5:
barrier.sync 0;
setp.gt.u32 %p4, %r2, 63;
@%p4 bra LBB177_7;

ld.shared.f64 %fd14, [%r7+512];
add.f64 %fd27, %fd27, %fd14;
st.shared.f64 [%r7], %fd27;

LBB177_7:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p5, %r8, 31;
@%p5 bra LBB177_9;

ld.shared.f64 %fd25, [%r7+256];
add.f64 %fd15, %fd27, %fd25;

	mov.b64 {%r19,%r20}, %fd15;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p6, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p7, %r19, %r41, %r40, %r42;

	mov.b64 %fd16, {%r21,%r22};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r23,%r24}, %fd17;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p8, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p9, %r23, %r43, %r40, %r42;

	mov.b64 %fd18, {%r25,%r26};

	add.f64 %fd19, %fd17, %fd18;

	mov.b64 {%r27,%r28}, %fd19;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p10, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p11, %r27, %r44, %r40, %r42;

	mov.b64 %fd20, {%r29,%r30};

	add.f64 %fd21, %fd19, %fd20;

	mov.b64 {%r31,%r32}, %fd21;

	shfl.sync.down.b32 %r34|%p12, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p13, %r31, %r39, %r40, %r42;

	mov.b64 %fd22, {%r33,%r34};

	add.f64 %fd23, %fd21, %fd22;

	mov.b64 {%r35,%r36}, %fd23;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p14, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p15, %r35, %r45, %r40, %r42;

	mov.b64 %fd24, {%r37,%r38};

	add.f64 %fd27, %fd23, %fd24;

LBB177_9:
setp.ne.s32 %p16, %r8, 0;
@%p16 bra LBB177_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB177_11:
ret;

}

.visible .entry _Z7reduce6IdLj128ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<47>;
.reg .f64 %fd<27>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj128ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd24, 0d0000000000000000;
@%p1 bra LBB178_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd24, 0d0000000000000000;

LBB178_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd10, [%rd5];
add.f64 %fd24, %fd24, %fd10;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra LBB178_2;

LBB178_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd24;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
setp.gt.u32 %p3, %r2, 63;
@%p3 bra LBB178_5;

ld.shared.f64 %fd11, [%r7+512];
add.f64 %fd24, %fd24, %fd11;
st.shared.f64 [%r7], %fd24;

LBB178_5:
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p4, %r8, 31;
@%p4 bra LBB178_7;

ld.shared.f64 %fd22, [%r7+256];
add.f64 %fd12, %fd24, %fd22;

	mov.b64 {%r19,%r20}, %fd12;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p5, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p6, %r19, %r41, %r40, %r42;

	mov.b64 %fd13, {%r21,%r22};

	add.f64 %fd14, %fd12, %fd13;

	mov.b64 {%r23,%r24}, %fd14;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p7, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p8, %r23, %r43, %r40, %r42;

	mov.b64 %fd15, {%r25,%r26};

	add.f64 %fd16, %fd14, %fd15;

	mov.b64 {%r27,%r28}, %fd16;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p9, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p10, %r27, %r44, %r40, %r42;

	mov.b64 %fd17, {%r29,%r30};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r31,%r32}, %fd18;

	shfl.sync.down.b32 %r34|%p11, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p12, %r31, %r39, %r40, %r42;

	mov.b64 %fd19, {%r33,%r34};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r35,%r36}, %fd20;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p13, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p14, %r35, %r45, %r40, %r42;

	mov.b64 %fd21, {%r37,%r38};

	add.f64 %fd24, %fd20, %fd21;

LBB178_7:
setp.ne.s32 %p15, %r8, 0;
@%p15 bra LBB178_9;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd24;

LBB178_9:
ret;

}

.visible .entry _Z7reduce6IdLj64ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<23>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r9, [_Z7reduce6IdLj64ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r10, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r10, %r2;
setp.ge.u32 %p1, %r46, %r9;
mov.f64 %fd21, 0d0000000000000000;
@%p1 bra LBB179_3;

mov.u32 %r11, %nctaid.x;
shl.b32 %r4, %r11, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB179_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd21, %fd21, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r9;
@%p2 bra LBB179_2;

LBB179_3:
shl.b32 %r12, %r2, 3;
mov.u32 %r13, __smem_d;
add.s32 %r7, %r13, %r12;
st.shared.f64 [%r7], %fd21;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r8, %r17, %r18, %r2;
setp.gt.u32 %p3, %r8, 31;
@%p3 bra LBB179_5;

ld.shared.f64 %fd19, [%r7+256];
add.f64 %fd9, %fd21, %fd19;

	mov.b64 {%r19,%r20}, %fd9;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd9, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd21, %fd17, %fd18;

LBB179_5:
setp.ne.s32 %p14, %r8, 0;
@%p14 bra LBB179_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB179_7:
ret;

}

.visible .entry _Z7reduce6IdLj32ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj32ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB180_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB180_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra LBB180_2;

LBB180_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB180_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

LBB180_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB180_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB180_7:
ret;

}

.visible .entry _Z7reduce6IdLj16ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj16ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB181_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB181_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra LBB181_2;

LBB181_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB181_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

LBB181_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB181_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB181_7:
ret;

}

.visible .entry _Z7reduce6IdLj8ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj8ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB182_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB182_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra LBB182_2;

LBB182_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB182_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

LBB182_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB182_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB182_7:
ret;

}

.visible .entry _Z7reduce6IdLj4ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj4ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB183_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB183_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra LBB183_2;

LBB183_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB183_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

LBB183_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB183_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB183_7:
ret;

}

.visible .entry _Z7reduce6IdLj2ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<47>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj2ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r9, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r9, %r2;
setp.ge.u32 %p1, %r46, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB184_3;

mov.u32 %r10, %nctaid.x;
shl.b32 %r4, %r10, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB184_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p2, %r46, %r8;
@%p2 bra LBB184_2;

LBB184_3:
shl.b32 %r11, %r2, 3;
mov.u32 %r12, __smem_d;
add.s32 %r13, %r12, %r11;
st.shared.f64 [%r13], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r14, %ntid.y;
mov.u32 %r15, %tid.z;
mov.u32 %r16, %tid.y;
mad.lo.s32 %r17, %r14, %r15, %r16;
mov.u32 %r18, %ntid.x;
mad.lo.s32 %r7, %r17, %r18, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB184_5;


	mov.b64 {%r19,%r20}, %fd20;

	mov.u32 %r39, 2;
mov.u32 %r40, 31;
mov.u32 %r41, 16;
mov.u32 %r42, -1;
shfl.sync.down.b32 %r22|%p4, %r20, %r41, %r40, %r42;
shfl.sync.down.b32 %r21|%p5, %r19, %r41, %r40, %r42;

	mov.b64 %fd10, {%r21,%r22};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r23,%r24}, %fd11;

	mov.u32 %r43, 8;
shfl.sync.down.b32 %r26|%p6, %r24, %r43, %r40, %r42;
shfl.sync.down.b32 %r25|%p7, %r23, %r43, %r40, %r42;

	mov.b64 %fd12, {%r25,%r26};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r27,%r28}, %fd13;

	mov.u32 %r44, 4;
shfl.sync.down.b32 %r30|%p8, %r28, %r44, %r40, %r42;
shfl.sync.down.b32 %r29|%p9, %r27, %r44, %r40, %r42;

	mov.b64 %fd14, {%r29,%r30};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r31,%r32}, %fd15;

	shfl.sync.down.b32 %r34|%p10, %r32, %r39, %r40, %r42;
shfl.sync.down.b32 %r33|%p11, %r31, %r39, %r40, %r42;

	mov.b64 %fd16, {%r33,%r34};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r35,%r36}, %fd17;

	mov.u32 %r45, 1;
shfl.sync.down.b32 %r38|%p12, %r36, %r45, %r40, %r42;
shfl.sync.down.b32 %r37|%p13, %r35, %r45, %r40, %r42;

	mov.b64 %fd18, {%r37,%r38};

	add.f64 %fd20, %fd17, %fd18;

LBB184_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB184_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB184_7:
ret;

}

.visible .entry _Z7reduce6IdLj1ELb0EEvPT_S1_j(
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0,
.param .u64 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1,
.param .u32 _Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2
)
{
.reg .pred %p<15>;
.reg .b32 %r<45>;
.reg .f64 %fd<22>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_1];
ld.param.u32 %r8, [_Z7reduce6IdLj1ELb0EEvPT_S1_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r44, %r1, %r2;
setp.ge.u32 %p1, %r44, %r8;
mov.f64 %fd20, 0d0000000000000000;
@%p1 bra LBB185_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd20, 0d0000000000000000;

LBB185_2:
mul.wide.u32 %rd4, %r44, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd8, [%rd5];
add.f64 %fd20, %fd20, %fd8;
add.s32 %r44, %r44, %r4;
setp.lt.u32 %p2, %r44, %r8;
@%p2 bra LBB185_2;

LBB185_3:
shl.b32 %r9, %r2, 3;
mov.u32 %r10, __smem_d;
add.s32 %r11, %r10, %r9;
st.shared.f64 [%r11], %fd20;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
barrier.sync 0;
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mad.lo.s32 %r7, %r15, %r16, %r2;
setp.gt.u32 %p3, %r7, 31;
@%p3 bra LBB185_5;


	mov.b64 {%r17,%r18}, %fd20;

	mov.u32 %r37, 2;
mov.u32 %r38, 31;
mov.u32 %r39, 16;
mov.u32 %r40, -1;
shfl.sync.down.b32 %r20|%p4, %r18, %r39, %r38, %r40;
shfl.sync.down.b32 %r19|%p5, %r17, %r39, %r38, %r40;

	mov.b64 %fd10, {%r19,%r20};

	add.f64 %fd11, %fd20, %fd10;

	mov.b64 {%r21,%r22}, %fd11;

	mov.u32 %r41, 8;
shfl.sync.down.b32 %r24|%p6, %r22, %r41, %r38, %r40;
shfl.sync.down.b32 %r23|%p7, %r21, %r41, %r38, %r40;

	mov.b64 %fd12, {%r23,%r24};

	add.f64 %fd13, %fd11, %fd12;

	mov.b64 {%r25,%r26}, %fd13;

	mov.u32 %r42, 4;
shfl.sync.down.b32 %r28|%p8, %r26, %r42, %r38, %r40;
shfl.sync.down.b32 %r27|%p9, %r25, %r42, %r38, %r40;

	mov.b64 %fd14, {%r27,%r28};

	add.f64 %fd15, %fd13, %fd14;

	mov.b64 {%r29,%r30}, %fd15;

	shfl.sync.down.b32 %r32|%p10, %r30, %r37, %r38, %r40;
shfl.sync.down.b32 %r31|%p11, %r29, %r37, %r38, %r40;

	mov.b64 %fd16, {%r31,%r32};

	add.f64 %fd17, %fd15, %fd16;

	mov.b64 {%r33,%r34}, %fd17;

	mov.u32 %r43, 1;
shfl.sync.down.b32 %r36|%p12, %r34, %r43, %r38, %r40;
shfl.sync.down.b32 %r35|%p13, %r33, %r43, %r38, %r40;

	mov.b64 %fd18, {%r35,%r36};

	add.f64 %fd20, %fd17, %fd18;

LBB185_5:
setp.ne.s32 %p14, %r7, 0;
@%p14 bra LBB185_7;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd20;

LBB185_7:
ret;

}

.visible .entry _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj1024ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 11;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB186_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 11;
mov.f64 %fd21, 0d0000000000000000;

LBB186_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 1024;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB186_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB186_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB186_2;

LBB186_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB186_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB186_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB186_7;

LBB186_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB186_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB186_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 1024;
mov.u32 %r48, 1;
@%p10 bra LBB186_12;

mov.u32 %r34, 1024;
div.u32 %r48, %r34, %r49;

LBB186_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB186_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB186_16;

mov.u32 %r45, 31;

LBB186_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB186_15;

LBB186_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB186_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB186_18:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj512ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 10;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB187_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 10;
mov.f64 %fd21, 0d0000000000000000;

LBB187_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 512;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB187_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB187_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB187_2;

LBB187_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB187_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB187_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB187_7;

LBB187_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB187_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB187_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 512;
mov.u32 %r48, 1;
@%p10 bra LBB187_12;

mov.u32 %r34, 512;
div.u32 %r48, %r34, %r49;

LBB187_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB187_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB187_16;

mov.u32 %r45, 31;

LBB187_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB187_15;

LBB187_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB187_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB187_18:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj256ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB188_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 9;
mov.f64 %fd21, 0d0000000000000000;

LBB188_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 256;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB188_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB188_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB188_2;

LBB188_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB188_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB188_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB188_7;

LBB188_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB188_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB188_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 256;
mov.u32 %r48, 1;
@%p10 bra LBB188_12;

mov.u32 %r34, 256;
div.u32 %r48, %r34, %r49;

LBB188_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB188_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB188_16;

mov.u32 %r45, 31;

LBB188_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB188_15;

LBB188_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB188_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB188_18:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj128ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB189_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 8;
mov.f64 %fd21, 0d0000000000000000;

LBB189_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 128;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB189_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB189_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB189_2;

LBB189_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB189_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB189_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB189_7;

LBB189_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB189_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB189_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 128;
mov.u32 %r48, 1;
@%p10 bra LBB189_12;

mov.u32 %r34, 128;
div.u32 %r48, %r34, %r49;

LBB189_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB189_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB189_16;

mov.u32 %r45, 31;

LBB189_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB189_15;

LBB189_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB189_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB189_18:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj64ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB190_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 7;
mov.f64 %fd21, 0d0000000000000000;

LBB190_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 64;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB190_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB190_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB190_2;

LBB190_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB190_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB190_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB190_7;

LBB190_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB190_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB190_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 64;
mov.u32 %r48, 1;
@%p10 bra LBB190_12;

mov.u32 %r34, 64;
div.u32 %r48, %r34, %r49;

LBB190_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB190_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB190_16;

mov.u32 %r45, 31;

LBB190_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB190_15;

LBB190_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB190_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB190_18:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj32ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB191_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 6;
mov.f64 %fd21, 0d0000000000000000;

LBB191_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 32;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB191_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB191_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB191_2;

LBB191_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB191_8;

mov.u32 %r26, 31;
mov.u32 %r27, -1;
mov.u32 %r47, %r49;

LBB191_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB191_7;

LBB191_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB191_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB191_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 32;
mov.u32 %r48, 1;
@%p10 bra LBB191_12;

mov.u32 %r34, 32;
div.u32 %r48, %r34, %r49;

LBB191_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, -1;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB191_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB191_16;

mov.u32 %r45, 31;

LBB191_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB191_15;

LBB191_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB191_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB191_18:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj16ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB192_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 5;
mov.f64 %fd21, 0d0000000000000000;

LBB192_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 16;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB192_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB192_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB192_2;

LBB192_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB192_8;

mov.u32 %r26, 31;
mov.u32 %r27, 65535;
mov.u32 %r47, %r49;

LBB192_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB192_7;

LBB192_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB192_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB192_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 16;
mov.u32 %r48, 1;
@%p10 bra LBB192_12;

mov.u32 %r34, 16;
div.u32 %r48, %r34, %r49;

LBB192_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, 65535;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB192_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB192_16;

mov.u32 %r45, 31;

LBB192_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB192_15;

LBB192_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB192_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB192_18:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj8ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB193_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 4;
mov.f64 %fd21, 0d0000000000000000;

LBB193_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 8;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB193_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB193_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB193_2;

LBB193_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB193_8;

mov.u32 %r26, 31;
mov.u32 %r27, 255;
mov.u32 %r47, %r49;

LBB193_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB193_7;

LBB193_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB193_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB193_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 8;
mov.u32 %r48, 1;
@%p10 bra LBB193_12;

mov.u32 %r34, 8;
div.u32 %r48, %r34, %r49;

LBB193_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, 255;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB193_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB193_16;

mov.u32 %r45, 31;

LBB193_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB193_15;

LBB193_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB193_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB193_18:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj4ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB194_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 3;
mov.f64 %fd21, 0d0000000000000000;

LBB194_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 4;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB194_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB194_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB194_2;

LBB194_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB194_8;

mov.u32 %r26, 31;
mov.u32 %r27, 15;
mov.u32 %r47, %r49;

LBB194_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB194_7;

LBB194_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB194_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB194_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 4;
mov.u32 %r48, 1;
@%p10 bra LBB194_12;

mov.u32 %r34, 4;
div.u32 %r48, %r34, %r49;

LBB194_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, 15;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB194_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB194_16;

mov.u32 %r45, 31;

LBB194_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB194_15;

LBB194_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB194_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB194_18:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<50>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r17, [_Z7reduce7IdLj2ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r18, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r46, %r18, %r2;
setp.ge.u32 %p2, %r46, %r17;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB195_5;

mov.u32 %r19, %nctaid.x;
shl.b32 %r4, %r19, 2;
mov.f64 %fd21, 0d0000000000000000;

LBB195_2:
mul.wide.u32 %rd4, %r46, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r46, 2;
setp.ge.u32 %p3, %r6, %r17;
@%p3 bra LBB195_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB195_4:
add.s32 %r46, %r46, %r4;
setp.lt.u32 %p4, %r46, %r17;
@%p4 bra LBB195_2;

LBB195_5:
mov.u32 %r49, WARP_SZ;
setp.lt.s32 %p5, %r49, 2;
@%p5 bra LBB195_8;

mov.u32 %r26, 31;
mov.u32 %r27, 3;
mov.u32 %r47, %r49;

LBB195_7:

	mov.b64 {%r20,%r21}, %fd21;

	shr.u32 %r24, %r47, 31;
add.s32 %r25, %r47, %r24;
shr.s32 %r10, %r25, 1;
shfl.sync.down.b32 %r23|%p6, %r21, %r10, %r26, %r27;
shfl.sync.down.b32 %r22|%p7, %r20, %r10, %r26, %r27;

	mov.b64 %fd18, {%r22,%r23};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r47, 3;
mov.u32 %r47, %r10;
@%p8 bra LBB195_7;

LBB195_8:
rem.u32 %r28, %r2, %r49;
setp.ne.s32 %p9, %r28, 0;
@%p9 bra LBB195_10;

div.u32 %r29, %r2, %r49;
shl.b32 %r30, %r29, 3;
mov.u32 %r31, __smem_d;
add.s32 %r32, %r31, %r30;
st.shared.f64 [%r32], %fd21;

LBB195_10:
bar.sync 0;
setp.gt.u32 %p10, %r49, 2;
mov.u32 %r48, 1;
@%p10 bra LBB195_12;

mov.u32 %r34, 2;
div.u32 %r48, %r34, %r49;

LBB195_12:
setp.ge.u32 %p11, %r2, %r48;
setp.lt.u32 %p12, %r2, %r48;
mov.u32 %r35, 3;
vote.sync.ballot.b32 %r13, %p12, %r35;
@%p11 bra LBB195_16;

shl.b32 %r36, %r2, 3;
mov.u32 %r37, __smem_d;
add.s32 %r38, %r37, %r36;
ld.shared.f64 %fd21, [%r38];
@%p5 bra LBB195_16;

mov.u32 %r45, 31;

LBB195_15:

	mov.b64 {%r39,%r40}, %fd21;

	shr.u32 %r43, %r49, 31;
add.s32 %r44, %r49, %r43;
shr.s32 %r16, %r44, 1;
shfl.sync.down.b32 %r42|%p14, %r40, %r16, %r45, %r13;
shfl.sync.down.b32 %r41|%p15, %r39, %r16, %r45, %r13;

	mov.b64 %fd20, {%r41,%r42};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p16, %r49, 3;
mov.u32 %r49, %r16;
@%p16 bra LBB195_15;

LBB195_16:
setp.ne.s32 %p17, %r2, 0;
@%p17 bra LBB195_18;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB195_18:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb1EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<42>;
.reg .f64 %fd<28>;
.reg .b64 %rd<11>;


ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_0];
ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_1];
ld.param.u32 %r15, [_Z7reduce7IdLj1ELb1EEvPKT_PS0_j_param_2];
cvta.to.global.u64 %rd1, %rd3;
mov.u32 %r1, %ctaid.x;
shl.b32 %r16, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r39, %r16, %r2;
setp.ge.u32 %p2, %r39, %r15;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB196_5;

mov.u32 %r17, %nctaid.x;
shl.b32 %r4, %r17, 1;
mov.f64 %fd21, 0d0000000000000000;

LBB196_2:
mul.wide.u32 %rd4, %r39, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd15, [%rd5];
add.f64 %fd21, %fd21, %fd15;
add.s32 %r6, %r39, 1;
setp.ge.u32 %p3, %r6, %r15;
@%p3 bra LBB196_4;

mul.wide.u32 %rd6, %r6, 8;
add.s64 %rd7, %rd1, %rd6;
ld.global.nc.f64 %fd16, [%rd7];
add.f64 %fd21, %fd21, %fd16;

LBB196_4:
add.s32 %r39, %r39, %r4;
setp.lt.u32 %p4, %r39, %r15;
@%p4 bra LBB196_2;

LBB196_5:
mov.u32 %r41, WARP_SZ;
setp.lt.s32 %p5, %r41, 2;
@%p5 bra LBB196_8;

mov.u32 %r24, 31;
mov.u32 %r25, 1;
mov.u32 %r40, %r41;

LBB196_7:

	mov.b64 {%r18,%r19}, %fd21;

	shr.u32 %r22, %r40, 31;
add.s32 %r23, %r40, %r22;
shr.s32 %r10, %r23, 1;
shfl.sync.down.b32 %r21|%p6, %r19, %r10, %r24, %r25;
shfl.sync.down.b32 %r20|%p7, %r18, %r10, %r24, %r25;

	mov.b64 %fd18, {%r20,%r21};

	add.f64 %fd21, %fd21, %fd18;
setp.gt.s32 %p8, %r40, 3;
mov.u32 %r40, %r10;
@%p8 bra LBB196_7;

LBB196_8:
rem.u32 %r26, %r2, %r41;
setp.ne.s32 %p9, %r26, 0;
@%p9 bra LBB196_10;

div.u32 %r27, %r2, %r41;
shl.b32 %r28, %r27, 3;
mov.u32 %r29, __smem_d;
add.s32 %r30, %r29, %r28;
st.shared.f64 [%r30], %fd21;

LBB196_10:
bar.sync 0;
setp.ne.s32 %p10, %r2, 0;
setp.eq.s32 %p11, %r2, 0;
mov.u32 %r31, 1;
vote.sync.ballot.b32 %r11, %p11, %r31;
@%p10 bra LBB196_14;

ld.shared.f64 %fd21, [__smem_d];
@%p5 bra LBB196_14;

mov.u32 %r38, 31;

LBB196_13:

	mov.b64 {%r32,%r33}, %fd21;

	shr.u32 %r36, %r41, 31;
add.s32 %r37, %r41, %r36;
shr.s32 %r14, %r37, 1;
shfl.sync.down.b32 %r35|%p13, %r33, %r14, %r38, %r11;
shfl.sync.down.b32 %r34|%p14, %r32, %r14, %r38, %r11;

	mov.b64 %fd20, {%r34,%r35};

	add.f64 %fd21, %fd21, %fd20;
setp.gt.s32 %p15, %r41, 3;
mov.u32 %r41, %r14;
@%p15 bra LBB196_13;

LBB196_14:
@%p10 bra LBB196_16;

cvta.to.global.u64 %rd8, %rd2;
mul.wide.u32 %rd9, %r1, 8;
add.s64 %rd10, %rd8, %rd9;
st.global.f64 [%rd10], %fd21;

LBB196_16:
ret;

}

.visible .entry _Z7reduce7IdLj512ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj512ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 9;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB197_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 9;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB197_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB197_2;

LBB197_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB197_6;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

LBB197_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB197_5;

LBB197_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB197_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB197_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 512;
mov.u32 %r47, 1;
@%p9 bra LBB197_10;

mov.u32 %r33, 512;
div.u32 %r47, %r33, %r48;

LBB197_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB197_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB197_14;

mov.u32 %r44, 31;

LBB197_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB197_13;

LBB197_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB197_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB197_16:
ret;

}

.visible .entry _Z7reduce7IdLj256ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj256ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 8;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB198_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 8;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB198_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB198_2;

LBB198_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB198_6;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

LBB198_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB198_5;

LBB198_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB198_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB198_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 256;
mov.u32 %r47, 1;
@%p9 bra LBB198_10;

mov.u32 %r33, 256;
div.u32 %r47, %r33, %r48;

LBB198_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB198_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB198_14;

mov.u32 %r44, 31;

LBB198_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB198_13;

LBB198_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB198_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB198_16:
ret;

}

.visible .entry _Z7reduce7IdLj128ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj128ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 7;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB199_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 7;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB199_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB199_2;

LBB199_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB199_6;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

LBB199_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB199_5;

LBB199_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB199_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB199_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 128;
mov.u32 %r47, 1;
@%p9 bra LBB199_10;

mov.u32 %r33, 128;
div.u32 %r47, %r33, %r48;

LBB199_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB199_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB199_14;

mov.u32 %r44, 31;

LBB199_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB199_13;

LBB199_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB199_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB199_16:
ret;

}

.visible .entry _Z7reduce7IdLj64ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj64ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 6;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB200_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 6;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB200_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB200_2;

LBB200_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB200_6;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

LBB200_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB200_5;

LBB200_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB200_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB200_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 64;
mov.u32 %r47, 1;
@%p9 bra LBB200_10;

mov.u32 %r33, 64;
div.u32 %r47, %r33, %r48;

LBB200_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB200_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB200_14;

mov.u32 %r44, 31;

LBB200_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB200_13;

LBB200_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB200_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB200_16:
ret;

}

.visible .entry _Z7reduce7IdLj32ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj32ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 5;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB201_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 5;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB201_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB201_2;

LBB201_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB201_6;

mov.u32 %r25, 31;
mov.u32 %r26, -1;
mov.u32 %r46, %r48;

LBB201_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB201_5;

LBB201_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB201_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB201_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 32;
mov.u32 %r47, 1;
@%p9 bra LBB201_10;

mov.u32 %r33, 32;
div.u32 %r47, %r33, %r48;

LBB201_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, -1;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB201_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB201_14;

mov.u32 %r44, 31;

LBB201_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB201_13;

LBB201_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB201_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB201_16:
ret;

}

.visible .entry _Z7reduce7IdLj16ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj16ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 4;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB202_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 4;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB202_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB202_2;

LBB202_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB202_6;

mov.u32 %r25, 31;
mov.u32 %r26, 65535;
mov.u32 %r46, %r48;

LBB202_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB202_5;

LBB202_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB202_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB202_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 16;
mov.u32 %r47, 1;
@%p9 bra LBB202_10;

mov.u32 %r33, 16;
div.u32 %r47, %r33, %r48;

LBB202_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 65535;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB202_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB202_14;

mov.u32 %r44, 31;

LBB202_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB202_13;

LBB202_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB202_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB202_16:
ret;

}

.visible .entry _Z7reduce7IdLj8ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj8ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 3;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB203_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 3;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB203_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB203_2;

LBB203_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB203_6;

mov.u32 %r25, 31;
mov.u32 %r26, 255;
mov.u32 %r46, %r48;

LBB203_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB203_5;

LBB203_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB203_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB203_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 8;
mov.u32 %r47, 1;
@%p9 bra LBB203_10;

mov.u32 %r33, 8;
div.u32 %r47, %r33, %r48;

LBB203_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 255;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB203_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB203_14;

mov.u32 %r44, 31;

LBB203_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB203_13;

LBB203_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB203_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB203_16:
ret;

}

.visible .entry _Z7reduce7IdLj4ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj4ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 2;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB204_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 2;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB204_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB204_2;

LBB204_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB204_6;

mov.u32 %r25, 31;
mov.u32 %r26, 15;
mov.u32 %r46, %r48;

LBB204_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB204_5;

LBB204_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB204_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB204_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 4;
mov.u32 %r47, 1;
@%p9 bra LBB204_10;

mov.u32 %r33, 4;
div.u32 %r47, %r33, %r48;

LBB204_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 15;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB204_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB204_14;

mov.u32 %r44, 31;

LBB204_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB204_13;

LBB204_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB204_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB204_16:
ret;

}

.visible .entry _Z7reduce7IdLj2ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<17>;
.reg .b32 %r<49>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r16, [_Z7reduce7IdLj2ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
shl.b32 %r17, %r1, 1;
mov.u32 %r2, %tid.x;
add.s32 %r45, %r17, %r2;
setp.ge.u32 %p2, %r45, %r16;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB205_3;

mov.u32 %r18, %nctaid.x;
shl.b32 %r4, %r18, 1;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB205_2:
mul.wide.u32 %rd4, %r45, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r45, %r45, %r4;
setp.lt.u32 %p3, %r45, %r16;
@%p3 bra LBB205_2;

LBB205_3:
mov.u32 %r48, WARP_SZ;
setp.lt.s32 %p4, %r48, 2;
@%p4 bra LBB205_6;

mov.u32 %r25, 31;
mov.u32 %r26, 3;
mov.u32 %r46, %r48;

LBB205_5:

	mov.b64 {%r19,%r20}, %fd21;

	shr.u32 %r23, %r46, 31;
add.s32 %r24, %r46, %r23;
shr.s32 %r9, %r24, 1;
shfl.sync.down.b32 %r22|%p5, %r20, %r9, %r25, %r26;
shfl.sync.down.b32 %r21|%p6, %r19, %r9, %r25, %r26;

	mov.b64 %fd15, {%r21,%r22};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r46, 3;
mov.u32 %r46, %r9;
@%p7 bra LBB205_5;

LBB205_6:
rem.u32 %r27, %r2, %r48;
setp.ne.s32 %p8, %r27, 0;
@%p8 bra LBB205_8;

div.u32 %r28, %r2, %r48;
shl.b32 %r29, %r28, 3;
mov.u32 %r30, __smem_d;
add.s32 %r31, %r30, %r29;
st.shared.f64 [%r31], %fd21;

LBB205_8:
bar.sync 0;
setp.gt.u32 %p9, %r48, 2;
mov.u32 %r47, 1;
@%p9 bra LBB205_10;

mov.u32 %r33, 2;
div.u32 %r47, %r33, %r48;

LBB205_10:
setp.ge.u32 %p10, %r2, %r47;
setp.lt.u32 %p11, %r2, %r47;
mov.u32 %r34, 3;
vote.sync.ballot.b32 %r12, %p11, %r34;
@%p10 bra LBB205_14;

shl.b32 %r35, %r2, 3;
mov.u32 %r36, __smem_d;
add.s32 %r37, %r36, %r35;
ld.shared.f64 %fd21, [%r37];
@%p4 bra LBB205_14;

mov.u32 %r44, 31;

LBB205_13:

	mov.b64 {%r38,%r39}, %fd21;

	shr.u32 %r42, %r48, 31;
add.s32 %r43, %r48, %r42;
shr.s32 %r15, %r43, 1;
shfl.sync.down.b32 %r41|%p13, %r39, %r15, %r44, %r12;
shfl.sync.down.b32 %r40|%p14, %r38, %r15, %r44, %r12;

	mov.b64 %fd17, {%r40,%r41};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p15, %r48, 3;
mov.u32 %r48, %r15;
@%p15 bra LBB205_13;

LBB205_14:
setp.ne.s32 %p16, %r2, 0;
@%p16 bra LBB205_16;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB205_16:
ret;

}

.visible .entry _Z7reduce7IdLj1ELb0EEvPKT_PS0_j(
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0,
.param .u64 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1,
.param .u32 _Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2
)
{
.reg .pred %p<16>;
.reg .b32 %r<39>;
.reg .f64 %fd<24>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_0];
ld.param.u64 %rd3, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_1];
ld.param.u32 %r14, [_Z7reduce7IdLj1ELb0EEvPKT_PS0_j_param_2];
mov.u32 %r1, %ctaid.x;
mov.u32 %r2, %tid.x;
add.s32 %r36, %r1, %r2;
setp.ge.u32 %p2, %r36, %r14;
mov.f64 %fd21, 0d0000000000000000;
@%p2 bra LBB206_3;

mov.u32 %r4, %nctaid.x;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd21, 0d0000000000000000;

LBB206_2:
mul.wide.u32 %rd4, %r36, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.nc.f64 %fd13, [%rd5];
add.f64 %fd21, %fd21, %fd13;
add.s32 %r36, %r36, %r4;
setp.lt.u32 %p3, %r36, %r14;
@%p3 bra LBB206_2;

LBB206_3:
mov.u32 %r38, WARP_SZ;
setp.lt.s32 %p4, %r38, 2;
@%p4 bra LBB206_6;

mov.u32 %r21, 31;
mov.u32 %r22, 1;
mov.u32 %r37, %r38;

LBB206_5:

	mov.b64 {%r15,%r16}, %fd21;

	shr.u32 %r19, %r37, 31;
add.s32 %r20, %r37, %r19;
shr.s32 %r9, %r20, 1;
shfl.sync.down.b32 %r18|%p5, %r16, %r9, %r21, %r22;
shfl.sync.down.b32 %r17|%p6, %r15, %r9, %r21, %r22;

	mov.b64 %fd15, {%r17,%r18};

	add.f64 %fd21, %fd21, %fd15;
setp.gt.s32 %p7, %r37, 3;
mov.u32 %r37, %r9;
@%p7 bra LBB206_5;

LBB206_6:
rem.u32 %r23, %r2, %r38;
setp.ne.s32 %p8, %r23, 0;
@%p8 bra LBB206_8;

div.u32 %r24, %r2, %r38;
shl.b32 %r25, %r24, 3;
mov.u32 %r26, __smem_d;
add.s32 %r27, %r26, %r25;
st.shared.f64 [%r27], %fd21;

LBB206_8:
bar.sync 0;
setp.ne.s32 %p9, %r2, 0;
setp.eq.s32 %p10, %r2, 0;
mov.u32 %r28, 1;
vote.sync.ballot.b32 %r10, %p10, %r28;
@%p9 bra LBB206_12;

ld.shared.f64 %fd21, [__smem_d];
@%p4 bra LBB206_12;

mov.u32 %r35, 31;

LBB206_11:

	mov.b64 {%r29,%r30}, %fd21;

	shr.u32 %r33, %r38, 31;
add.s32 %r34, %r38, %r33;
shr.s32 %r13, %r34, 1;
shfl.sync.down.b32 %r32|%p12, %r30, %r13, %r35, %r10;
shfl.sync.down.b32 %r31|%p13, %r29, %r13, %r35, %r10;

	mov.b64 %fd17, {%r31,%r32};

	add.f64 %fd21, %fd21, %fd17;
setp.gt.s32 %p14, %r38, 3;
mov.u32 %r38, %r13;
@%p14 bra LBB206_11;

LBB206_12:
@%p9 bra LBB206_14;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r1, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd21;

LBB206_14:
ret;

}

.visible .entry _Z9cg_reduceIdEvPT_S1_j(
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_0,
.param .u64 _Z9cg_reduceIdEvPT_S1_j_param_1,
.param .u32 _Z9cg_reduceIdEvPT_S1_j_param_2
)
{
.reg .pred %p<18>;
.reg .b32 %r<55>;
.reg .f64 %fd<30>;
.reg .b64 %rd<9>;


ld.param.u64 %rd2, [_Z9cg_reduceIdEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z9cg_reduceIdEvPT_S1_j_param_1];
ld.param.u32 %r11, [_Z9cg_reduceIdEvPT_S1_j_param_2];
mov.u32 %r12, %ntid.y;
mov.u32 %r13, %tid.z;
mov.u32 %r14, %tid.y;
mad.lo.s32 %r15, %r12, %r13, %r14;
mov.u32 %r16, %ntid.x;
mov.u32 %r17, %tid.x;
mad.lo.s32 %r1, %r15, %r16, %r17;
mul.lo.s32 %r18, %r16, %r12;
mov.u32 %r19, %ntid.z;
mul.lo.s32 %r54, %r18, %r19;
mov.u32 %r3, %ctaid.x;
mad.lo.s32 %r53, %r54, %r3, %r1;
setp.ge.u32 %p1, %r53, %r11;
mov.f64 %fd27, 0d0000000000000000;
@%p1 bra LBB207_3;

mov.u32 %r20, %nctaid.x;
mul.lo.s32 %r5, %r54, %r20;
cvta.to.global.u64 %rd1, %rd2;
mov.f64 %fd27, 0d0000000000000000;

LBB207_2:
mul.wide.u32 %rd4, %r53, 8;
add.s64 %rd5, %rd1, %rd4;
ld.global.f64 %fd12, [%rd5];
add.f64 %fd27, %fd27, %fd12;
add.s32 %r53, %r53, %r5;
setp.lt.u32 %p2, %r53, %r11;
@%p2 bra LBB207_2;

LBB207_3:
shl.b32 %r21, %r1, 3;
mov.u32 %r22, __smem_d;
add.s32 %r8, %r22, %r21;
st.shared.f64 [%r8], %fd27;
setp.lt.u32 %p3, %r54, 64;
@%p3 bra LBB207_7;

LBB207_4:
barrier.sync 0;
shr.u32 %r10, %r54, 1;
setp.ge.u32 %p4, %r1, %r10;
@%p4 bra LBB207_6;

shl.b32 %r23, %r10, 3;
add.s32 %r24, %r8, %r23;
ld.shared.f64 %fd13, [%r24];
add.f64 %fd27, %fd27, %fd13;
st.shared.f64 [%r8], %fd27;

LBB207_6:
setp.gt.u32 %p5, %r54, 127;
mov.u32 %r54, %r10;
@%p5 bra LBB207_4;

LBB207_7:
barrier.sync 0;
shl.b32 %r25, %r1, 11;
setp.gt.u32 %p6, %r25, 65535;
@%p6 bra LBB207_9;


	mov.b64 {%r26,%r27}, %fd27;

	mov.u32 %r46, 31;
mov.u32 %r47, 16;
mov.u32 %r48, -1;
shfl.sync.bfly.b32 %r29|%p7, %r27, %r47, %r46, %r48;
shfl.sync.bfly.b32 %r28|%p8, %r26, %r47, %r46, %r48;

	mov.b64 %fd15, {%r28,%r29};

	add.f64 %fd16, %fd27, %fd15;

	mov.b64 {%r30,%r31}, %fd16;

	mov.u32 %r49, 8;
shfl.sync.bfly.b32 %r33|%p9, %r31, %r49, %r46, %r48;
shfl.sync.bfly.b32 %r32|%p10, %r30, %r49, %r46, %r48;

	mov.b64 %fd17, {%r32,%r33};

	add.f64 %fd18, %fd16, %fd17;

	mov.b64 {%r34,%r35}, %fd18;

	mov.u32 %r50, 4;
shfl.sync.bfly.b32 %r37|%p11, %r35, %r50, %r46, %r48;
shfl.sync.bfly.b32 %r36|%p12, %r34, %r50, %r46, %r48;

	mov.b64 %fd19, {%r36,%r37};

	add.f64 %fd20, %fd18, %fd19;

	mov.b64 {%r38,%r39}, %fd20;

	mov.u32 %r51, 2;
shfl.sync.bfly.b32 %r41|%p13, %r39, %r51, %r46, %r48;
shfl.sync.bfly.b32 %r40|%p14, %r38, %r51, %r46, %r48;

	mov.b64 %fd21, {%r40,%r41};

	add.f64 %fd22, %fd20, %fd21;

	mov.b64 {%r42,%r43}, %fd22;

	mov.u32 %r52, 1;
shfl.sync.bfly.b32 %r45|%p15, %r43, %r52, %r46, %r48;
shfl.sync.bfly.b32 %r44|%p16, %r42, %r52, %r46, %r48;

	mov.b64 %fd23, {%r44,%r45};

	add.f64 %fd27, %fd22, %fd23;

LBB207_9:
setp.ne.s32 %p17, %r1, 0;
@%p17 bra LBB207_11;

cvta.to.global.u64 %rd6, %rd3;
mul.wide.u32 %rd7, %r3, 8;
add.s64 %rd8, %rd6, %rd7;
st.global.f64 [%rd8], %fd27;

LBB207_11:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2
)
{
.reg .pred %p<39>;
.reg .b32 %r<159>;
.reg .f64 %fd<64>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch[384];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 31;
@%p1 bra LBB208_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

LBB208_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB208_6;

shl.b32 %r45, %r6, 10;
add.s32 %r151, %r45, %r3;
setp.ge.u32 %p3, %r151, %r35;
mov.f64 %fd58, 0d0000000000000000;
@%p3 bra LBB208_11;

shl.b32 %r8, %r5, 10;
mov.f64 %fd58, 0d0000000000000000;

LBB208_5:
mul.wide.u32 %rd5, %r151, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd58, %fd58, %fd18;
add.s32 %r151, %r151, %r8;
setp.lt.u32 %p4, %r151, %r35;
@%p4 bra LBB208_5;
bra.uni LBB208_11;

LBB208_6:
shl.b32 %r46, %r6, 11;
add.s32 %r152, %r46, %r3;
setp.ge.u32 %p5, %r152, %r35;
mov.f64 %fd58, 0d0000000000000000;
@%p5 bra LBB208_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 11;
mov.f64 %fd58, 0d0000000000000000;

LBB208_8:
cvt.u64.u32 %rd7, %r152;
mul.wide.u32 %rd8, %r152, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd58, %fd58, %fd21;
add.s64 %rd10, %rd7, 1024;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB208_10;

add.s32 %r47, %r152, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd58, %fd58, %fd22;

LBB208_10:
add.s32 %r152, %r152, %r12;
setp.lt.u32 %p7, %r152, %r35;
@%p7 bra LBB208_8;

LBB208_11:
shr.u32 %r15, %r4, 9;
shr.u32 %r69, %r4, 2;
and.b32 %r70, %r69, 1073741816;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm1024ELm512EEvPT_S1_jE7scratch;
add.s32 %r16, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd58;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd58, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r16+128], %fd33;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p18, %r17, 0;
bar.warp.sync -1;
mov.u32 %r153, %r68;
@%p18 bra LBB208_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r71;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r153,[%rd13],%r78;


LBB208_13:
shfl.sync.idx.b32 %r20|%p19, %r153, %r68, %r72, %r74;
add.s32 %r85, %r20, 1;
and.b32 %r86, %r85, 2147483647;
setp.eq.s32 %p20, %r86, 16;
shl.b32 %r87, %r15, 2;
add.s32 %r21, %r71, %r87;
@%p20 bra LBB208_15;
bra.uni LBB208_14;

LBB208_15:
and.b32 %r91, %r4, 16;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra LBB208_17;

and.b32 %r112, %r4, 15;
and.b32 %r113, %r4, -512;
shr.u32 %r114, %r113, 5;
or.b32 %r115, %r114, %r112;
shl.b32 %r116, %r115, 3;
add.s32 %r118, %r71, %r116;
ld.shared.f64 %fd34, [%r118+128];

	mov.u32 %r92, %laneid;

	and.b32 %r119, %r92, -16;
mov.u32 %r120, 65535;
shl.b32 %r121, %r120, %r119;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r122, 4127;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r75, %r122, %r121;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r75, %r122, %r121;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r124, %r97, -16;
shl.b32 %r125, %r120, %r124;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r76, %r122, %r125;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r76, %r122, %r125;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r127, %r102, -16;
shl.b32 %r128, %r120, %r127;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r77, %r122, %r128;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r77, %r122, %r128;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;

	mov.u32 %r107, %laneid;

	and.b32 %r130, %r107, -16;
shl.b32 %r131, %r120, %r130;

	mov.b64 {%r108,%r109}, %fd40;

	shfl.sync.bfly.b32 %r111|%p29, %r109, %r78, %r122, %r131;
shfl.sync.bfly.b32 %r110|%p30, %r108, %r78, %r122, %r131;

	mov.b64 %fd41, {%r110,%r111};

	add.f64 %fd42, %fd40, %fd41;
st.shared.f64 [%r118+128], %fd42;

LBB208_17:
bar.warp.sync -1;
@%p18 bra LBB208_19;

ld.volatile.shared.u32 %r133, [%r21+8];
not.b32 %r134, %r133;
and.b32 %r135, %r134, -2147483648;
st.volatile.shared.u32 [%r21+8], %r135;
bra.uni LBB208_19;

LBB208_14:
ld.volatile.shared.u32 %r89, [%r21+8];
xor.b32 %r90, %r89, %r20;
setp.gt.s32 %p21, %r90, -1;
@%p21 bra LBB208_14;

LBB208_19:
ld.shared.f64 %fd8, [%r16+128];
bar.warp.sync -1;
and.b32 %r136, %r4, 511;
setp.ne.s32 %p32, %r136, 0;
@%p32 bra LBB208_21;

shl.b32 %r137, %r15, 3;
mov.u32 %r138, __smem_d;
add.s32 %r139, %r138, %r137;
st.shared.f64 [%r139], %fd8;

LBB208_21:
barrier.sync 0;
setp.ne.s32 %p33, %r3, 0;
@%p33 bra LBB208_30;

mul.lo.s32 %r140, %r2, %r1;
mov.u32 %r141, %ntid.z;
mad.lo.s32 %r142, %r140, %r141, 511;
shr.u32 %r22, %r142, 9;
setp.eq.s32 %p34, %r22, 0;
mov.f64 %fd63, 0d0000000000000000;
@%p34 bra LBB208_29;

add.s32 %r144, %r22, -1;
and.b32 %r158, %r22, 3;
setp.lt.u32 %p35, %r144, 3;
mov.f64 %fd63, 0d0000000000000000;
mov.u32 %r156, 0;
@%p35 bra LBB208_26;

sub.s32 %r155, %r22, %r158;
mov.f64 %fd63, 0d0000000000000000;
mov.u32 %r156, 0;

LBB208_25:
shl.b32 %r146, %r156, 3;
mov.u32 %r147, __smem_d;
add.s32 %r148, %r147, %r146;
ld.shared.f64 %fd47, [%r148];
add.f64 %fd48, %fd63, %fd47;
ld.shared.f64 %fd49, [%r148+8];
add.f64 %fd50, %fd48, %fd49;
ld.shared.f64 %fd51, [%r148+16];
add.f64 %fd52, %fd50, %fd51;
ld.shared.f64 %fd53, [%r148+24];
add.f64 %fd63, %fd52, %fd53;
add.s32 %r156, %r156, 4;
add.s32 %r155, %r155, -4;
setp.ne.s32 %p36, %r155, 0;
@%p36 bra LBB208_25;

LBB208_26:
setp.eq.s32 %p37, %r158, 0;
@%p37 bra LBB208_29;

shl.b32 %r149, %r156, 3;
mov.u32 %r150, __smem_d;
add.s32 %r157, %r150, %r149;

LBB208_28:
.pragma "nounroll";
ld.shared.f64 %fd54, [%r157];
add.f64 %fd63, %fd63, %fd54;
add.s32 %r157, %r157, 8;
add.s32 %r158, %r158, -1;
setp.ne.s32 %p38, %r158, 0;
@%p38 bra LBB208_28;

LBB208_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 8;
add.s64 %rd19, %rd17, %rd18;
st.global.f64 [%rd19], %fd63;

LBB208_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2
)
{
.reg .pred %p<37>;
.reg .b32 %r<151>;
.reg .f64 %fd<62>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch[192];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 15;
@%p1 bra LBB209_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

LBB209_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB209_6;

shl.b32 %r45, %r6, 9;
add.s32 %r143, %r45, %r3;
setp.ge.u32 %p3, %r143, %r35;
mov.f64 %fd56, 0d0000000000000000;
@%p3 bra LBB209_11;

shl.b32 %r8, %r5, 9;
mov.f64 %fd56, 0d0000000000000000;

LBB209_5:
mul.wide.u32 %rd5, %r143, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd56, %fd56, %fd18;
add.s32 %r143, %r143, %r8;
setp.lt.u32 %p4, %r143, %r35;
@%p4 bra LBB209_5;
bra.uni LBB209_11;

LBB209_6:
shl.b32 %r46, %r6, 10;
add.s32 %r144, %r46, %r3;
setp.ge.u32 %p5, %r144, %r35;
mov.f64 %fd56, 0d0000000000000000;
@%p5 bra LBB209_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 10;
mov.f64 %fd56, 0d0000000000000000;

LBB209_8:
cvt.u64.u32 %rd7, %r144;
mul.wide.u32 %rd8, %r144, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd56, %fd56, %fd21;
add.s64 %rd10, %rd7, 512;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB209_10;

add.s32 %r47, %r144, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd56, %fd56, %fd22;

LBB209_10:
add.s32 %r144, %r144, %r12;
setp.lt.u32 %p7, %r144, %r35;
@%p7 bra LBB209_8;

LBB209_11:
shr.u32 %r15, %r4, 8;
mov.u32 %r69, 8;
shr.u32 %r70, %r4, 2;
and.b32 %r71, %r70, 1073741816;
mov.u32 %r72, _ZZ20multi_warp_cg_reduceIdLm512ELm256EEvPT_S1_jE7scratch;
add.s32 %r16, %r72, %r71;

	mov.b64 {%r48,%r49}, %fd56;

	mov.u32 %r73, 31;
mov.u32 %r74, 16;
mov.u32 %r75, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r74, %r73, %r75;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r74, %r73, %r75;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd56, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	shfl.sync.bfly.b32 %r55|%p10, %r53, %r69, %r73, %r75;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r69, %r73, %r75;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r73, %r75;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r73, %r75;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r73, %r75;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r73, %r75;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r73, %r75;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r73, %r75;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r16+64], %fd33;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p18, %r17, 0;
bar.warp.sync -1;
mov.u32 %r145, %r68;
@%p18 bra LBB209_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r72;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r145,[%rd13],%r78;


LBB209_13:
shfl.sync.idx.b32 %r20|%p19, %r145, %r68, %r73, %r75;
add.s32 %r85, %r20, 1;
and.b32 %r86, %r85, 2147483647;
setp.eq.s32 %p20, %r86, 8;
shl.b32 %r87, %r15, 2;
add.s32 %r21, %r72, %r87;
@%p20 bra LBB209_15;
bra.uni LBB209_14;

LBB209_15:
and.b32 %r91, %r4, 24;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra LBB209_17;

and.b32 %r107, %r4, 7;
and.b32 %r108, %r4, -256;
shr.u32 %r109, %r108, 5;
or.b32 %r110, %r109, %r107;
shl.b32 %r111, %r110, 3;
add.s32 %r113, %r72, %r111;
ld.shared.f64 %fd34, [%r113+64];

	mov.u32 %r92, %laneid;

	and.b32 %r114, %r92, -8;
mov.u32 %r115, 255;
shl.b32 %r116, %r115, %r114;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r117, 6175;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r76, %r117, %r116;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r76, %r117, %r116;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r119, %r97, -8;
shl.b32 %r120, %r115, %r119;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r77, %r117, %r120;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r77, %r117, %r120;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;

	mov.u32 %r102, %laneid;

	and.b32 %r122, %r102, -8;
shl.b32 %r123, %r115, %r122;

	mov.b64 {%r103,%r104}, %fd38;

	shfl.sync.bfly.b32 %r106|%p27, %r104, %r78, %r117, %r123;
shfl.sync.bfly.b32 %r105|%p28, %r103, %r78, %r117, %r123;

	mov.b64 %fd39, {%r105,%r106};

	add.f64 %fd40, %fd38, %fd39;
st.shared.f64 [%r113+64], %fd40;

LBB209_17:
bar.warp.sync -1;
@%p18 bra LBB209_19;

ld.volatile.shared.u32 %r125, [%r21+8];
not.b32 %r126, %r125;
and.b32 %r127, %r126, -2147483648;
st.volatile.shared.u32 [%r21+8], %r127;
bra.uni LBB209_19;

LBB209_14:
ld.volatile.shared.u32 %r89, [%r21+8];
xor.b32 %r90, %r89, %r20;
setp.gt.s32 %p21, %r90, -1;
@%p21 bra LBB209_14;

LBB209_19:
ld.shared.f64 %fd8, [%r16+64];
bar.warp.sync -1;
and.b32 %r128, %r4, 255;
setp.ne.s32 %p30, %r128, 0;
@%p30 bra LBB209_21;

shl.b32 %r129, %r15, 3;
mov.u32 %r130, __smem_d;
add.s32 %r131, %r130, %r129;
st.shared.f64 [%r131], %fd8;

LBB209_21:
barrier.sync 0;
setp.ne.s32 %p31, %r3, 0;
@%p31 bra LBB209_30;

mul.lo.s32 %r132, %r2, %r1;
mov.u32 %r133, %ntid.z;
mad.lo.s32 %r134, %r132, %r133, 255;
shr.u32 %r22, %r134, 8;
setp.eq.s32 %p32, %r22, 0;
mov.f64 %fd61, 0d0000000000000000;
@%p32 bra LBB209_29;

add.s32 %r136, %r22, -1;
and.b32 %r150, %r22, 3;
setp.lt.u32 %p33, %r136, 3;
mov.f64 %fd61, 0d0000000000000000;
mov.u32 %r148, 0;
@%p33 bra LBB209_26;

sub.s32 %r147, %r22, %r150;
mov.f64 %fd61, 0d0000000000000000;
mov.u32 %r148, 0;

LBB209_25:
shl.b32 %r138, %r148, 3;
mov.u32 %r139, __smem_d;
add.s32 %r140, %r139, %r138;
ld.shared.f64 %fd45, [%r140];
add.f64 %fd46, %fd61, %fd45;
ld.shared.f64 %fd47, [%r140+8];
add.f64 %fd48, %fd46, %fd47;
ld.shared.f64 %fd49, [%r140+16];
add.f64 %fd50, %fd48, %fd49;
ld.shared.f64 %fd51, [%r140+24];
add.f64 %fd61, %fd50, %fd51;
add.s32 %r148, %r148, 4;
add.s32 %r147, %r147, -4;
setp.ne.s32 %p34, %r147, 0;
@%p34 bra LBB209_25;

LBB209_26:
setp.eq.s32 %p35, %r150, 0;
@%p35 bra LBB209_29;

shl.b32 %r141, %r148, 3;
mov.u32 %r142, __smem_d;
add.s32 %r149, %r142, %r141;

LBB209_28:
.pragma "nounroll";
ld.shared.f64 %fd52, [%r149];
add.f64 %fd61, %fd61, %fd52;
add.s32 %r149, %r149, 8;
add.s32 %r150, %r150, -1;
setp.ne.s32 %p36, %r150, 0;
@%p36 bra LBB209_28;

LBB209_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 8;
add.s64 %rd19, %rd17, %rd18;
st.global.f64 [%rd19], %fd61;

LBB209_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2
)
{
.reg .pred %p<35>;
.reg .b32 %r<143>;
.reg .f64 %fd<60>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch[96];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 7;
@%p1 bra LBB210_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

LBB210_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB210_6;

shl.b32 %r45, %r6, 8;
add.s32 %r135, %r45, %r3;
setp.ge.u32 %p3, %r135, %r35;
mov.f64 %fd54, 0d0000000000000000;
@%p3 bra LBB210_11;

shl.b32 %r8, %r5, 8;
mov.f64 %fd54, 0d0000000000000000;

LBB210_5:
mul.wide.u32 %rd5, %r135, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd54, %fd54, %fd18;
add.s32 %r135, %r135, %r8;
setp.lt.u32 %p4, %r135, %r35;
@%p4 bra LBB210_5;
bra.uni LBB210_11;

LBB210_6:
shl.b32 %r46, %r6, 9;
add.s32 %r136, %r46, %r3;
setp.ge.u32 %p5, %r136, %r35;
mov.f64 %fd54, 0d0000000000000000;
@%p5 bra LBB210_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 9;
mov.f64 %fd54, 0d0000000000000000;

LBB210_8:
cvt.u64.u32 %rd7, %r136;
mul.wide.u32 %rd8, %r136, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd54, %fd54, %fd21;
add.s64 %rd10, %rd7, 256;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB210_10;

add.s32 %r47, %r136, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd54, %fd54, %fd22;

LBB210_10:
add.s32 %r136, %r136, %r12;
setp.lt.u32 %p7, %r136, %r35;
@%p7 bra LBB210_8;

LBB210_11:
shr.u32 %r15, %r4, 7;
shr.u32 %r69, %r4, 2;
and.b32 %r70, %r69, 1073741816;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm256ELm128EEvPT_S1_jE7scratch;
add.s32 %r16, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd54;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd54, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r16+32], %fd33;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p18, %r17, 0;
bar.warp.sync -1;
mov.u32 %r137, %r68;
@%p18 bra LBB210_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r71;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r137,[%rd13],%r78;


LBB210_13:
shfl.sync.idx.b32 %r20|%p19, %r137, %r68, %r72, %r74;
add.s32 %r85, %r20, 1;
and.b32 %r86, %r85, 2147483647;
setp.eq.s32 %p20, %r86, 4;
shl.b32 %r87, %r15, 2;
add.s32 %r21, %r71, %r87;
@%p20 bra LBB210_15;
bra.uni LBB210_14;

LBB210_15:
and.b32 %r91, %r4, 28;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra LBB210_17;

and.b32 %r102, %r4, 3;
and.b32 %r103, %r4, -128;
shr.u32 %r104, %r103, 5;
or.b32 %r105, %r104, %r102;
shl.b32 %r106, %r105, 3;
add.s32 %r108, %r71, %r106;
ld.shared.f64 %fd34, [%r108+32];

	mov.u32 %r92, %laneid;

	and.b32 %r109, %r92, -4;
mov.u32 %r110, 15;
shl.b32 %r111, %r110, %r109;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r112, 7199;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r77, %r112, %r111;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r77, %r112, %r111;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;

	mov.u32 %r97, %laneid;

	and.b32 %r114, %r97, -4;
shl.b32 %r115, %r110, %r114;

	mov.b64 {%r98,%r99}, %fd36;

	shfl.sync.bfly.b32 %r101|%p25, %r99, %r78, %r112, %r115;
shfl.sync.bfly.b32 %r100|%p26, %r98, %r78, %r112, %r115;

	mov.b64 %fd37, {%r100,%r101};

	add.f64 %fd38, %fd36, %fd37;
st.shared.f64 [%r108+32], %fd38;

LBB210_17:
bar.warp.sync -1;
@%p18 bra LBB210_19;

ld.volatile.shared.u32 %r117, [%r21+8];
not.b32 %r118, %r117;
and.b32 %r119, %r118, -2147483648;
st.volatile.shared.u32 [%r21+8], %r119;
bra.uni LBB210_19;

LBB210_14:
ld.volatile.shared.u32 %r89, [%r21+8];
xor.b32 %r90, %r89, %r20;
setp.gt.s32 %p21, %r90, -1;
@%p21 bra LBB210_14;

LBB210_19:
ld.shared.f64 %fd8, [%r16+32];
bar.warp.sync -1;
and.b32 %r120, %r4, 127;
setp.ne.s32 %p28, %r120, 0;
@%p28 bra LBB210_21;

shl.b32 %r121, %r15, 3;
mov.u32 %r122, __smem_d;
add.s32 %r123, %r122, %r121;
st.shared.f64 [%r123], %fd8;

LBB210_21:
barrier.sync 0;
setp.ne.s32 %p29, %r3, 0;
@%p29 bra LBB210_30;

mul.lo.s32 %r124, %r2, %r1;
mov.u32 %r125, %ntid.z;
mad.lo.s32 %r126, %r124, %r125, 127;
shr.u32 %r22, %r126, 7;
setp.eq.s32 %p30, %r22, 0;
mov.f64 %fd59, 0d0000000000000000;
@%p30 bra LBB210_29;

add.s32 %r128, %r22, -1;
and.b32 %r142, %r22, 3;
setp.lt.u32 %p31, %r128, 3;
mov.f64 %fd59, 0d0000000000000000;
mov.u32 %r140, 0;
@%p31 bra LBB210_26;

sub.s32 %r139, %r22, %r142;
mov.f64 %fd59, 0d0000000000000000;
mov.u32 %r140, 0;

LBB210_25:
shl.b32 %r130, %r140, 3;
mov.u32 %r131, __smem_d;
add.s32 %r132, %r131, %r130;
ld.shared.f64 %fd43, [%r132];
add.f64 %fd44, %fd59, %fd43;
ld.shared.f64 %fd45, [%r132+8];
add.f64 %fd46, %fd44, %fd45;
ld.shared.f64 %fd47, [%r132+16];
add.f64 %fd48, %fd46, %fd47;
ld.shared.f64 %fd49, [%r132+24];
add.f64 %fd59, %fd48, %fd49;
add.s32 %r140, %r140, 4;
add.s32 %r139, %r139, -4;
setp.ne.s32 %p32, %r139, 0;
@%p32 bra LBB210_25;

LBB210_26:
setp.eq.s32 %p33, %r142, 0;
@%p33 bra LBB210_29;

shl.b32 %r133, %r140, 3;
mov.u32 %r134, __smem_d;
add.s32 %r141, %r134, %r133;

LBB210_28:
.pragma "nounroll";
ld.shared.f64 %fd50, [%r141];
add.f64 %fd59, %fd59, %fd50;
add.s32 %r141, %r141, 8;
add.s32 %r142, %r142, -1;
setp.ne.s32 %p34, %r142, 0;
@%p34 bra LBB210_28;

LBB210_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 8;
add.s64 %rd19, %rd17, %rd18;
st.global.f64 [%rd19], %fd59;

LBB210_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2
)
{
.reg .pred %p<33>;
.reg .b32 %r<135>;
.reg .f64 %fd<58>;
.reg .b64 %rd<20>;

	.shared .align 1 .b8 _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch[48];

ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_1];
ld.param.u32 %r35, [_Z20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r36, %tid.z;
mov.u32 %r37, %tid.y;
mad.lo.s32 %r38, %r1, %r36, %r37;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r38, %r2, %r3;
setp.gt.u32 %p1, %r4, 3;
@%p1 bra LBB211_2;

shl.b32 %r39, %r4, 2;
mov.u32 %r40, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r41, %r40, %r39;
mov.u32 %r42, 0;
st.shared.u32 [%r41], %r42;

LBB211_2:
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r43, %r35, -1;
and.b32 %r44, %r43, %r35;
setp.eq.s32 %p2, %r44, 0;
mov.u32 %r6, %ctaid.x;
@%p2 bra LBB211_6;

shl.b32 %r45, %r6, 7;
add.s32 %r127, %r45, %r3;
setp.ge.u32 %p3, %r127, %r35;
mov.f64 %fd52, 0d0000000000000000;
@%p3 bra LBB211_11;

shl.b32 %r8, %r5, 7;
mov.f64 %fd52, 0d0000000000000000;

LBB211_5:
mul.wide.u32 %rd5, %r127, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd52, %fd52, %fd18;
add.s32 %r127, %r127, %r8;
setp.lt.u32 %p4, %r127, %r35;
@%p4 bra LBB211_5;
bra.uni LBB211_11;

LBB211_6:
shl.b32 %r46, %r6, 8;
add.s32 %r128, %r46, %r3;
setp.ge.u32 %p5, %r128, %r35;
mov.f64 %fd52, 0d0000000000000000;
@%p5 bra LBB211_11;

cvt.u64.u32 %rd2, %r35;
shl.b32 %r12, %r5, 8;
mov.f64 %fd52, 0d0000000000000000;

LBB211_8:
cvt.u64.u32 %rd7, %r128;
mul.wide.u32 %rd8, %r128, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd52, %fd52, %fd21;
add.s64 %rd10, %rd7, 128;
setp.ge.u64 %p6, %rd10, %rd2;
@%p6 bra LBB211_10;

add.s32 %r47, %r128, %r2;
mul.wide.u32 %rd11, %r47, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd52, %fd52, %fd22;

LBB211_10:
add.s32 %r128, %r128, %r12;
setp.lt.u32 %p7, %r128, %r35;
@%p7 bra LBB211_8;

LBB211_11:
shr.u32 %r15, %r4, 6;
shr.u32 %r69, %r4, 2;
and.b32 %r70, %r69, 1073741816;
mov.u32 %r71, _ZZ20multi_warp_cg_reduceIdLm128ELm64EEvPT_S1_jE7scratch;
add.s32 %r16, %r71, %r70;

	mov.b64 {%r48,%r49}, %fd52;

	mov.u32 %r72, 31;
mov.u32 %r73, 16;
mov.u32 %r74, -1;
shfl.sync.bfly.b32 %r51|%p8, %r49, %r73, %r72, %r74;
shfl.sync.bfly.b32 %r50|%p9, %r48, %r73, %r72, %r74;

	mov.b64 %fd24, {%r50,%r51};

	add.f64 %fd25, %fd52, %fd24;

	mov.b64 {%r52,%r53}, %fd25;

	mov.u32 %r75, 8;
shfl.sync.bfly.b32 %r55|%p10, %r53, %r75, %r72, %r74;
shfl.sync.bfly.b32 %r54|%p11, %r52, %r75, %r72, %r74;

	mov.b64 %fd26, {%r54,%r55};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r56,%r57}, %fd27;

	mov.u32 %r76, 4;
shfl.sync.bfly.b32 %r59|%p12, %r57, %r76, %r72, %r74;
shfl.sync.bfly.b32 %r58|%p13, %r56, %r76, %r72, %r74;

	mov.b64 %fd28, {%r58,%r59};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r60,%r61}, %fd29;

	mov.u32 %r77, 2;
shfl.sync.bfly.b32 %r63|%p14, %r61, %r77, %r72, %r74;
shfl.sync.bfly.b32 %r62|%p15, %r60, %r77, %r72, %r74;

	mov.b64 %fd30, {%r62,%r63};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r64,%r65}, %fd31;

	mov.u32 %r78, 1;
shfl.sync.bfly.b32 %r67|%p16, %r65, %r78, %r72, %r74;
shfl.sync.bfly.b32 %r66|%p17, %r64, %r78, %r72, %r74;

	mov.b64 %fd32, {%r66,%r67};

	add.f64 %fd33, %fd31, %fd32;
mov.u32 %r68, 0;
st.shared.f64 [%r16+16], %fd33;
and.b32 %r17, %r4, 31;
setp.ne.s32 %p18, %r17, 0;
bar.warp.sync -1;
mov.u32 %r129, %r68;
@%p18 bra LBB211_13;

mul.wide.u32 %rd14, %r15, 4;
{ .reg .b64 %tmp;
cvt.u64.u32 %tmp, %r71;
cvta.shared.u64 %rd15, %tmp; }
add.s64 %rd16, %rd15, %rd14;
add.s64 %rd13, %rd16, 8;

	atom.add.release.gpu.u32 %r129,[%rd13],%r78;


LBB211_13:
shfl.sync.idx.b32 %r20|%p19, %r129, %r68, %r72, %r74;
add.s32 %r85, %r20, 1;
and.b32 %r86, %r85, 2147483647;
setp.eq.s32 %p20, %r86, 2;
shl.b32 %r87, %r15, 2;
add.s32 %r21, %r71, %r87;
@%p20 bra LBB211_15;
bra.uni LBB211_14;

LBB211_15:
and.b32 %r91, %r4, 30;
setp.ne.s32 %p22, %r91, 0;
@%p22 bra LBB211_17;

and.b32 %r97, %r4, 1;
and.b32 %r99, %r4, -64;
shr.u32 %r100, %r99, 5;
or.b32 %r101, %r100, %r97;
shl.b32 %r102, %r101, 3;
mov.u32 %r103, 3;
add.s32 %r105, %r71, %r102;
ld.shared.f64 %fd34, [%r105+16];

	mov.u32 %r92, %laneid;

	and.b32 %r106, %r92, -2;
shl.b32 %r107, %r103, %r106;

	mov.b64 {%r93,%r94}, %fd34;

	mov.u32 %r108, 7711;
shfl.sync.bfly.b32 %r96|%p23, %r94, %r78, %r108, %r107;
shfl.sync.bfly.b32 %r95|%p24, %r93, %r78, %r108, %r107;

	mov.b64 %fd35, {%r95,%r96};

	add.f64 %fd36, %fd34, %fd35;
st.shared.f64 [%r105+16], %fd36;

LBB211_17:
bar.warp.sync -1;
@%p18 bra LBB211_19;

ld.volatile.shared.u32 %r109, [%r21+8];
not.b32 %r110, %r109;
and.b32 %r111, %r110, -2147483648;
st.volatile.shared.u32 [%r21+8], %r111;
bra.uni LBB211_19;

LBB211_14:
ld.volatile.shared.u32 %r89, [%r21+8];
xor.b32 %r90, %r89, %r20;
setp.gt.s32 %p21, %r90, -1;
@%p21 bra LBB211_14;

LBB211_19:
ld.shared.f64 %fd8, [%r16+16];
bar.warp.sync -1;
and.b32 %r112, %r4, 63;
setp.ne.s32 %p26, %r112, 0;
@%p26 bra LBB211_21;

shl.b32 %r113, %r15, 3;
mov.u32 %r114, __smem_d;
add.s32 %r115, %r114, %r113;
st.shared.f64 [%r115], %fd8;

LBB211_21:
barrier.sync 0;
setp.ne.s32 %p27, %r3, 0;
@%p27 bra LBB211_30;

mul.lo.s32 %r116, %r2, %r1;
mov.u32 %r117, %ntid.z;
mad.lo.s32 %r118, %r116, %r117, 63;
shr.u32 %r22, %r118, 6;
setp.eq.s32 %p28, %r22, 0;
mov.f64 %fd57, 0d0000000000000000;
@%p28 bra LBB211_29;

add.s32 %r120, %r22, -1;
and.b32 %r134, %r22, 3;
setp.lt.u32 %p29, %r120, 3;
mov.f64 %fd57, 0d0000000000000000;
mov.u32 %r132, 0;
@%p29 bra LBB211_26;

sub.s32 %r131, %r22, %r134;
mov.f64 %fd57, 0d0000000000000000;
mov.u32 %r132, 0;

LBB211_25:
shl.b32 %r122, %r132, 3;
mov.u32 %r123, __smem_d;
add.s32 %r124, %r123, %r122;
ld.shared.f64 %fd41, [%r124];
add.f64 %fd42, %fd57, %fd41;
ld.shared.f64 %fd43, [%r124+8];
add.f64 %fd44, %fd42, %fd43;
ld.shared.f64 %fd45, [%r124+16];
add.f64 %fd46, %fd44, %fd45;
ld.shared.f64 %fd47, [%r124+24];
add.f64 %fd57, %fd46, %fd47;
add.s32 %r132, %r132, 4;
add.s32 %r131, %r131, -4;
setp.ne.s32 %p30, %r131, 0;
@%p30 bra LBB211_25;

LBB211_26:
setp.eq.s32 %p31, %r134, 0;
@%p31 bra LBB211_29;

shl.b32 %r125, %r132, 3;
mov.u32 %r126, __smem_d;
add.s32 %r133, %r126, %r125;

LBB211_28:
.pragma "nounroll";
ld.shared.f64 %fd48, [%r133];
add.f64 %fd57, %fd57, %fd48;
add.s32 %r133, %r133, 8;
add.s32 %r134, %r134, -1;
setp.ne.s32 %p32, %r134, 0;
@%p32 bra LBB211_28;

LBB211_29:
cvta.to.global.u64 %rd17, %rd3;
mul.wide.u32 %rd18, %r6, 8;
add.s64 %rd19, %rd17, %rd18;
st.global.f64 [%rd19], %fd57;

LBB211_30:
ret;

}

.visible .entry _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j(
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0,
.param .u64 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1,
.param .u32 _Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2
)
{
.reg .pred %p<24>;
.reg .b32 %r<88>;
.reg .f64 %fd<54>;
.reg .b64 %rd<16>;


ld.param.u64 %rd4, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_0];
ld.param.u64 %rd3, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_1];
ld.param.u32 %r30, [_Z20multi_warp_cg_reduceIdLm64ELm32EEvPT_S1_j_param_2];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r1, %ntid.y;
mov.u32 %r31, %tid.z;
mov.u32 %r32, %tid.y;
mad.lo.s32 %r33, %r1, %r31, %r32;
mov.u32 %r2, %ntid.x;
mov.u32 %r3, %tid.x;
mad.lo.s32 %r4, %r33, %r2, %r3;
barrier.sync 0;
mov.u32 %r5, %nctaid.x;
add.s32 %r34, %r30, -1;
and.b32 %r35, %r34, %r30;
setp.eq.s32 %p1, %r35, 0;
mov.u32 %r6, %ctaid.x;
@%p1 bra LBB212_4;

shl.b32 %r36, %r6, 6;
add.s32 %r80, %r36, %r3;
setp.ge.u32 %p2, %r80, %r30;
mov.f64 %fd48, 0d0000000000000000;
@%p2 bra LBB212_9;

shl.b32 %r8, %r5, 6;
mov.f64 %fd48, 0d0000000000000000;

LBB212_3:
mul.wide.u32 %rd5, %r80, 8;
add.s64 %rd6, %rd1, %rd5;
ld.global.f64 %fd18, [%rd6];
add.f64 %fd48, %fd48, %fd18;
add.s32 %r80, %r80, %r8;
setp.lt.u32 %p3, %r80, %r30;
@%p3 bra LBB212_3;
bra.uni LBB212_9;

LBB212_4:
shl.b32 %r37, %r6, 7;
add.s32 %r81, %r37, %r3;
setp.ge.u32 %p4, %r81, %r30;
mov.f64 %fd48, 0d0000000000000000;
@%p4 bra LBB212_9;

cvt.u64.u32 %rd2, %r30;
shl.b32 %r12, %r5, 7;
mov.f64 %fd48, 0d0000000000000000;

LBB212_6:
cvt.u64.u32 %rd7, %r81;
mul.wide.u32 %rd8, %r81, 8;
add.s64 %rd9, %rd1, %rd8;
ld.global.f64 %fd21, [%rd9];
add.f64 %fd48, %fd48, %fd21;
add.s64 %rd10, %rd7, 64;
setp.ge.u64 %p5, %rd10, %rd2;
@%p5 bra LBB212_8;

add.s32 %r38, %r81, %r2;
mul.wide.u32 %rd11, %r38, 8;
add.s64 %rd12, %rd1, %rd11;
ld.global.f64 %fd22, [%rd12];
add.f64 %fd48, %fd48, %fd22;

LBB212_8:
add.s32 %r81, %r81, %r12;
setp.lt.u32 %p6, %r81, %r30;
@%p6 bra LBB212_6;

LBB212_9:

	mov.b64 {%r39,%r40}, %fd48;

	mov.u32 %r59, 31;
mov.u32 %r60, 16;
mov.u32 %r61, -1;
shfl.sync.bfly.b32 %r42|%p7, %r40, %r60, %r59, %r61;
shfl.sync.bfly.b32 %r41|%p8, %r39, %r60, %r59, %r61;

	mov.b64 %fd24, {%r41,%r42};

	add.f64 %fd25, %fd48, %fd24;

	mov.b64 {%r43,%r44}, %fd25;

	mov.u32 %r62, 8;
shfl.sync.bfly.b32 %r46|%p9, %r44, %r62, %r59, %r61;
shfl.sync.bfly.b32 %r45|%p10, %r43, %r62, %r59, %r61;

	mov.b64 %fd26, {%r45,%r46};

	add.f64 %fd27, %fd25, %fd26;

	mov.b64 {%r47,%r48}, %fd27;

	mov.u32 %r63, 4;
shfl.sync.bfly.b32 %r50|%p11, %r48, %r63, %r59, %r61;
shfl.sync.bfly.b32 %r49|%p12, %r47, %r63, %r59, %r61;

	mov.b64 %fd28, {%r49,%r50};

	add.f64 %fd29, %fd27, %fd28;

	mov.b64 {%r51,%r52}, %fd29;

	mov.u32 %r64, 2;
shfl.sync.bfly.b32 %r54|%p13, %r52, %r64, %r59, %r61;
shfl.sync.bfly.b32 %r53|%p14, %r51, %r64, %r59, %r61;

	mov.b64 %fd30, {%r53,%r54};

	add.f64 %fd31, %fd29, %fd30;

	mov.b64 {%r55,%r56}, %fd31;

	mov.u32 %r65, 1;
shfl.sync.bfly.b32 %r58|%p15, %r56, %r65, %r59, %r61;
shfl.sync.bfly.b32 %r57|%p16, %r55, %r65, %r59, %r61;

	mov.b64 %fd32, {%r57,%r58};

	add.f64 %fd8, %fd31, %fd32;
and.b32 %r66, %r4, 31;
setp.ne.s32 %p17, %r66, 0;
@%p17 bra LBB212_11;

shr.u32 %r67, %r4, 2;
and.b32 %r68, %r67, 1073741816;
mov.u32 %r69, __smem_d;
add.s32 %r70, %r69, %r68;
st.shared.f64 [%r70], %fd8;

LBB212_11:
barrier.sync 0;
setp.ne.s32 %p18, %r3, 0;
@%p18 bra LBB212_20;

mul.lo.s32 %r71, %r2, %r1;
mov.u32 %r72, %ntid.z;
mad.lo.s32 %r73, %r71, %r72, 31;
shr.u32 %r15, %r73, 5;
setp.eq.s32 %p19, %r15, 0;
mov.f64 %fd53, 0d0000000000000000;
@%p19 bra LBB212_19;

add.s32 %r75, %r15, -1;
and.b32 %r87, %r15, 3;
setp.lt.u32 %p20, %r75, 3;
mov.f64 %fd53, 0d0000000000000000;
mov.u32 %r85, 0;
@%p20 bra LBB212_16;

sub.s32 %r84, %r15, %r87;
mov.f64 %fd53, 0d0000000000000000;
mov.u32 %r85, 0;
mov.u32 %r82, __smem_d;

LBB212_15:
ld.shared.f64 %fd37, [%r82];
add.f64 %fd38, %fd53, %fd37;
ld.shared.f64 %fd39, [%r82+8];
add.f64 %fd40, %fd38, %fd39;
ld.shared.f64 %fd41, [%r82+16];
add.f64 %fd42, %fd40, %fd41;
ld.shared.f64 %fd43, [%r82+24];
add.f64 %fd53, %fd42, %fd43;
add.s32 %r85, %r85, 4;
add.s32 %r82, %r82, 32;
add.s32 %r84, %r84, -4;
setp.ne.s32 %p21, %r84, 0;
@%p21 bra LBB212_15;

LBB212_16:
setp.eq.s32 %p22, %r87, 0;
@%p22 bra LBB212_19;

shl.b32 %r78, %r85, 3;
mov.u32 %r79, __smem_d;
add.s32 %r86, %r79, %r78;

LBB212_18:
.pragma "nounroll";
ld.shared.f64 %fd44, [%r86];
add.f64 %fd53, %fd53, %fd44;
add.s32 %r86, %r86, 8;
add.s32 %r87, %r87, -1;
setp.ne.s32 %p23, %r87, 0;
@%p23 bra LBB212_18;

LBB212_19:
cvta.to.global.u64 %rd13, %rd3;
mul.wide.u32 %rd14, %r6, 8;
add.s64 %rd15, %rd13, %rd14;
st.global.f64 [%rd15], %fd53;

LBB212_20:
ret;

}


Fatbin elf code:
================
arch = sm_80
code version = [1,7]
producer = <unknown>
host = linux
compile_size = 64bit
